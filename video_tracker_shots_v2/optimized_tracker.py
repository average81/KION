"""
–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ç—Ä–µ–∫–µ—Ä –æ–±—ä–µ–∫—Ç–æ–≤ –≤ –≤–∏–¥–µ–æ
–¢–æ—á–Ω–∞—è –∫–æ–ø–∏—è —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏ –∏–∑ integrated_tracker_optimized.py
"""

import cv2
import numpy as np
import torch
from ultralytics import YOLO
import pandas as pd
# from moviepy.editor import VideoFileClip, AudioFileClip  # –£–±–∏—Ä–∞–µ–º –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç—å –æ—Ç moviepy
import os
from collections import deque, defaultdict
import time
from typing import List, Tuple, Optional, Dict, Any
import logging
from pathlib import Path
import shutil
import sys

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class OptimizedBoundingBoxTracker:
    """–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ç—Ä–µ–∫–µ—Ä –æ–±—ä–µ–∫—Ç–æ–≤ —Å —É–ª—É—á—à–µ–Ω–Ω–æ–π –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å—é"""
    
    def __init__(self, max_history: int = 30, interpolation_frames: int = 20, 
                 iou_threshold: float = 0.3, min_detections_for_tracking: int = 6,
                 min_confidence: float = 0.7):
        self.objects: Dict[int, 'TrackedObject'] = {}
        self.next_id = 0
        self.max_history = max_history
        self.interpolation_frames = interpolation_frames
        self.iou_threshold = iou_threshold
        self.min_detections_for_tracking = min_detections_for_tracking
        self.min_confidence = min_confidence
        self.current_frame = 0
        
        # –ö—ç—à –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è –≤—ã—á–∏—Å–ª–µ–Ω–∏–π
        self._iou_cache = {}
        self._frame_cache_size = 100
        
    def update(self, detections: List[Tuple], frame_num: int) -> List[Tuple]:
        """–û–±–Ω–æ–≤–ª—è–µ—Ç —Ç—Ä–µ–∫–µ—Ä —Å –Ω–æ–≤—ã–º–∏ –¥–µ—Ç–µ–∫—Ü–∏—è–º–∏"""
        self.current_frame = frame_num
        self._clear_old_cache()
        
        if not detections:
            return self._get_all_boxes()
            
        # –°–æ–ø–æ—Å—Ç–∞–≤–ª—è–µ–º –¥–µ—Ç–µ–∫—Ü–∏–∏ —Å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º–∏ –æ–±—ä–µ–∫—Ç–∞–º–∏
        matched_detections, unmatched_detections = self._match_detections(detections)
        
        # –û–±–Ω–æ–≤–ª—è–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –æ–±—ä–µ–∫—Ç—ã
        for detection, obj_id in matched_detections:
            self.objects[obj_id].update(detection, frame_num)
            
        # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–µ –æ–±—ä–µ–∫—Ç—ã –¥–ª—è –Ω–µ—Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã—Ö –¥–µ—Ç–µ–∫—Ü–∏–π
        for detection in unmatched_detections:
            self._create_new_object(detection, frame_num)
            
        # –£–¥–∞–ª—è–µ–º —É—Å—Ç–∞—Ä–µ–≤—à–∏–µ –æ–±—ä–µ–∫—Ç—ã
        self._remove_expired_objects()
        
        return self._get_all_boxes()
    
    def _match_detections(self, detections: List[Tuple]) -> Tuple[List[Tuple], List[Tuple]]:
        """–°–æ–ø–æ—Å—Ç–∞–≤–ª—è–µ—Ç –¥–µ—Ç–µ–∫—Ü–∏–∏ —Å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º–∏ –æ–±—ä–µ–∫—Ç–∞–º–∏ –∏—Å–ø–æ–ª—å–∑—É—è IoU –∏ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ (–∫–∞–∫ –≤ –æ—Ä–∏–≥–∏–Ω–∞–ª–µ)"""
        if not self.objects:
            return [], detections
            
        matched = []
        unmatched = []
        
        for detection in detections:
            best_match_id = None
            best_iou = 0.0
            
            # –í—ã—á–∏—Å–ª—è–µ–º —Ü–µ–Ω—Ç—Ä –Ω–æ–≤–æ–π –¥–µ—Ç–µ–∫—Ü–∏–∏
            new_center_x = (detection[0] + detection[2]) / 2
            new_center_y = (detection[1] + detection[3]) / 2
            
            for obj_id, obj in self.objects.items():
                last_box = obj.get_last_box()
                if last_box is not None:
                    iou = self._calculate_iou(detection[:4], last_box)
                    
                    # –í—ã—á–∏—Å–ª—è–µ–º —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –º–µ–∂–¥—É —Ü–µ–Ω—Ç—Ä–∞–º–∏
                    last_center_x = (last_box[0] + last_box[2]) / 2
                    last_center_y = (last_box[1] + last_box[3]) / 2
                    distance = np.sqrt((new_center_x - last_center_x)**2 + (new_center_y - last_center_y)**2)
                    
                    # –£—Å–ª–æ–≤–∏—è —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è –∫–∞–∫ –≤ –æ—Ä–∏–≥–∏–Ω–∞–ª–µ
                    if (iou > best_iou and iou > self.iou_threshold and distance < 100):
                        best_iou = iou
                        best_match_id = obj_id
                        logger.debug(f"ÔøΩÔøΩ –ù–∞–π–¥–µ–Ω–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ: –æ–±—ä–µ–∫—Ç {obj_id}, IoU={iou:.3f}, —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ={distance:.1f}")
            
            if best_match_id is not None:
                matched.append((detection, best_match_id))
            else:
                unmatched.append(detection)
        
        return matched, unmatched
    
    def _create_new_object(self, detection: Tuple, frame_num: int):
        """–°–æ–∑–¥–∞–µ—Ç –Ω–æ–≤—ã–π –æ–±—ä–µ–∫—Ç –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è"""
        obj = TrackedObject(
            self.next_id, detection, frame_num, 
            self.max_history, self.interpolation_frames
        )
        self.objects[self.next_id] = obj
        self.next_id += 1
        logger.info(f"üÜï –°–æ–∑–¥–∞–Ω –Ω–æ–≤—ã–π –æ–±—ä–µ–∫—Ç {obj.object_id}")
    
    def _remove_expired_objects(self):
        """–£–¥–∞–ª—è–µ—Ç —É—Å—Ç–∞—Ä–µ–≤—à–∏–µ –æ–±—ä–µ–∫—Ç—ã"""
        expired_objects = []
        
        for obj_id, obj in self.objects.items():
            frames_since_creation = self.current_frame - obj.creation_frame
            frames_since_seen = self.current_frame - obj.last_seen
            
            # –£–¥–∞–ª—è–µ–º –æ–±—ä–µ–∫—Ç—ã —Å—Ç–∞—Ä—à–µ 300 –∫–∞–¥—Ä–æ–≤ (~12 —Å–µ–∫—É–Ω–¥)
            if frames_since_creation > 300:
                expired_objects.append(obj_id)
                logger.info(f"üóëÔ∏è –£–¥–∞–ª–µ–Ω —Å—Ç–∞—Ä—ã–π –æ–±—ä–µ–∫—Ç {obj_id} (–≤–æ–∑—Ä–∞—Å—Ç: {frames_since_creation} –∫–∞–¥—Ä–æ–≤)")
                continue
                
            # –£–¥–∞–ª—è–µ–º –æ–±—ä–µ–∫—Ç—ã –Ω–µ–∞–∫—Ç–∏–≤–Ω—ã–µ –±–æ–ª–µ–µ 25 –∫–∞–¥—Ä–æ–≤ (~1 —Å–µ–∫—É–Ω–¥–∞) –¥–ª—è –Ω–µ–∞–∫—Ç–∏–≤–Ω—ã—Ö (–∫–∞–∫ –≤ –æ—Ä–∏–≥–∏–Ω–∞–ª–µ)
            if not obj.is_tracking and frames_since_seen > 25:
                expired_objects.append(obj_id)
                logger.info(f"üóëÔ∏è –£–¥–∞–ª–µ–Ω –Ω–µ–∞–∫—Ç–∏–≤–Ω—ã–π –æ–±—ä–µ–∫—Ç {obj_id} (–¥–µ—Ç–µ–∫—Ü–∏–π: {obj.detection_count}, –Ω–µ–∞–∫—Ç–∏–≤–µ–Ω: {frames_since_seen} –∫–∞–¥—Ä–æ–≤)")
                continue
            # –£–¥–∞–ª—è–µ–º –∞–∫—Ç–∏–≤–Ω—ã–µ –æ–±—ä–µ–∫—Ç—ã —á–µ—Ä–µ–∑ 20 –∫–∞–¥—Ä–æ–≤ (~0.8 —Å–µ–∫—É–Ω–¥—ã)
            elif obj.is_tracking and frames_since_seen > 20:
                expired_objects.append(obj_id)
                logger.info(f"üóëÔ∏è –£–¥–∞–ª–µ–Ω –∞–∫—Ç–∏–≤–Ω—ã–π –æ–±—ä–µ–∫—Ç {obj_id} (–Ω–µ–∞–∫—Ç–∏–≤–µ–Ω: {frames_since_seen} –∫–∞–¥—Ä–æ–≤)")
                continue
        
        for obj_id in expired_objects:
            del self.objects[obj_id]
    
    def _get_all_boxes(self) -> List[Tuple]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –≤—Å–µ –∞–∫—Ç–∏–≤–Ω—ã–µ —Ä–∞–º–∫–∏"""
        active_boxes = []
        
        for obj in self.objects.values():
            if obj.is_tracking:
                obj.check_interpolation(self.current_frame)
                box, conf = obj.get_smoothed_box()
                
                if box is None:
                    box, conf = obj.get_interpolated_box(self.current_frame)
                
                # Fallback –Ω–∞ –ø–æ—Å–ª–µ–¥–Ω—é—é —Ä–∞–º–∫—É –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
                if box is None and len(obj.history) > 0:
                    last_box, last_conf = obj.history[-1]
                    box = last_box[:4]
                    conf = last_conf
                    logger.debug(f"üîÑ Fallback –¥–ª—è –æ–±—ä–µ–∫—Ç–∞ {obj.object_id}")
                
                if box is not None:
                    active_boxes.append((*box, conf, obj.object_id))
                    logger.debug(f"‚úÖ –û–±—ä–µ–∫—Ç {obj.object_id} –æ—Ç–æ–±—Ä–∞–∂–∞–µ—Ç—Å—è (–∏–Ω—Ç–µ—Ä–ø–æ–ª—è—Ü–∏—è: {obj.is_interpolating})")
        
        return active_boxes
    
    def _calculate_distance(self, box1: Tuple, box2: Tuple) -> float:
        """–í—ã—á–∏—Å–ª—è–µ—Ç —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –º–µ–∂–¥—É —Ü–µ–Ω—Ç—Ä–∞–º–∏ —Ä–∞–º–æ–∫"""
        center1 = ((box1[0] + box1[2]) / 2, (box1[1] + box1[3]) / 2)
        center2 = ((box2[0] + box2[2]) / 2, (box2[1] + box2[3]) / 2)
        return np.sqrt((center1[0] - center2[0])**2 + (center1[1] - center2[1])**2)
    
    def _calculate_iou(self, box1: Tuple, box2: Tuple) -> float:
        """–í—ã—á–∏—Å–ª—è–µ—Ç IoU –º–µ–∂–¥—É –¥–≤—É–º—è —Ä–∞–º–∫–∞–º–∏ —Å –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ–º"""
        cache_key = tuple(sorted([box1, box2]))
        if cache_key in self._iou_cache:
            return self._iou_cache[cache_key]
        
        x1, y1, x2, y2 = box1
        x3, y3, x4, y4 = box2
        
        # –í—ã—á–∏—Å–ª—è–µ–º –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏–µ
        x_left = max(x1, x3)
        y_top = max(y1, y3)
        x_right = min(x2, x4)
        y_bottom = min(y2, y4)
        
        if x_right < x_left or y_bottom < y_top:
            iou = 0.0
        else:
            intersection = (x_right - x_left) * (y_bottom - y_top)
            area1 = (x2 - x1) * (y2 - y1)
            area2 = (x4 - x3) * (y4 - y3)
            union = area1 + area2 - intersection
            iou = intersection / union if union > 0 else 0.0
        
        self._iou_cache[cache_key] = iou
        return iou
    
    def _clear_old_cache(self):
        """–û—á–∏—â–∞–µ—Ç —Å—Ç–∞—Ä—ã–π –∫—ç—à –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ –ø–∞–º—è—Ç–∏"""
        if len(self._iou_cache) > self._frame_cache_size:
            self._iou_cache.clear()
    
    def reset(self):
        """–°–±—Ä–∞—Å—ã–≤–∞–µ—Ç —Ç—Ä–µ–∫–µ—Ä –ø—Ä–∏ —Å–º–µ–Ω–µ —Å—Ü–µ–Ω—ã"""
        self.objects.clear()
        self.next_id = 0
        self._iou_cache.clear()
        logger.info("üîÑ –¢—Ä–µ–∫–µ—Ä —Å–±—Ä–æ—à–µ–Ω")


class TrackedObject:
    """–ö–ª–∞—Å—Å –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è –æ—Ç–¥–µ–ª—å–Ω–æ–≥–æ –æ–±—ä–µ–∫—Ç–∞"""
    
    def __init__(self, object_id: int, initial_detection: Tuple, creation_frame: int,
                 max_history: int, interpolation_frames: int):
        self.object_id = object_id
        self.creation_frame = creation_frame
        self.last_seen = creation_frame
        self.detection_count = 1
        self.is_tracking = False
        self.is_interpolating = False
        self.interpolation_start_frame = 0
        self.interpolation_start = None
        self.interpolation_end = None
        
        # –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ —Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏—Å—Ç–æ—Ä–∏–∏
        self.history = deque(maxlen=max_history)
        self.interpolation_frames = interpolation_frames
        
        # –î–æ–±–∞–≤–ª—è–µ–º –ø–µ—Ä–≤—É—é –¥–µ—Ç–µ–∫—Ü–∏—é
        self.history.append((initial_detection[:4], initial_detection[4]))
        
        # –ê–∫—Ç–∏–≤–∏—Ä—É–µ–º —Ç—Ä–µ–∫–∏–Ω–≥ –ø–æ—Å–ª–µ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –¥–µ—Ç–µ–∫—Ü–∏–π
        self._check_tracking_activation()
        
    def update(self, detection: Tuple, frame_num: int):
        """–û–±–Ω–æ–≤–ª—è–µ—Ç –æ–±—ä–µ–∫—Ç –Ω–æ–≤–æ–π –¥–µ—Ç–µ–∫—Ü–∏–µ–π"""
        self.last_seen = frame_num
        self.detection_count += 1
        self.is_interpolating = False
        
        # –î–æ–±–∞–≤–ª—è–µ–º –≤ –∏—Å—Ç–æ—Ä–∏—é
        self.history.append((detection[:4], detection[4]))
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∞–∫—Ç–∏–≤–∞—Ü–∏—é —Ç—Ä–µ–∫–∏–Ω–≥–∞
        self._check_tracking_activation()
        
        # –õ–æ–≥–∏—Ä—É–µ–º –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ
        if self.is_tracking:
            last_box = self.get_last_box()
            if last_box is not None:
                distance = self._calculate_distance(detection[:4], last_box)
                logger.debug(f"üìè –û–±—ä–µ–∫—Ç {self.object_id}: —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ {distance:.1f}px, IoU: {self._calculate_iou(detection[:4], last_box):.2f}")
        
    def _check_tracking_activation(self):
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –Ω—É–∂–Ω–æ –ª–∏ –∞–∫—Ç–∏–≤–∏—Ä–æ–≤–∞—Ç—å —Ç—Ä–µ–∫–∏–Ω–≥"""
        if not self.is_tracking and self.detection_count >= 6:  # –ê–∫—Ç–∏–≤–∏—Ä—É–µ–º –ø–æ—Å–ª–µ 6 –¥–µ—Ç–µ–∫—Ü–∏–π –∫–∞–∫ –≤ –æ—Ä–∏–≥–∏–Ω–∞–ª–µ
            self.is_tracking = True
            logger.info(f"üéØ –ê–∫—Ç–∏–≤–∏—Ä–æ–≤–∞–Ω —Ç—Ä–µ–∫–∏–Ω–≥ –¥–ª—è –æ–±—ä–µ–∫—Ç–∞ {self.object_id} (–¥–µ—Ç–µ–∫—Ü–∏–π: {self.detection_count})")
        elif not self.is_tracking and self.detection_count % 1 == 0:  # –û—Ç–ª–∞–¥–∫–∞ –∫–∞–∂–¥—É—é –¥–µ—Ç–µ–∫—Ü–∏—é
            logger.info(f"üìä –û–±—ä–µ–∫—Ç {self.object_id}: {self.detection_count} –¥–µ—Ç–µ–∫—Ü–∏–π, —Ç—Ä–µ–∫–∏–Ω–≥: {self.is_tracking}")
    
    def check_interpolation(self, current_frame: int):
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –Ω—É–∂–Ω–æ –ª–∏ –Ω–∞—á–∞—Ç—å –∏–Ω—Ç–µ—Ä–ø–æ–ª—è—Ü–∏—é"""
        frames_since_seen = current_frame - self.last_seen
        
        # –ù–∞—á–∏–Ω–∞–µ–º –∏–Ω—Ç–µ—Ä–ø–æ–ª—è—Ü–∏—é –ø–æ—Å–ª–µ 3 –∫–∞–¥—Ä–æ–≤ –±–µ–∑ –¥–µ—Ç–µ–∫—Ü–∏–∏
        if frames_since_seen > 3 and not self.is_interpolating:
            self.is_interpolating = True
            self.interpolation_start_frame = current_frame
            
            if len(self.history) >= 2:
                recent_boxes = list(self.history)[-2:]
                self.interpolation_start = recent_boxes[-1][:4]
                self.interpolation_end = recent_boxes[-2][:4]
            
            logger.debug(f"üîÑ –ù–∞—á–∞—Ç–∞ –∏–Ω—Ç–µ—Ä–ø–æ–ª—è—Ü–∏—è –¥–ª—è –æ–±—ä–µ–∫—Ç–∞ {self.object_id}")
        
        # –ó–∞–≤–µ—Ä—à–∞–µ–º –∏–Ω—Ç–µ—Ä–ø–æ–ª—è—Ü–∏—é
        elif self.is_interpolating:
            if frames_since_seen > self.interpolation_frames * 2.5:
                self.is_interpolating = False
                logger.debug(f"‚èπÔ∏è –ó–∞–≤–µ—Ä—à–µ–Ω–∞ –∏–Ω—Ç–µ—Ä–ø–æ–ª—è—Ü–∏—è –¥–ª—è –æ–±—ä–µ–∫—Ç–∞ {self.object_id}")
    
    def get_smoothed_box(self) -> Tuple[Optional[Tuple], Optional[float]]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–≥–ª–∞–∂–µ–Ω–Ω—É—é —Ä–∞–º–∫—É"""
        if len(self.history) < 3:
            last_box = self.get_last_box()
            last_conf = self.history[-1][1] if self.history else None
            return last_box, last_conf
        
        # –ü—Ä–æ—Å—Ç–æ–µ —Å–≥–ª–∞–∂–∏–≤–∞–Ω–∏–µ –ø–æ –ø–æ—Å–ª–µ–¥–Ω–∏–º 3 –∫–∞–¥—Ä–∞–º
        recent_boxes = list(self.history)[-3:]
        smoothed_box = self._average_boxes([box for box, _ in recent_boxes])
        avg_conf = sum(conf for _, conf in recent_boxes) / len(recent_boxes)
        
        return smoothed_box, avg_conf
    
    def get_interpolated_box(self, current_frame: int) -> Tuple[Optional[Tuple], Optional[float]]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∏–Ω—Ç–µ—Ä–ø–æ–ª–∏—Ä–æ–≤–∞–Ω–Ω—É—é —Ä–∞–º–∫—É"""
        if not self.is_interpolating or self.interpolation_start is None:
            return None, None
        
        frames_since_start = current_frame - self.interpolation_start_frame
        if frames_since_start > self.interpolation_frames:
            return None, None
        
        # –õ–∏–Ω–µ–π–Ω–∞—è –∏–Ω—Ç–µ—Ä–ø–æ–ª—è—Ü–∏—è
        progress = frames_since_start / self.interpolation_frames
        interpolated_box = self._interpolate_boxes(self.interpolation_start, self.interpolation_end, progress)
        
        return interpolated_box, 0.5  # –°—Ä–µ–¥–Ω—è—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –¥–ª—è –∏–Ω—Ç–µ—Ä–ø–æ–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Ä–∞–º–æ–∫
    
    def get_last_box(self) -> Optional[Tuple]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø–æ—Å–ª–µ–¥–Ω—é—é —Ä–∞–º–∫—É"""
        return self.history[-1][0] if self.history else None
    
    def _average_boxes(self, boxes: List[Tuple]) -> Tuple:
        """–í—ã—á–∏—Å–ª—è–µ—Ç —Å—Ä–µ–¥–Ω—é—é —Ä–∞–º–∫—É"""
        if not boxes:
            return None
        
        avg_box = [0, 0, 0, 0]
        for box in boxes:
            for i in range(4):
                avg_box[i] += box[i]
        
        return tuple(x / len(boxes) for x in avg_box)
    
    def _interpolate_boxes(self, box1: Tuple, box2: Tuple, progress: float) -> Tuple:
        """–ò–Ω—Ç–µ—Ä–ø–æ–ª–∏—Ä—É–µ—Ç –º–µ–∂–¥—É –¥–≤—É–º—è —Ä–∞–º–∫–∞–º–∏"""
        return tuple(b1 + (b2 - b1) * progress for b1, b2 in zip(box1, box2))
    
    def _calculate_distance(self, box1: Tuple, box2: Tuple) -> float:
        """–í—ã—á–∏—Å–ª—è–µ—Ç —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –º–µ–∂–¥—É —Ü–µ–Ω—Ç—Ä–∞–º–∏ —Ä–∞–º–æ–∫"""
        center1 = ((box1[0] + box1[2]) / 2, (box1[1] + box1[3]) / 2)
        center2 = ((box2[0] + box2[2]) / 2, (box2[1] + box2[3]) / 2)
        return np.sqrt((center1[0] - center2[0])**2 + (center1[1] - center2[1])**2)
    
    def _calculate_iou(self, box1: Tuple, box2: Tuple) -> float:
        """–í—ã—á–∏—Å–ª—è–µ—Ç IoU –º–µ–∂–¥—É –¥–≤—É–º—è —Ä–∞–º–∫–∞–º–∏"""
        x1, y1, x2, y2 = box1
        x3, y3, x4, y4 = box2
        
        x_left = max(x1, x3)
        y_top = max(y1, y3)
        x_right = min(x2, x4)
        y_bottom = min(y2, y4)
        
        if x_right < x_left or y_bottom < y_top:
            return 0.0
        
        intersection = (x_right - x_left) * (y_bottom - y_top)
        area1 = (x2 - x1) * (y2 - y1)
        area2 = (x4 - x3) * (y4 - y3)
        union = area1 + area2 - intersection
        
        return intersection / union if union > 0 else 0.0


class OptimizedSceneDetector:
    """–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –¥–µ—Ç–µ–∫—Ç–æ—Ä —Å–º–µ–Ω —Å—Ü–µ–Ω"""
    
    def __init__(self, threshold: float = 10.0, min_scene_length: float = 0.7, 
                 required_consecutive: int = 1):
        self.threshold = threshold
        self.min_scene_length = min_scene_length
        self.required_consecutive = required_consecutive
        self.scene_changes = []
        self.prev_frame = None
        self.consecutive_detections = 0
        self.last_scene_change = 0
        
    def detect_scene_change(self, frame: np.ndarray, frame_num: int, fps: float) -> bool:
        """–î–µ—Ç–µ–∫—Ç–∏—Ä—É–µ—Ç —Å–º–µ–Ω—É —Å—Ü–µ–Ω—ã"""
        if self.prev_frame is None:
            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
            self.prev_frame = gray
            return False
        
        # –í—ã—á–∏—Å–ª—è–µ–º —Ä–∞–∑–Ω–æ—Å—Ç—å –∫–∞–¥—Ä–æ–≤ (–∫–∞–∫ –≤ –Ω–µ–æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –≤–µ—Ä—Å–∏–∏)
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        diff = cv2.absdiff(gray, self.prev_frame)
        mean_diff = np.mean(diff)
        normalized_diff = (mean_diff / 255.0) * 100  # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –∫–∞–∫ –≤ –æ—Ä–∏–≥–∏–Ω–∞–ª–µ
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω—É—é –¥–ª–∏–Ω—É —Å—Ü–µ–Ω—ã
        min_frames = int(self.min_scene_length * fps)
        if frame_num - self.last_scene_change < min_frames:
            self.prev_frame = gray
            return False
        
        # –î–µ—Ç–µ–∫—Ç–∏—Ä—É–µ–º —Å–º–µ–Ω—É —Å—Ü–µ–Ω—ã (–∏—Å–ø–æ–ª—å–∑—É–µ–º –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—É—é —Ä–∞–∑–Ω–æ—Å—Ç—å)
        if normalized_diff > self.threshold:
            self.consecutive_detections += 1
            if self.consecutive_detections >= self.required_consecutive:
                self.scene_changes.append(frame_num)
                self.last_scene_change = frame_num
                self.consecutive_detections = 0
                logger.info(f"üé¨ –°–º–µ–Ω–∞ —Å—Ü–µ–Ω—ã –≤ –∫–∞–¥—Ä–µ {frame_num} (—Ä–∞–∑–Ω–æ—Å—Ç—å: {normalized_diff:.1f})")
                self.prev_frame = gray
                return True
        else:
            self.consecutive_detections = 0
        
        self.prev_frame = gray
        return False
    
    def get_current_scene(self, frame_num: int) -> int:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –Ω–æ–º–µ—Ä —Ç–µ–∫—É—â–µ–π —Å—Ü–µ–Ω—ã"""
        scene_num = 0
        for change_frame in self.scene_changes:
            if frame_num >= change_frame:
                scene_num += 1
        return scene_num
    
    def save_analysis(self, output_file: str, fps: float, total_frames: int = None):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –∞–Ω–∞–ª–∏–∑ —Å—Ü–µ–Ω –≤ CSV —Å –ø–æ–ª—É–æ—Ç–∫—Ä—ã—Ç—ã–º–∏ –∏–Ω—Ç–µ—Ä–≤–∞–ª–∞–º–∏ (end_frame –Ω–µ –≤–∫–ª—é—á–∏—Ç–µ–ª—å–Ω–æ)"""
        logger.info(f"[scene_analysis] –í—ã–∑–≤–∞–Ω save_analysis. –°—Ü–µ–Ω: {len(self.scene_changes)}. –ü—É—Ç—å: {output_file}")
        if not self.scene_changes:
            logger.warning("[scene_analysis] –ù–µ—Ç —Å–º–µ–Ω —Å—Ü–µ–Ω, —Ñ–∞–π–ª –Ω–µ –±—É–¥–µ—Ç —Å–æ–∑–¥–∞–Ω.")
            return
        data = []
        prev_frame = 0
        for i, change_frame in enumerate(self.scene_changes):
            end_frame = change_frame - 1  # –ø–æ–ª—É–æ—Ç–∫—Ä—ã—Ç—ã–π –∏–Ω—Ç–µ—Ä–≤–∞–ª
            duration = (end_frame - prev_frame + 1) / fps
            data.append({
                'scene': i,
                'start_frame': prev_frame,
                'end_frame': end_frame,
                'duration_seconds': duration
            })
            prev_frame = change_frame
        # –î–æ–±–∞–≤–ª—è–µ–º –ø–æ—Å–ª–µ–¥–Ω—é—é —Å—Ü–µ–Ω—É –¥–æ –∫–æ–Ω—Ü–∞ –≤–∏–¥–µ–æ
        if total_frames is not None:
            end_frame = total_frames - 1
        else:
            end_frame = 'end'
        data.append({
            'scene': len(self.scene_changes),
            'start_frame': prev_frame,
            'end_frame': end_frame,
            'duration_seconds': 'unknown'
        })
        df = pd.DataFrame(data)
        try:
            df.to_csv(output_file, index=False)
            logger.info(f"üìä –ê–Ω–∞–ª–∏–∑ —Å—Ü–µ–Ω —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ {output_file}")
        except Exception as e:
            logger.error(f"[scene_analysis] –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ —Ñ–∞–π–ª–∞: {e}")


class OptimizedVideoProcessor:
    """–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä –≤–∏–¥–µ–æ"""
    
    def __init__(self, model_path: str = "yolov8n-pose.pt"):
        self.model = YOLO(model_path)
        self.scene_detector = OptimizedSceneDetector()
        self.tracker = OptimizedBoundingBoxTracker()
        self.color_cache = {}  # –ö—ç—à —Ü–≤–µ—Ç–æ–≤ –¥–ª—è ID
        
    def process_video(self, input_path: str, output_path: str):
        """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –≤–∏–¥–µ–æ —Å –¥–µ—Ç–µ–∫—Ü–∏–µ–π, —Ç—Ä–µ–∫–∏–Ω–≥–æ–º –∏ —Å–º–µ–Ω–æ–π —Å—Ü–µ–Ω"""
        cap = cv2.VideoCapture(input_path)
        fps = cap.get(cv2.CAP_PROP_FPS)
        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –≤–∏–¥–µ–æ–∑–∞–ø–∏—Å–∏
        fourcc = cv2.VideoWriter_fourcc(*'mp4v')
        out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))
        
        logger.info(f"üé¨ –ù–∞—á–∏–Ω–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É –≤–∏–¥–µ–æ: {total_frames} –∫–∞–¥—Ä–æ–≤, {fps:.1f} FPS")
        
        frame_count = 0
        last_scene_change = 0
        
        while True:
            ret, frame = cap.read()
            if not ret:
                break
            
            frame_count += 1
            
            # –î–µ—Ç–µ–∫—Ü–∏—è —Å–º–µ–Ω—ã —Å—Ü–µ–Ω—ã
            scene_changed = self.scene_detector.detect_scene_change(frame, frame_count, fps)
            if scene_changed:
                self.tracker.reset()
                last_scene_change = frame_count
            
            # YOLO –¥–µ—Ç–µ–∫—Ü–∏—è (–∫–∞–∂–¥—ã–π –∫–∞–¥—Ä)
            results = self.model(frame, conf=0.6, iou=0.35, max_det=15, verbose=False)
            
            # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –¥–µ—Ç–µ–∫—Ü–∏–π –ª—é–¥–µ–π
            detections = []
            for result in results:
                boxes = result.boxes
                if boxes is not None:
                    for box in boxes:
                        if box.cls == 0:  # –∫–ª–∞—Å—Å "person"
                            x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()
                            conf = box.conf[0].cpu().numpy()
                            detections.append((x1, y1, x2, y2, conf))
            
            # –£–¥–∞–ª–µ–Ω–∏–µ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤
            detections = self._filter_duplicates(detections)
            
            # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Ç—Ä–µ–∫–µ—Ä–∞
            tracked_boxes = self.tracker.update(detections, frame_count)
            
            # –û—Ç—Ä–∏—Å–æ–≤–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            processed_frame = self._draw_results(frame, tracked_boxes, frame_count, fps)
            
            # –ó–∞–ø–∏—Å—å –∫–∞–¥—Ä–∞
            out.write(processed_frame)
            
            # –ü—Ä–æ–≥—Ä–µ—Å—Å
            if frame_count % 100 == 0:
                progress = (frame_count / total_frames) * 100
                logger.info(f"üìà –ü—Ä–æ–≥—Ä–µ—Å—Å: {progress:.1f}% ({frame_count}/{total_frames})")
        
        # –ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ
        cap.release()
        out.release()
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∞–Ω–∞–ª–∏–∑–∞
        self.scene_detector.save_analysis(str(Path("output") / "scene_analysis_optimized.csv"), fps)
        
        # –ü—Ä–∏—Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ –∞—É–¥–∏–æ
        self._attach_audio(input_path, output_path)
        
        logger.info("‚úÖ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")
    
    def _filter_duplicates(self, detections: List[Tuple]) -> List[Tuple]:
        """–§–∏–ª—å—Ç—Ä—É–µ—Ç –¥—É–±–ª–∏—Ä—É—é—â–∏–µ—Å—è –¥–µ—Ç–µ–∫—Ü–∏–∏"""
        if len(detections) <= 1:
            return detections
        
        filtered = []
        for i, det1 in enumerate(detections):
            is_duplicate = False
            for j, det2 in enumerate(detections):
                if i != j:
                    iou = self._calculate_iou(det1[:4], det2[:4])
                    distance = self._calculate_distance(det1[:4], det2[:4])
                    
                    # –ë–æ–ª–µ–µ —Å—Ç—Ä–æ–≥–∞—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è: IoU > 0.3 –∏–ª–∏ –±–ª–∏–∑–∫–æ–µ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ
                    if iou > 0.3 or (iou > 0.1 and distance < 30):
                        # –û—Å—Ç–∞–≤–ª—è–µ–º –¥–µ—Ç–µ–∫—Ü–∏—é —Å –±–æ–ª—å—à–µ–π —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å—é
                        if det1[4] < det2[4]:
                            is_duplicate = True
                            logger.debug(f"üö´ –£–¥–∞–ª–µ–Ω –¥—É–±–ª–∏–∫–∞—Ç: IoU={iou:.2f}, —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ={distance:.1f}")
                            break
            if not is_duplicate:
                filtered.append(det1)
        
        return filtered
    
    def _get_color_for_id(self, obj_id: int) -> Tuple[int, int, int]:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —É–Ω–∏–∫–∞–ª—å–Ω—ã–π —Ü–≤–µ—Ç –¥–ª—è ID –æ–±—ä–µ–∫—Ç–∞"""
        if obj_id not in self.color_cache:
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ü–≤–µ—Ç –Ω–∞ –æ—Å–Ω–æ–≤–µ ID
            hue = (obj_id * 137.5) % 360  # –ó–æ–ª–æ—Ç–æ–µ —Å–µ—á–µ–Ω–∏–µ –¥–ª—è —Ä–∞–≤–Ω–æ–º–µ—Ä–Ω–æ–≥–æ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º HSV –≤ BGR
            h = hue / 60
            i = int(h)
            f = h - i
            p = 0
            q = 255 * (1 - f)
            t = 255 * f
            
            if i == 0:
                r, g, b = 255, t, p
            elif i == 1:
                r, g, b = q, 255, p
            elif i == 2:
                r, g, b = p, 255, t
            elif i == 3:
                r, g, b = p, q, 255
            elif i == 4:
                r, g, b = t, p, 255
            else:
                r, g, b = 255, p, q
            
            # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º —è—Ä–∫–æ—Å—Ç—å –¥–ª—è –ª—É—á—à–µ–π –≤–∏–¥–∏–º–æ—Å—Ç–∏
            brightness = 0.8
            r = min(255, int(r * brightness))
            g = min(255, int(g * brightness))
            b = min(255, int(b * brightness))
            
            self.color_cache[obj_id] = (b, g, r)  # BGR —Ñ–æ—Ä–º–∞—Ç –¥–ª—è OpenCV
        
        return self.color_cache[obj_id]
    
    def _draw_results(self, frame: np.ndarray, tracked_boxes: List[Tuple], 
                     frame_num: int, fps: float, shot_id: int) -> np.ndarray:
        """–û—Ç—Ä–∏—Å–æ–≤—ã–≤–∞–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –Ω–∞ –∫–∞–¥—Ä–µ"""
        result_frame = frame.copy()
        
        # –û—Ç–ª–∞–¥–æ—á–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
        if frame_num % 30 == 0:  # –ö–∞–∂–¥—ã–µ 30 –∫–∞–¥—Ä–æ–≤
            logger.info(f"üé® –û—Ç—Ä–∏—Å–æ–≤–∫–∞: {len(tracked_boxes)} –æ–±—ä–µ–∫—Ç–æ–≤ –≤ –∫–∞–¥—Ä–µ {frame_num}")
        
        # –û—Ç—Ä–∏—Å–æ–≤–∫–∞ —Ä–∞–º–æ–∫ —Å —Ä–∞–∑–Ω–æ—Ü–≤–µ—Ç–Ω—ã–º–∏ ID
        for box in tracked_boxes:
            x1, y1, x2, y2, conf, obj_id = box
            color = self._get_color_for_id(obj_id)
            
            # –†–∞–º–∫–∞
            cv2.rectangle(result_frame, (int(x1), int(y1)), (int(x2), int(y2)), color, 3)
            
            # –¢–µ–∫—Å—Ç ID –í–ù–£–¢–†–ò —Ä–∞–º–∫–∏ (–ª–µ–≤—ã–π –≤–µ—Ä—Ö–Ω–∏–π —É–≥–æ–ª)
            text = f"ID: {obj_id}"
            (text_width, text_height), _ = cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, 0.7, 2)
            text_x = int(x1) + 5
            text_y = int(y1) + text_height + 5
            # –§–æ–Ω –¥–ª—è —á–∏—Ç–∞–µ–º–æ—Å—Ç–∏
            cv2.rectangle(result_frame, (text_x - 2, text_y - text_height - 2), (text_x + text_width + 2, text_y + 2), color, -1)
            # –¢–µ–∫—Å—Ç
            cv2.putText(result_frame, text, (text_x, text_y), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
            
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å (confidence) –≤–Ω—É—Ç—Ä–∏ —Ä–∞–º–∫–∏, –≤ –ª–µ–≤–æ–º –Ω–∏–∂–Ω–µ–º —É–≥–ª—É
            conf_text = f"{conf:.2f}"
            (conf_width, conf_height), _ = cv2.getTextSize(conf_text, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2)
            conf_bg_x1 = int(x1)
            conf_bg_y1 = int(y2) - conf_height - 8
            conf_bg_x2 = int(x1) + conf_width + 10
            conf_bg_y2 = int(y2)
            # –§–æ–Ω –¥–ª—è —á–∏—Ç–∞–µ–º–æ—Å—Ç–∏
            cv2.rectangle(result_frame, (conf_bg_x1, conf_bg_y1), (conf_bg_x2, conf_bg_y2), color, -1)
            # –¢–µ–∫—Å—Ç confidence
            cv2.putText(result_frame, conf_text, (conf_bg_x1 + 5, conf_bg_y2 - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
        
        # –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –Ω–æ–º–µ—Ä–∞ —Ç–µ–∫—É—â–µ–≥–æ —à–æ—Ç–∞
        cv2.putText(result_frame, f"Shot {shot_id}", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 3)
        cv2.putText(result_frame, f"Shot {shot_id}", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 0), 1)
        
        return result_frame
    
    def _calculate_distance(self, box1: Tuple, box2: Tuple) -> float:
        """–í—ã—á–∏—Å–ª—è–µ—Ç —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –º–µ–∂–¥—É —Ü–µ–Ω—Ç—Ä–∞–º–∏ —Ä–∞–º–æ–∫"""
        center1 = ((box1[0] + box1[2]) / 2, (box1[1] + box1[3]) / 2)
        center2 = ((box2[0] + box2[2]) / 2, (box2[1] + box2[3]) / 2)
        return np.sqrt((center1[0] - center2[0])**2 + (center1[1] - center2[1])**2)
    
    def _calculate_iou(self, box1: Tuple, box2: Tuple) -> float:
        """–í—ã—á–∏—Å–ª—è–µ—Ç IoU –º–µ–∂–¥—É –¥–≤—É–º—è —Ä–∞–º–∫–∞–º–∏"""
        x1, y1, x2, y2 = box1
        x3, y3, x4, y4 = box2
        
        x_left = max(x1, x3)
        y_top = max(y1, y3)
        x_right = min(x2, x4)
        y_bottom = min(y2, y4)
        
        if x_right < x_left or y_bottom < y_top:
            return 0.0
        
        intersection = (x_right - x_left) * (y_bottom - y_top)
        area1 = (x2 - x1) * (y2 - y1)
        area2 = (x4 - x3) * (y4 - y3)
        union = area1 + area2 - intersection
        
        return intersection / union if union > 0 else 0.0
    
    def _attach_audio(self, input_path: str, output_path: str):
        """–ü—Ä–∏—Å–æ–µ–¥–∏–Ω—è–µ—Ç –∞—É–¥–∏–æ –∫ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω–æ–º—É –≤–∏–¥–µ–æ (–∑–∞–≥–ª—É—à–∫–∞ –±–µ–∑ moviepy)"""
        logger.info("üìπ –í–∏–¥–µ–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ –±–µ–∑ –∞—É–¥–∏–æ (moviepy –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω)")


class ShotsVideoProcessor(OptimizedVideoProcessor):
    """–†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤–∏–¥–µ–æ —Å —Ä–∞–∑–±–∏–≤–∫–æ–π –Ω–∞ —à–æ—Ç—ã –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º —Ñ–æ—Ç–æ"""
    
    def __init__(self, model_path: str = "yolov8n.pt"):
        super().__init__(model_path)
        self.output_root = Path("output")
        self.shots_dir = self.output_root / "shorts"
        self.shaped_shots_dir = self.output_root / "shaped_shorts"
        self.photos_dir = self.output_root / "pictures"
        self.scenes_dir = self.output_root / "scenes"
        self.shots_dir.mkdir(parents=True, exist_ok=True)
        self.shaped_shots_dir.mkdir(parents=True, exist_ok=True)
        self.photos_dir.mkdir(parents=True, exist_ok=True)
        self.scenes_dir.mkdir(parents=True, exist_ok=True)
        
        # –î–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ñ–æ—Ç–æ –∫–∞–∂–¥—ã–µ 15 –∫–∞–¥—Ä–æ–≤ (0.5 —Å–µ–∫ –ø—Ä–∏ 30fps)
        self.photo_interval_frames = 15  # –∫–∞–¥—Ä—ã
        self.last_photo_frame = {}  # {obj_id: last_frame}
        
    def process_video_with_shots(self, input_path: str, output_path: str):
        logger.info(f"üé¨ –ù–∞—á–∏–Ω–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É —Å —Ä–∞–∑–±–∏–≤–∫–æ–π –Ω–∞ —à–æ—Ç—ã: {input_path}")
        scene_csv_path = "output/scene_analysis_optimized.csv"
        # –ï—Å–ª–∏ —Ñ–∞–π–ª —Å –∞–Ω–∞–ª–∏–∑–æ–º —Å—Ü–µ–Ω –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç ‚Äî —Å–æ–∑–¥–∞—ë–º –µ–≥–æ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏
        if not os.path.exists(scene_csv_path):
            logger.info("[scene_analysis] –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω, –∑–∞–ø—É—Å–∫–∞–µ–º –∞–Ω–∞–ª–∏–∑ —Å—Ü–µ–Ω...")
            self._detect_and_save_scenes(input_path, scene_csv_path)
        scenes_df = pd.read_csv(scene_csv_path)
        logger.info(f"üìä –ù–∞–π–¥–µ–Ω–æ {len(scenes_df)} —Å—Ü–µ–Ω –¥–ª—è —Ä–∞–∑–±–∏–≤–∫–∏ –Ω–∞ —à–æ—Ç—ã")
        
        # –°–æ–∑–¥–∞–µ–º –æ–±—â–∏–π CSV —Ñ–∞–π–ª –¥–ª—è –≤—Å–µ—Ö –ª—é–¥–µ–π
        csv_data = []
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∂–¥—É—é —Å—Ü–µ–Ω—É –æ—Ç–¥–µ–ª—å–Ω–æ
        for shot_id, (_, scene) in enumerate(scenes_df.iterrows()):
            start_frame = int(scene['start_frame'])
            end_frame_str = str(scene['end_frame']).strip()
            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω—é—é —Å—Ü–µ–Ω—É —Å "end"
            if end_frame_str == "end":
                continue
            end_frame = int(end_frame_str)
            logger.info(f"üé¨ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —à–æ—Ç {shot_id}: –∫–∞–¥—Ä—ã {start_frame}-{end_frame}")
            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —à–æ—Ç: —Å–æ—Ö—Ä–∞–Ω—è–µ–º –≤–∏–¥–µ–æ, —Ç—Ä–µ–∫–∏–Ω–≥ –∏ —Ñ–æ—Ç–æ –≤ –æ–¥–Ω–æ–º –ø—Ä–æ—Ö–æ–¥–µ
            shot_csv_data = self._process_single_shot(input_path, start_frame, end_frame, shot_id)
            csv_data.extend(shot_csv_data)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–±—â–∏–π CSV —Ñ–∞–π–ª
        if csv_data:
            df = pd.DataFrame(csv_data)
            df.to_csv(str(self.shaped_shots_dir / "people_tracking_results.csv"), index=False)
            logger.info(f"üìä –°–æ—Ö—Ä–∞–Ω–µ–Ω CSV —Ñ–∞–π–ª —Å {len(csv_data)} –∑–∞–ø–∏—Å—è–º–∏ –≤ {self.shaped_shots_dir}")

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∞–Ω–∞–ª–∏–∑ —Å—Ü–µ–Ω
        cap = cv2.VideoCapture(input_path)
        fps = cap.get(cv2.CAP_PROP_FPS)
        cap.release()
        # –ü–µ—Ä–µ–¥ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –∞–Ω–∞–ª–∏–∑–∞ —Å—Ü–µ–Ω —É–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä—ã–π —Ñ–∞–π–ª, –µ—Å–ª–∏ –æ–Ω –µ—Å—Ç—å
        scene_csv_path = str(Path("output") / "scene_analysis_optimized.csv")
        if os.path.exists(scene_csv_path):
            os.remove(scene_csv_path)
        self.scene_detector.save_analysis(scene_csv_path, fps)

        logger.info("‚úÖ –û–±—Ä–∞–±–æ—Ç–∫–∞ —Å —à–æ—Ç–∞–º–∏ –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")
    
    def _detect_and_save_scenes(self, input_path: str, output_csv: str):
        cap = cv2.VideoCapture(input_path)
        fps = cap.get(cv2.CAP_PROP_FPS)
        frame_count = 0
        self.scene_detector = OptimizedSceneDetector()
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        while True:
            ret, frame = cap.read()
            if not ret:
                break
            frame_count += 1
            self.scene_detector.detect_scene_change(frame, frame_count, fps)
        cap.release()
        self.scene_detector.save_analysis(output_csv, fps, total_frames=total_frames)
        logger.info(f"[scene_analysis] –ê–Ω–∞–ª–∏–∑ —Å—Ü–µ–Ω –∑–∞–≤–µ—Ä—à—ë–Ω –∏ —Å–æ—Ö—Ä–∞–Ω—ë–Ω –≤ {output_csv}")
    
    def _process_single_shot(self, input_path: str, start_frame: int, end_frame: int, shot_id: int):
        """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –æ–¥–∏–Ω —à–æ—Ç: –≤–∏–¥–µ–æ + —Ç—Ä–µ–∫–∏–Ω–≥ + —Ñ–æ—Ç–æ –≤ –æ–¥–Ω–æ–º –ø—Ä–æ—Ö–æ–¥–µ"""
        logger.info(f"üé¨ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —à–æ—Ç {shot_id}: –∫–∞–¥—Ä—ã {start_frame}-{end_frame}")
        
        cap = cv2.VideoCapture(input_path)
        fps = cap.get(cv2.CAP_PROP_FPS)
        
        # –ü–æ–ª—É—á–∞–µ–º —Ä–∞–∑–º–µ—Ä—ã –∫–∞–¥—Ä–∞
        cap.set(cv2.CAP_PROP_POS_FRAMES, start_frame)
        ret, frame = cap.read()
        if not ret:
            raise ValueError(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å –∫–∞–¥—Ä {start_frame}")
        
        height, width = frame.shape[:2]
        
        # –°–æ–∑–¥–∞–µ–º –≤–∏–¥–µ–æ–ø–∏—Å–∞—Ç–µ–ª—å –¥–ª—è —à–æ—Ç–∞ (–±–µ–∑ —Ä–∞–∑–º–µ—Ç–∫–∏)
        fourcc = cv2.VideoWriter_fourcc(*'mp4v')
        shot_path = self.shots_dir / f"shot_{shot_id:03d}.mp4"
        out = cv2.VideoWriter(str(shot_path), fourcc, fps, (width, height))
        # –°–æ–∑–¥–∞–µ–º –≤–∏–¥–µ–æ–ø–∏—Å–∞—Ç–µ–ª—å –¥–ª—è —à–æ—Ç–∞ —Å —Ä–∞–∑–º–µ—Ç–∫–æ–π
        shaped_shot_path = self.shaped_shots_dir / f"shot_{shot_id:03d}.mp4"
        out_shaped = cv2.VideoWriter(str(shaped_shot_path), fourcc, fps, (width, height))
        
        # –°–±—Ä–∞—Å—ã–≤–∞–µ–º —Ç—Ä–µ–∫–µ—Ä –¥–ª—è –Ω–æ–≤–æ–≥–æ —à–æ—Ç–∞
        self.tracker.reset()
        self.last_photo_frame = {}
        
        # –û—á–∏—â–∞–µ–º –≤—Å–µ –∞—Ç—Ä–∏–±—É—Ç—ã –æ–±—ä–µ–∫—Ç–æ–≤, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–≥–ª–∏ –æ—Å—Ç–∞—Ç—å—Å—è
        for obj in self.tracker.objects.values():
            if hasattr(obj, 'first_photo_saved'):
                delattr(obj, 'first_photo_saved')
        
        # –î–∞–Ω–Ω—ã–µ –¥–ª—è CSV
        csv_data = []
        
        # –ü–µ—Ä–µ—Ö–æ–¥–∏–º –∫ –Ω–∞—á–∞–ª—å–Ω–æ–º—É –∫–∞–¥—Ä—É
        cap.set(cv2.CAP_PROP_POS_FRAMES, start_frame)
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–¥—Ä—ã —à–æ—Ç–∞
        for frame_num in range(start_frame, end_frame + 1):
            ret, frame = cap.read()
            if not ret:
                break
            
            # –î–µ—Ç–µ–∫—Ü–∏—è –ª—é–¥–µ–π
            results = self.model(frame, verbose=False)
            detections = []
            
            for result in results:
                boxes = result.boxes
                if boxes is not None:
                    for box in boxes:
                        if box.cls == 0:  # person class
                            x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()
                            conf = box.conf[0].cpu().numpy()
                            if conf > 0.5:
                                detections.append((x1, y1, x2, y2, conf))
            
            # –§–∏–ª—å—Ç—Ä—É–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã
            detections = self._filter_duplicates(detections)
            
            # –û–±–Ω–æ–≤–ª—è–µ–º —Ç—Ä–µ–∫–µ—Ä
            tracked_boxes = self.tracker.update(detections, frame_num)
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ–æ—Ç–æ –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
            self._save_photos_if_needed(frame, tracked_boxes, shot_id, frame_num, self.tracker)
            
            # –û—Ç—Ä–∏—Å–æ–≤—ã–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            result_frame = self._draw_results(frame, tracked_boxes, frame_num, fps, shot_id)
            
            # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –∫–∞–¥—Ä –≤ –≤–∏–¥–µ–æ —à–æ—Ç–∞ (–±–µ–∑ —Ä–∞–∑–º–µ—Ç–∫–∏)
            out.write(frame)
            # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –∫–∞–¥—Ä –≤ –≤–∏–¥–µ–æ —à–æ—Ç–∞ —Å —Ä–∞–∑–º–µ—Ç–∫–æ–π
            out_shaped.write(result_frame)
            
            # –î–æ–±–∞–≤–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ –≤ CSV
            for box in tracked_boxes:
                x1, y1, x2, y2, conf, obj_id = box
                csv_data.append({
                    'shot_id': shot_id,
                    'frame': frame_num,
                    'object_id': obj_id,
                    'x1': x1,
                    'y1': y1,
                    'x2': x2,
                    'y2': y2,
                    'confidence': conf
                })
        
        out.release()
        out_shaped.release()
        cap.release()
        
        return csv_data
    
    def _save_photos_if_needed(self, frame: np.ndarray, tracked_boxes: List[Tuple], 
                              shot_id: int, frame_count: int, shot_tracker: OptimizedBoundingBoxTracker):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ñ–æ—Ç–æ –ª—é–¥–µ–π —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –æ–±—ä–µ–∫—Ç –µ—Å—Ç—å –≤ tracked_boxes (—Ä–∞–º–∫–∞ –µ—Å—Ç—å –Ω–∞ –∫–∞–¥—Ä–µ). –ü–µ—Ä–≤–∞—è —Ñ–æ—Ç–∫–∞ —Å–æ–≤–ø–∞–¥–∞–µ—Ç —Å –ø–æ—è–≤–ª–µ–Ω–∏–µ–º —Ä–∞–º–∫–∏. –ï—Å–ª–∏ —Ä–∞–º–∫–∞ –∏—Å—á–µ–∑–ª–∞ ‚Äî —Å–±—Ä–∞—Å—ã–≤–∞–µ–º —Ç–∞–π–º–µ—Ä."""
        logger.info(f"üîç –®–æ—Ç {shot_id}, –∫–∞–¥—Ä {frame_count}: tracked_boxes={len(tracked_boxes)}")
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å–ø–∏—Å–æ–∫ –∞–∫—Ç–∏–≤–Ω—ã—Ö obj_id –Ω–∞ —ç—Ç–æ–º –∫–∞–¥—Ä–µ
        current_ids = set()
        for box in tracked_boxes:
            x1, y1, x2, y2, conf, obj_id = box
            current_ids.add(obj_id)
            logger.info(f"üîç –®–æ—Ç {shot_id}, –∫–∞–¥—Ä {frame_count}: –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –æ–±—ä–µ–∫—Ç {obj_id} –≤ –ø–æ–∑–∏—Ü–∏–∏ ({x1:.1f}, {y1:.1f})")
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ–æ—Ç–æ —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –æ–±—ä–µ–∫—Ç –µ—Å—Ç—å –≤ tracked_boxes (—Ä–∞–º–∫–∞ —Ä–µ–∞–ª—å–Ω–æ –µ—Å—Ç—å)
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω—É–∂–Ω–æ –ª–∏ —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å —Ñ–æ—Ç–æ
            just_appeared = obj_id not in self.last_photo_frame
            should_save = False
            if just_appeared:
                should_save = True
                self.last_photo_frame[obj_id] = frame_count
                logger.info(f"üîç –®–æ—Ç {shot_id}, –æ–±—ä–µ–∫—Ç {obj_id}: –ø–µ—Ä–≤—ã–π —Ä–∞–∑, should_save=True")
            else:
                # –ö–∞–∂–¥—ã–µ 15 –∫–∞–¥—Ä–æ–≤ (0.5 —Å–µ–∫)
                if frame_count - self.last_photo_frame[obj_id] >= self.photo_interval_frames:
                    should_save = True
                    self.last_photo_frame[obj_id] = frame_count
                    logger.info(f"üîç –®–æ—Ç {shot_id}, –æ–±—ä–µ–∫—Ç {obj_id}: –Ω–µ –ø–µ—Ä–≤—ã–π —Ä–∞–∑, should_save=True")
                else:
                    logger.info(f"üîç –®–æ—Ç {shot_id}, –æ–±—ä–µ–∫—Ç {obj_id}: –Ω–µ –ø–µ—Ä–≤—ã–π —Ä–∞–∑, should_save=False")
            
            if should_save:
                # –í—ã—Ä–µ–∑–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —á–µ–ª–æ–≤–µ–∫–∞
                x1, y1, x2, y2 = map(int, [x1, y1, x2, y2])
                person_img = frame[y1:y2, x1:x2]
                if person_img.size > 0:
                    # –°–æ–∑–¥–∞–µ–º –ø–∞–ø–∫—É —à–æ—Ç–∞ –∏ –ø–æ–¥–ø–∞–ø–∫—É ID
                    shot_dir = self.photos_dir / f"shot_{shot_id:03d}"
                    shot_dir.mkdir(exist_ok=True)
                    id_dir = shot_dir / f"ID_{obj_id:03d}"
                    id_dir.mkdir(exist_ok=True)
                    img_path = id_dir / f"shot_{shot_id:03d}_frame_{frame_count:06d}.jpg"
                    cv2.imwrite(str(img_path), person_img)
                    
                    if just_appeared:
                        logger.info(f"üì∏ –ü–µ—Ä–≤–æ–µ —Ñ–æ—Ç–æ –ø—Ä–∏ –ø–æ—è–≤–ª–µ–Ω–∏–∏ —Ä–∞–º–∫–∏ (–∫–∞–¥—Ä {frame_count}): {img_path}")
                    else:
                        logger.info(f"üì∏ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ —Ñ–æ—Ç–æ –∫–∞–∂–¥—ã–µ 15 –∫–∞–¥—Ä–æ–≤ (–∫–∞–¥—Ä {frame_count}): {img_path}")
        
        # –°–±—Ä–æ—Å last_photo_frame –¥–ª—è –∏—Å—á–µ–∑–Ω—É–≤—à–∏—Ö –æ–±—ä–µ–∫—Ç–æ–≤
        ids_to_remove = [obj_id for obj_id in self.last_photo_frame if obj_id not in current_ids]
        for obj_id in ids_to_remove:
            del self.last_photo_frame[obj_id]


def clear_output_dirs():
    """–û—á–∏—â–∞–µ—Ç –ø–∞–ø–∫—É output –∏ –≤—Å–µ –≤–ª–æ–∂–µ–Ω–Ω—ã–µ –≤—ã—Ö–æ–¥–Ω—ã–µ –ø–∞–ø–∫–∏ –ø–µ—Ä–µ–¥ –Ω–∞—á–∞–ª–æ–º —Ä–∞–±–æ—Ç—ã"""
    output_root = Path("output")
    if output_root.exists():
        shutil.rmtree(output_root)
    (output_root / "shorts").mkdir(parents=True, exist_ok=True)
    (output_root / "shaped_shorts").mkdir(parents=True, exist_ok=True)
    (output_root / "pictures").mkdir(parents=True, exist_ok=True)
    (output_root / "scenes").mkdir(parents=True, exist_ok=True)


def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    clear_output_dirs()
    # –ü–æ–ª—É—á–∞–µ–º –∏–º—è –≤—Ö–æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞ –∏–∑ –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤ –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏, –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 'in1.mp4'
    input_video = sys.argv[1] if len(sys.argv) > 1 else "mister-i-missis-smit-2005_1.mkv"
    processor = ShotsVideoProcessor()
    processor.process_video_with_shots(input_video, "output_video_optimized.mp4")


if __name__ == "__main__":
    main() 