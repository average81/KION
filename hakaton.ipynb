{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP+XyS+tkcEdf6kMIh51Raw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iKatePy/KION/blob/main/hakaton.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "можно добавить видео с аудио или автоматическое описание сцен через GPT/LLM"
      ],
      "metadata": {
        "id": "U6MFbQv7eRsw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wiGRqZfliiLl",
        "outputId": "0c611b0c-f5cd-4a6f-bea4-77a9ed1d9f32"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.11.13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Обновляем список пакетов и устанавливаем Python 3.9 и необходимые компоненты\n",
        "!sudo apt-get update -y\n",
        "!sudo apt-get install python3.9 python3.9-distutils python3.9-dev -y\n",
        "\n",
        "# 2. Заменяем системный python3 на python3.9 (через символическую ссылку)\n",
        "!sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.11 1\n",
        "!sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.9 2\n",
        "!sudo update-alternatives --config python3  # В появившемся меню выбираем номер с python3.9\n",
        "\n",
        "# 3. Проверяем текущую версию python3\n",
        "!python3 --version\n",
        "\n",
        "# 4. Устанавливаем pip для Python 3.9\n",
        "!curl https://bootstrap.pypa.io/get-pip.py -o get-pip.py\n",
        "!python3 get-pip.py --force-reinstall\n",
        "\n",
        "# 5. При необходимости переустанавливаем нужные пакеты через pip для Python 3.9\n",
        "!python3 -m pip install --upgrade transformers accelerate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wo9OmWgwjG2t",
        "outputId": "5ac15340-dd51-4bd3-c877-dcdb9161a64b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Get:1 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Hit:2 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:4 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "Get:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Get:6 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:11 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [3,148 kB]\n",
            "Get:12 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,267 kB]\n",
            "Get:13 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [4,932 kB]\n",
            "Get:14 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1,840 kB]\n",
            "Get:15 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [9,124 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [5,139 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,572 kB]\n",
            "Get:18 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,764 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,461 kB]\n",
            "Fetched 33.6 MB in 7s (4,755 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libpython3.9 libpython3.9-dev libpython3.9-minimal libpython3.9-stdlib\n",
            "  python3.9-lib2to3 python3.9-minimal\n",
            "Suggested packages:\n",
            "  python3.9-venv binfmt-support\n",
            "The following NEW packages will be installed:\n",
            "  libpython3.9 libpython3.9-dev libpython3.9-minimal libpython3.9-stdlib\n",
            "  python3.9 python3.9-dev python3.9-distutils python3.9-lib2to3\n",
            "  python3.9-minimal\n",
            "0 upgraded, 9 newly installed, 0 to remove and 36 not upgraded.\n",
            "Need to get 12.2 MB of archives.\n",
            "After this operation, 46.6 MB of additional disk space will be used.\n",
            "Get:1 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 libpython3.9-minimal amd64 3.9.23-1+jammy1 [837 kB]\n",
            "Get:2 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 python3.9-minimal amd64 3.9.23-1+jammy1 [2,075 kB]\n",
            "Get:3 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 libpython3.9-stdlib amd64 3.9.23-1+jammy1 [1,842 kB]\n",
            "Get:4 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 libpython3.9 amd64 3.9.23-1+jammy1 [1,904 kB]\n",
            "Get:5 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 libpython3.9-dev amd64 3.9.23-1+jammy1 [4,630 kB]\n",
            "Get:6 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 python3.9 amd64 3.9.23-1+jammy1 [93.1 kB]\n",
            "Get:7 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 python3.9-dev amd64 3.9.23-1+jammy1 [500 kB]\n",
            "Get:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 python3.9-lib2to3 all 3.9.23-1+jammy1 [127 kB]\n",
            "Get:9 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 python3.9-distutils all 3.9.23-1+jammy1 [193 kB]\n",
            "Fetched 12.2 MB in 2s (6,776 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 9.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package libpython3.9-minimal:amd64.\n",
            "(Reading database ... 126281 files and directories currently installed.)\n",
            "Preparing to unpack .../0-libpython3.9-minimal_3.9.23-1+jammy1_amd64.deb ...\n",
            "Unpacking libpython3.9-minimal:amd64 (3.9.23-1+jammy1) ...\n",
            "Selecting previously unselected package python3.9-minimal.\n",
            "Preparing to unpack .../1-python3.9-minimal_3.9.23-1+jammy1_amd64.deb ...\n",
            "Unpacking python3.9-minimal (3.9.23-1+jammy1) ...\n",
            "Selecting previously unselected package libpython3.9-stdlib:amd64.\n",
            "Preparing to unpack .../2-libpython3.9-stdlib_3.9.23-1+jammy1_amd64.deb ...\n",
            "Unpacking libpython3.9-stdlib:amd64 (3.9.23-1+jammy1) ...\n",
            "Selecting previously unselected package libpython3.9:amd64.\n",
            "Preparing to unpack .../3-libpython3.9_3.9.23-1+jammy1_amd64.deb ...\n",
            "Unpacking libpython3.9:amd64 (3.9.23-1+jammy1) ...\n",
            "Selecting previously unselected package libpython3.9-dev:amd64.\n",
            "Preparing to unpack .../4-libpython3.9-dev_3.9.23-1+jammy1_amd64.deb ...\n",
            "Unpacking libpython3.9-dev:amd64 (3.9.23-1+jammy1) ...\n",
            "Selecting previously unselected package python3.9.\n",
            "Preparing to unpack .../5-python3.9_3.9.23-1+jammy1_amd64.deb ...\n",
            "Unpacking python3.9 (3.9.23-1+jammy1) ...\n",
            "Selecting previously unselected package python3.9-dev.\n",
            "Preparing to unpack .../6-python3.9-dev_3.9.23-1+jammy1_amd64.deb ...\n",
            "Unpacking python3.9-dev (3.9.23-1+jammy1) ...\n",
            "Selecting previously unselected package python3.9-lib2to3.\n",
            "Preparing to unpack .../7-python3.9-lib2to3_3.9.23-1+jammy1_all.deb ...\n",
            "Unpacking python3.9-lib2to3 (3.9.23-1+jammy1) ...\n",
            "Selecting previously unselected package python3.9-distutils.\n",
            "Preparing to unpack .../8-python3.9-distutils_3.9.23-1+jammy1_all.deb ...\n",
            "Unpacking python3.9-distutils (3.9.23-1+jammy1) ...\n",
            "Setting up libpython3.9-minimal:amd64 (3.9.23-1+jammy1) ...\n",
            "Setting up python3.9-lib2to3 (3.9.23-1+jammy1) ...\n",
            "Setting up python3.9-distutils (3.9.23-1+jammy1) ...\n",
            "Setting up python3.9-minimal (3.9.23-1+jammy1) ...\n",
            "Setting up libpython3.9-stdlib:amd64 (3.9.23-1+jammy1) ...\n",
            "Setting up libpython3.9:amd64 (3.9.23-1+jammy1) ...\n",
            "Setting up python3.9 (3.9.23-1+jammy1) ...\n",
            "Setting up libpython3.9-dev:amd64 (3.9.23-1+jammy1) ...\n",
            "Setting up python3.9-dev (3.9.23-1+jammy1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for mailcap (3.70+nmu1ubuntu1) ...\n",
            "update-alternatives: using /usr/bin/python3.9 to provide /usr/bin/python3 (python3) in auto mode\n",
            "There are 3 choices for the alternative python3 (providing /usr/bin/python3).\n",
            "\n",
            "  Selection    Path                 Priority   Status\n",
            "------------------------------------------------------------\n",
            "* 0            /usr/bin/python3.9    2         auto mode\n",
            "  1            /usr/bin/python3.10   1         manual mode\n",
            "  2            /usr/bin/python3.11   1         manual mode\n",
            "  3            /usr/bin/python3.9    2         manual mode\n",
            "\n",
            "Press <enter> to keep the current choice[*], or type selection number: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-aycNRsnjZmY",
        "outputId": "8ef9a849-e0ba-47f9-e298-957a92aded56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.9.23\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Установка необходимых библиотек\n",
        "!pip install ultralytics deep_sort_realtime facenet-pytorch torchaudio matplotlib scikit-learn opencv-python Pillow\n",
        "!pip install openai-whisper  # Whisper для распознавания речи\n",
        "!pip uninstall -y transformers  # Удаление старой версии (если есть)\n",
        "!pip install transformers  # Установка актуальной версии\n",
        "!pip install faster-whisper  # Для работы с видео и аудио"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "0QPRt9hle6ha",
        "outputId": "b3e04fba-8eab-4d61-dc38-48974c60eb38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Using cached ultralytics-8.3.168-py3-none-any.whl.metadata (37 kB)\n",
            "Collecting deep_sort_realtime\n",
            "  Using cached deep_sort_realtime-1.3.2-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting facenet-pytorch\n",
            "  Using cached facenet_pytorch-2.6.0-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting torchaudio\n",
            "  Downloading torchaudio-2.7.1-cp39-cp39-manylinux_2_28_x86_64.whl.metadata (6.6 kB)\n",
            "Collecting matplotlib\n",
            "  Downloading matplotlib-3.9.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Collecting scikit-learn\n",
            "  Downloading scikit_learn-1.6.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
            "Collecting opencv-python\n",
            "  Downloading opencv_python-4.12.0.88-cp37-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (19 kB)\n",
            "Collecting Pillow\n",
            "  Downloading pillow-11.3.0-cp39-cp39-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.9/dist-packages (from ultralytics) (2.0.2)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.9/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.9/dist-packages (from ultralytics) (2.32.4)\n",
            "Collecting scipy>=1.4.1 (from ultralytics)\n",
            "  Downloading scipy-1.13.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.9/dist-packages (from ultralytics) (2.7.1)\n",
            "Collecting torchvision>=0.9.0 (from ultralytics)\n",
            "  Downloading torchvision-0.22.1-cp39-cp39-manylinux_2_28_x86_64.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.9/dist-packages (from ultralytics) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.9/dist-packages (from ultralytics) (7.0.0)\n",
            "Collecting py-cpuinfo (from ultralytics)\n",
            "  Downloading py_cpuinfo-9.0.0-py3-none-any.whl.metadata (794 bytes)\n",
            "Collecting pandas>=1.1.4 (from ultralytics)\n",
            "  Downloading pandas-2.3.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (91 kB)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
            "  Using cached ultralytics_thop-2.0.14-py3-none-any.whl.metadata (9.4 kB)\n",
            "Collecting numpy>=1.23.0 (from ultralytics)\n",
            "  Downloading numpy-1.26.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "Collecting Pillow\n",
            "  Downloading pillow-10.2.0-cp39-cp39-manylinux_2_28_x86_64.whl.metadata (9.7 kB)\n",
            "Collecting torch>=1.8.0 (from ultralytics)\n",
            "  Downloading torch-2.2.2-cp39-cp39-manylinux1_x86_64.whl.metadata (25 kB)\n",
            "Collecting torchvision>=0.9.0 (from ultralytics)\n",
            "  Downloading torchvision-0.17.2-cp39-cp39-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.9/dist-packages (from requests>=2.23.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.23.0->ultralytics) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.23.0->ultralytics) (2025.7.14)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from torch>=1.8.0->ultralytics) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.9/dist-packages (from torch>=1.8.0->ultralytics) (4.14.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from torch>=1.8.0->ultralytics) (1.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from torch>=1.8.0->ultralytics) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.9/dist-packages (from torch>=1.8.0->ultralytics) (2025.7.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==2.2.0 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading triton-2.2.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.9/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.8.0->ultralytics) (12.6.85)\n",
            "INFO: pip is looking at multiple versions of torchaudio to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting torchaudio\n",
            "  Downloading torchaudio-2.7.0-cp39-cp39-manylinux_2_28_x86_64.whl.metadata (6.6 kB)\n",
            "  Downloading torchaudio-2.6.0-cp39-cp39-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
            "  Downloading torchaudio-2.5.1-cp39-cp39-manylinux1_x86_64.whl.metadata (6.4 kB)\n",
            "  Downloading torchaudio-2.5.0-cp39-cp39-manylinux1_x86_64.whl.metadata (6.4 kB)\n",
            "  Downloading torchaudio-2.4.1-cp39-cp39-manylinux1_x86_64.whl.metadata (6.4 kB)\n",
            "  Downloading torchaudio-2.4.0-cp39-cp39-manylinux1_x86_64.whl.metadata (6.4 kB)\n",
            "  Downloading torchaudio-2.3.1-cp39-cp39-manylinux1_x86_64.whl.metadata (6.4 kB)\n",
            "INFO: pip is still looking at multiple versions of torchaudio to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading torchaudio-2.3.0-cp39-cp39-manylinux1_x86_64.whl.metadata (6.4 kB)\n",
            "  Downloading torchaudio-2.2.2-cp39-cp39-manylinux1_x86_64.whl.metadata (6.4 kB)\n",
            "Collecting contourpy>=1.0.1 (from matplotlib)\n",
            "  Downloading contourpy-1.3.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.4 kB)\n",
            "Collecting cycler>=0.10 (from matplotlib)\n",
            "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting fonttools>=4.22.0 (from matplotlib)\n",
            "  Downloading fonttools-4.59.0-cp39-cp39-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (107 kB)\n",
            "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
            "  Downloading kiwisolver-1.4.7-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (6.3 kB)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/lib/python3/dist-packages (from matplotlib) (2.4.7)\n",
            "Collecting python-dateutil>=2.7 (from matplotlib)\n",
            "  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting importlib-resources>=3.2.0 (from matplotlib)\n",
            "  Downloading importlib_resources-6.5.2-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting joblib>=1.2.0 (from scikit-learn)\n",
            "  Downloading joblib-1.5.1-py3-none-any.whl.metadata (5.6 kB)\n",
            "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
            "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
            "INFO: pip is looking at multiple versions of opencv-python to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting opencv-python\n",
            "  Downloading opencv_python-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Collecting zipp>=3.1.0 (from importlib-resources>=3.2.0->matplotlib)\n",
            "  Downloading zipp-3.23.0-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting pytz>=2020.1 (from pandas>=1.1.4->ultralytics)\n",
            "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Collecting tzdata>=2022.7 (from pandas>=1.1.4->ultralytics)\n",
            "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/lib/python3/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (2.0.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.9/dist-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Using cached ultralytics-8.3.168-py3-none-any.whl (1.0 MB)\n",
            "Using cached deep_sort_realtime-1.3.2-py3-none-any.whl (8.4 MB)\n",
            "Using cached facenet_pytorch-2.6.0-py3-none-any.whl (1.9 MB)\n",
            "Downloading pillow-10.2.0-cp39-cp39-manylinux_2_28_x86_64.whl (4.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m36.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m52.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch-2.2.2-cp39-cp39-manylinux1_x86_64.whl (755.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m755.5/755.5 MB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Downloading triton-2.2.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (167.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.9/167.9 MB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchvision-0.17.2-cp39-cp39-manylinux1_x86_64.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m74.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchaudio-2.2.2-cp39-cp39-manylinux1_x86_64.whl (3.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m54.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading matplotlib-3.9.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.3/8.3 MB\u001b[0m \u001b[31m81.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scikit_learn-1.6.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.5/13.5 MB\u001b[0m \u001b[31m82.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opencv_python-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (63.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.0/63.0 MB\u001b[0m \u001b[31m47.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading contourpy-1.3.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (321 kB)\n",
            "Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
            "Downloading fonttools-4.59.0-cp39-cp39-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (4.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m60.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading importlib_resources-6.5.2-py3-none-any.whl (37 kB)\n",
            "Downloading joblib-1.5.1-py3-none-any.whl (307 kB)\n",
            "Downloading kiwisolver-1.4.7-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m39.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pandas-2.3.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m72.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
            "Downloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
            "Downloading scipy-1.13.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.6/38.6 MB\u001b[0m \u001b[31m42.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
            "Downloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
            "Using cached ultralytics_thop-2.0.14-py3-none-any.whl (26 kB)\n",
            "Downloading zipp-3.23.0-py3-none-any.whl (10 kB)\n",
            "Downloading py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\n",
            "Installing collected packages: pytz, py-cpuinfo, zipp, tzdata, triton, threadpoolctl, python-dateutil, Pillow, nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, kiwisolver, joblib, fonttools, cycler, scipy, pandas, opencv-python, nvidia-cusolver-cu12, nvidia-cudnn-cu12, importlib-resources, contourpy, torch, scikit-learn, matplotlib, deep_sort_realtime, ultralytics-thop, torchvision, torchaudio, ultralytics, facenet-pytorch\n",
            "\u001b[2K  Attempting uninstall: zipp\n",
            "\u001b[2K    Found existing installation: zipp 1.0.0\n",
            "\u001b[2K    Uninstalling zipp-1.0.0:\n",
            "\u001b[2K      Successfully uninstalled zipp-1.0.0\n",
            "\u001b[2K  Attempting uninstall: triton\n",
            "\u001b[2K    Found existing installation: triton 3.3.1\n",
            "\u001b[2K    Uninstalling triton-3.3.1:\n",
            "\u001b[2K      Successfully uninstalled triton-3.3.1\n",
            "\u001b[2K  Attempting uninstall: nvidia-nvtx-cu12\n",
            "\u001b[2K    Found existing installation: nvidia-nvtx-cu12 12.6.77\n",
            "\u001b[2K    Uninstalling nvidia-nvtx-cu12-12.6.77:\n",
            "\u001b[2K      Successfully uninstalled nvidia-nvtx-cu12-12.6.77\n",
            "\u001b[2K  Attempting uninstall: nvidia-nccl-cu12\n",
            "\u001b[2K    Found existing installation: nvidia-nccl-cu12 2.26.2\n",
            "\u001b[2K    Uninstalling nvidia-nccl-cu12-2.26.2:\n",
            "\u001b[2K      Successfully uninstalled nvidia-nccl-cu12-2.26.2\n",
            "\u001b[2K  Attempting uninstall: nvidia-cusparse-cu12\n",
            "\u001b[2K    Found existing installation: nvidia-cusparse-cu12 12.5.4.2\n",
            "\u001b[2K    Uninstalling nvidia-cusparse-cu12-12.5.4.2:\n",
            "\u001b[2K      Successfully uninstalled nvidia-cusparse-cu12-12.5.4.2\n",
            "\u001b[2K  Attempting uninstall: nvidia-curand-cu12\n",
            "\u001b[2K    Found existing installation: nvidia-curand-cu12 10.3.7.77\n",
            "\u001b[2K    Uninstalling nvidia-curand-cu12-10.3.7.77:\n",
            "\u001b[2K      Successfully uninstalled nvidia-curand-cu12-10.3.7.77\n",
            "\u001b[2K  Attempting uninstall: nvidia-cufft-cu12\n",
            "\u001b[2K    Found existing installation: nvidia-cufft-cu12 11.3.0.4\n",
            "\u001b[2K    Uninstalling nvidia-cufft-cu12-11.3.0.4:\n",
            "\u001b[2K      Successfully uninstalled nvidia-cufft-cu12-11.3.0.4\n",
            "\u001b[2K  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "\u001b[2K    Found existing installation: nvidia-cuda-runtime-cu12 12.6.77\n",
            "\u001b[2K    Uninstalling nvidia-cuda-runtime-cu12-12.6.77:\n",
            "\u001b[2K      Successfully uninstalled nvidia-cuda-runtime-cu12-12.6.77\n",
            "\u001b[2K  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "\u001b[2K    Found existing installation: nvidia-cuda-nvrtc-cu12 12.6.77\n",
            "\u001b[2K    Uninstalling nvidia-cuda-nvrtc-cu12-12.6.77:\n",
            "\u001b[2K      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.6.77\n",
            "\u001b[2K  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "\u001b[2K    Found existing installation: nvidia-cuda-cupti-cu12 12.6.80\n",
            "\u001b[2K    Uninstalling nvidia-cuda-cupti-cu12-12.6.80:\n",
            "\u001b[2K      Successfully uninstalled nvidia-cuda-cupti-cu12-12.6.80\n",
            "\u001b[2K  Attempting uninstall: nvidia-cublas-cu12\n",
            "\u001b[2K    Found existing installation: nvidia-cublas-cu12 12.6.4.1\n",
            "\u001b[2K    Uninstalling nvidia-cublas-cu12-12.6.4.1:\n",
            "\u001b[2K      Successfully uninstalled nvidia-cublas-cu12-12.6.4.1\n",
            "\u001b[2K  Attempting uninstall: numpy\n",
            "\u001b[2K    Found existing installation: numpy 2.0.2\n",
            "\u001b[2K    Uninstalling numpy-2.0.2:\n",
            "\u001b[2K      Successfully uninstalled numpy-2.0.2\n",
            "\u001b[2K  Attempting uninstall: nvidia-cusolver-cu12\n",
            "\u001b[2K    Found existing installation: nvidia-cusolver-cu12 11.7.1.2\n",
            "\u001b[2K    Uninstalling nvidia-cusolver-cu12-11.7.1.2:\n",
            "\u001b[2K      Successfully uninstalled nvidia-cusolver-cu12-11.7.1.2\n",
            "\u001b[2K  Attempting uninstall: nvidia-cudnn-cu12\n",
            "\u001b[2K    Found existing installation: nvidia-cudnn-cu12 9.5.1.17\n",
            "\u001b[2K    Uninstalling nvidia-cudnn-cu12-9.5.1.17:\n",
            "\u001b[2K      Successfully uninstalled nvidia-cudnn-cu12-9.5.1.17\n",
            "\u001b[2K  Attempting uninstall: torch\n",
            "\u001b[2K    Found existing installation: torch 2.7.1\n",
            "\u001b[2K    Uninstalling torch-2.7.1:\n",
            "\u001b[2K      Successfully uninstalled torch-2.7.1\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38/38\u001b[0m [facenet-pytorch]\n",
            "\u001b[1A\u001b[2KSuccessfully installed Pillow-10.2.0 contourpy-1.3.0 cycler-0.12.1 deep_sort_realtime-1.3.2 facenet-pytorch-2.6.0 fonttools-4.59.0 importlib-resources-6.5.2 joblib-1.5.1 kiwisolver-1.4.7 matplotlib-3.9.4 numpy-1.26.4 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvtx-cu12-12.1.105 opencv-python-4.11.0.86 pandas-2.3.1 py-cpuinfo-9.0.0 python-dateutil-2.9.0.post0 pytz-2025.2 scikit-learn-1.6.1 scipy-1.13.1 threadpoolctl-3.6.0 torch-2.2.2 torchaudio-2.2.2 torchvision-0.17.2 triton-2.2.0 tzdata-2025.2 ultralytics-8.3.168 ultralytics-thop-2.0.14 zipp-3.23.0\n",
            "Collecting openai-whisper\n",
            "  Using cached openai_whisper-20250625.tar.gz (803 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: more-itertools in /usr/lib/python3/dist-packages (from openai-whisper) (8.10.0)\n",
            "Collecting numba (from openai-whisper)\n",
            "  Downloading numba-0.60.0-cp39-cp39-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from openai-whisper) (1.26.4)\n",
            "Collecting tiktoken (from openai-whisper)\n",
            "  Downloading tiktoken-0.9.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.9/dist-packages (from openai-whisper) (2.2.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from openai-whisper) (4.67.1)\n",
            "Requirement already satisfied: triton>=2 in /usr/local/lib/python3.9/dist-packages (from openai-whisper) (2.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from triton>=2->openai-whisper) (3.18.0)\n",
            "Collecting llvmlite<0.44,>=0.43.0dev0 (from numba->openai-whisper)\n",
            "  Downloading llvmlite-0.43.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.8 kB)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.9/dist-packages (from tiktoken->openai-whisper) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.9/dist-packages (from tiktoken->openai-whisper) (2.32.4)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.9/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2025.7.14)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.9/dist-packages (from torch->openai-whisper) (4.14.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from torch->openai-whisper) (1.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from torch->openai-whisper) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch->openai-whisper) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.9/dist-packages (from torch->openai-whisper) (2025.7.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.9/dist-packages (from torch->openai-whisper) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.9/dist-packages (from torch->openai-whisper) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.9/dist-packages (from torch->openai-whisper) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.9/dist-packages (from torch->openai-whisper) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.9/dist-packages (from torch->openai-whisper) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.9/dist-packages (from torch->openai-whisper) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.9/dist-packages (from torch->openai-whisper) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.9/dist-packages (from torch->openai-whisper) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.9/dist-packages (from torch->openai-whisper) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.9/dist-packages (from torch->openai-whisper) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.9/dist-packages (from torch->openai-whisper) (12.1.105)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.9/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->openai-whisper) (12.6.85)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/lib/python3/dist-packages (from jinja2->torch->openai-whisper) (2.0.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.9/dist-packages (from sympy->torch->openai-whisper) (1.3.0)\n",
            "Downloading numba-0.60.0-cp39-cp39-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m48.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llvmlite-0.43.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (43.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.9/43.9 MB\u001b[0m \u001b[31m77.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tiktoken-0.9.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m43.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: openai-whisper\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20250625-py3-none-any.whl size=803979 sha256=818b7573f59d27bb06154484ae4e753bfb625a25cdfe33c4e5ec1336b479dd33\n",
            "  Stored in directory: /root/.cache/pip/wheels/8a/52/46/c497a169da69d4edcfe4e66e2f597ce258c334d74d371bf8c9\n",
            "Successfully built openai-whisper\n",
            "Installing collected packages: llvmlite, tiktoken, numba, openai-whisper\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4/4\u001b[0m [openai-whisper]\n",
            "\u001b[1A\u001b[2KSuccessfully installed llvmlite-0.43.0 numba-0.60.0 openai-whisper-20250625 tiktoken-0.9.0\n",
            "Found existing installation: transformers 4.53.2\n",
            "Uninstalling transformers-4.53.2:\n",
            "  Successfully uninstalled transformers-4.53.2\n",
            "Collecting transformers\n",
            "  Using cached transformers-4.53.2-py3-none-any.whl.metadata (40 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.33.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.21.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.7.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.14.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.5)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2025.7.14)\n",
            "Using cached transformers-4.53.2-py3-none-any.whl (10.8 MB)\n",
            "Installing collected packages: transformers\n",
            "Successfully installed transformers-4.53.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "transformers"
                ]
              },
              "id": "01f91ef68b0a4019a9103f5d785c06c1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting faster-whisper\n",
            "  Using cached faster_whisper-1.1.1-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting ctranslate2<5,>=4.0 (from faster-whisper)\n",
            "  Downloading ctranslate2-4.6.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: huggingface-hub>=0.13 in /usr/local/lib/python3.9/dist-packages (from faster-whisper) (0.33.4)\n",
            "Requirement already satisfied: tokenizers<1,>=0.13 in /usr/local/lib/python3.9/dist-packages (from faster-whisper) (0.21.2)\n",
            "Collecting onnxruntime<2,>=1.14 (from faster-whisper)\n",
            "  Downloading onnxruntime-1.19.2-cp39-cp39-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
            "Collecting av>=11 (from faster-whisper)\n",
            "  Downloading av-15.0.0-cp39-cp39-manylinux_2_28_x86_64.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from faster-whisper) (4.67.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from ctranslate2<5,>=4.0->faster-whisper) (80.9.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from ctranslate2<5,>=4.0->faster-whisper) (1.26.4)\n",
            "Requirement already satisfied: pyyaml<7,>=5.3 in /usr/local/lib/python3.9/dist-packages (from ctranslate2<5,>=4.0->faster-whisper) (6.0.2)\n",
            "Collecting coloredlogs (from onnxruntime<2,>=1.14->faster-whisper)\n",
            "  Using cached coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Collecting flatbuffers (from onnxruntime<2,>=1.14->faster-whisper)\n",
            "  Downloading flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from onnxruntime<2,>=1.14->faster-whisper) (25.0)\n",
            "Collecting protobuf (from onnxruntime<2,>=1.14->faster-whisper)\n",
            "  Downloading protobuf-6.31.1-cp39-abi3-manylinux2014_x86_64.whl.metadata (593 bytes)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from onnxruntime<2,>=1.14->faster-whisper) (1.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from huggingface-hub>=0.13->faster-whisper) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub>=0.13->faster-whisper) (2025.7.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from huggingface-hub>=0.13->faster-whisper) (2.32.4)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub>=0.13->faster-whisper) (4.14.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub>=0.13->faster-whisper) (1.1.5)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime<2,>=1.14->faster-whisper)\n",
            "  Using cached humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.9/dist-packages (from requests->huggingface-hub>=0.13->faster-whisper) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->huggingface-hub>=0.13->faster-whisper) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->huggingface-hub>=0.13->faster-whisper) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->huggingface-hub>=0.13->faster-whisper) (2025.7.14)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.9/dist-packages (from sympy->onnxruntime<2,>=1.14->faster-whisper) (1.3.0)\n",
            "Using cached faster_whisper-1.1.1-py3-none-any.whl (1.1 MB)\n",
            "Downloading ctranslate2-4.6.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.4/38.4 MB\u001b[0m \u001b[31m53.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.19.2-cp39-cp39-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (13.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.2/13.2 MB\u001b[0m \u001b[31m132.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading av-15.0.0-cp39-cp39-manylinux_2_28_x86_64.whl (39.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.3/39.3 MB\u001b[0m \u001b[31m50.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "Using cached humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "Downloading flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
            "Downloading protobuf-6.31.1-cp39-abi3-manylinux2014_x86_64.whl (321 kB)\n",
            "Installing collected packages: flatbuffers, protobuf, humanfriendly, ctranslate2, av, coloredlogs, onnxruntime, faster-whisper\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8/8\u001b[0m [faster-whisper]\n",
            "\u001b[1A\u001b[2KSuccessfully installed av-15.0.0 coloredlogs-15.0.1 ctranslate2-4.6.0 faster-whisper-1.1.1 flatbuffers-25.2.10 humanfriendly-10.0 onnxruntime-1.19.2 protobuf-6.31.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install --upgrade transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O2JuJOu7hs72",
        "outputId": "bc7a660d-ef1a-4db8-da4e-acabbfa1d580"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.9/dist-packages (4.53.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.33.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.21.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.7.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.14.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.5)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2025.7.14)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install --upgrade accelerate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1lcKBfaYhvi8",
        "outputId": "f1305402-1cd9-476a-edd2-4988228972ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.9/dist-packages (1.9.0)\n",
            "Requirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.9/dist-packages (from accelerate) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from accelerate) (25.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.9/dist-packages (from accelerate) (7.0.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.9/dist-packages (from accelerate) (6.0.2)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from accelerate) (2.2.2)\n",
            "Requirement already satisfied: huggingface_hub>=0.21.0 in /usr/local/lib/python3.9/dist-packages (from accelerate) (0.33.4)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.9/dist-packages (from accelerate) (0.5.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from huggingface_hub>=0.21.0->accelerate) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.9/dist-packages (from huggingface_hub>=0.21.0->accelerate) (2025.7.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from huggingface_hub>=0.21.0->accelerate) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.9/dist-packages (from huggingface_hub>=0.21.0->accelerate) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface_hub>=0.21.0->accelerate) (4.14.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.9/dist-packages (from huggingface_hub>=0.21.0->accelerate) (1.1.5)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from torch>=2.0.0->accelerate) (1.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from torch>=2.0.0->accelerate) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.9/dist-packages (from torch>=2.0.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.9/dist-packages (from torch>=2.0.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.9/dist-packages (from torch>=2.0.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.9/dist-packages (from torch>=2.0.0->accelerate) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.9/dist-packages (from torch>=2.0.0->accelerate) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.9/dist-packages (from torch>=2.0.0->accelerate) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.9/dist-packages (from torch>=2.0.0->accelerate) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.9/dist-packages (from torch>=2.0.0->accelerate) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.9/dist-packages (from torch>=2.0.0->accelerate) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.9/dist-packages (from torch>=2.0.0->accelerate) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.9/dist-packages (from torch>=2.0.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.9/dist-packages (from torch>=2.0.0->accelerate) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.9/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.0.0->accelerate) (12.6.85)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/lib/python3/dist-packages (from jinja2->torch>=2.0.0->accelerate) (2.0.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.9/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2025.7.14)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.9/dist-packages (from sympy->torch>=2.0.0->accelerate) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "print(\"Pipeline успешно импортирован!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Moej8nXge7jH",
        "outputId": "4a94f59d-0f7c-4859-c49b-883fd4540713"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "cannot import name 'pipeline' from 'transformers' (/usr/local/lib/python3.11/dist-packages/transformers/__init__.py)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-11-80276966.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Pipeline успешно импортирован!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'pipeline' from 'transformers' (/usr/local/lib/python3.11/dist-packages/transformers/__init__.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Импорт библиотек\n",
        "import cv2  # Работа с видео и кадрами\n",
        "import numpy as np  # Работа с массивами\n",
        "import torch  # Работа с моделями на PyTorch\n",
        "import torch.nn as nn  # Нейросетевые слои\n",
        "import whisper  # Распознавание речи\n",
        "from ultralytics import YOLO  # YOLO для детекции объектов\n",
        "from deep_sort_realtime.deepsort_tracker import DeepSort  # Трекинг объектов\n",
        "from facenet_pytorch import InceptionResnetV1  # FaceNet для идентификации лиц\n",
        "from sklearn.cluster import DBSCAN  # Кластеризация сцен\n",
        "from scipy.spatial.distance import cosine  # Сравнение эмбеддингов\n",
        "from transformers import pipeline  # NLP-модель для анализа текста\n",
        "import torchaudio  # Работа с аудио\n",
        "import torchaudio.transforms as T  # Преобразования аудиосигнала\n",
        "import os  # Работа с файлами\n",
        "import json  # Сохранение метаданных о сценах\n",
        "from torchvision import models, transforms  # Работа с изображениями для ResNet"
      ],
      "metadata": {
        "id": "6lGUaQ4VejD3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "класс предназначен для анализа видео и сегментации на сцены с использованием:\n",
        "\n",
        "Детекции объектов (YOLOv8)\n",
        "Трекинга объектов (DeepSORT)\n",
        "Идентификации лиц (FaceNet)\n",
        "Анализа аудио (Whisper + MFCC)\n",
        "NLP-анализа текста (zero-shot classification)\n",
        "Кластеризации и обнаружения переходов между сценами"
      ],
      "metadata": {
        "id": "byMJdj8tgQ0B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SceneSegmenter:\n",
        "    def __init__(self, device=None, lang='ru'):\n",
        "        self.device = device if device else ('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        self.model = YOLO('yolov8n.pt').to(self.device)\n",
        "\n",
        "        # Используем ResNet18 без последнего слоя как feature extractor\n",
        "        resnet = models.resnet18(pretrained=True)\n",
        "        self.feature_extractor = nn.Sequential(*list(resnet.children())[:-1])\n",
        "        self.feature_extractor = self.feature_extractor.to(self.device).eval()\n",
        "\n",
        "        # Трансформации для ResNet\n",
        "        self.transform = transforms.Compose([\n",
        "            transforms.ToPILImage(),\n",
        "            transforms.Resize((224, 224)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "        ])\n",
        "\n",
        "        # DeepSORT для трекинга объектов\n",
        "        self.tracker = DeepSort(max_age=30)\n",
        "\n",
        "        # FaceNet для идентификации лиц\n",
        "        self.face_net = InceptionResnetV1(pretrained='vggface2').eval().to(self.device)\n",
        "\n",
        "        # Хранилища\n",
        "        self.visual_features = []\n",
        "        self.scenes = []\n",
        "        self.lang = lang\n",
        "\n",
        "        # Whisper для распознавания речи\n",
        "        self.whisper_model = whisper.load_model(\"base\", device=self.device)\n",
        "\n",
        "        # NLP модель для анализа текста (русский)\n",
        "        self.nlp_pipeline = pipeline(\n",
        "            \"zero-shot-classification\",\n",
        "            model=\"cointegrated/rubert-tiny2\",\n",
        "            device=0 if self.device == 'cuda' else -1\n",
        "        )\n",
        "\n",
        "    def extract_frame_features(self, frame):\n",
        "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "        frame_tensor = self.transform(frame).unsqueeze(0).to(self.device)\n",
        "        with torch.no_grad():\n",
        "            features = self.feature_extractor(frame_tensor)\n",
        "        return features.squeeze().cpu().numpy()\n",
        "\n",
        "    def extract_audio_features(self, audio_path):\n",
        "        waveform, sample_rate = torchaudio.load(audio_path)\n",
        "        mfcc = T.MFCC(sample_rate=sample_rate)(waveform)\n",
        "        energy = waveform.pow(2).mean(dim=1).sqrt().item()\n",
        "        return {\n",
        "            'mfcc': mfcc.mean(dim=1),\n",
        "            'energy': energy,\n",
        "        }\n",
        "\n",
        "    def extract_visual_features(self, frame):\n",
        "        results = self.model(frame)\n",
        "\n",
        "        boxes = results[0].boxes.xyxy.cpu() if results[0].boxes is not None else None\n",
        "        confs = results[0].boxes.conf.cpu() if results[0].boxes is not None else None\n",
        "        classes = results[0].boxes.cls.cpu() if results[0].boxes is not None else None\n",
        "\n",
        "        if boxes is None or len(boxes) == 0:\n",
        "            raw_detections = []\n",
        "        else:\n",
        "            boxes_np = boxes.numpy()\n",
        "            if boxes_np.ndim == 1:\n",
        "                boxes_np = boxes_np.reshape(1, 4)\n",
        "            boxes_np = boxes_np.astype(np.float32)\n",
        "\n",
        "            confs_np = confs.numpy()\n",
        "            if confs_np.ndim == 0:\n",
        "                confs_np = confs_np.reshape(1)\n",
        "            confs_np = confs_np.astype(np.float32)\n",
        "\n",
        "            classes_np = classes.numpy()\n",
        "            if classes_np.ndim == 0:\n",
        "                classes_np = classes_np.reshape(1)\n",
        "            classes_np = classes_np.astype(np.int64)\n",
        "\n",
        "            raw_detections = []\n",
        "            for i in range(len(boxes_np)):\n",
        "                box = boxes_np[i]\n",
        "                conf = confs_np[i]\n",
        "                cls = classes_np[i]\n",
        "                raw_detections.append((box, conf, cls))\n",
        "\n",
        "        tracks = self.tracker.update_tracks(raw_detections, frame=frame)\n",
        "\n",
        "        face_embeddings = []\n",
        "        for track in tracks:\n",
        "            if track.get_class() == 0:  # class 0 — это 'person'\n",
        "                x1, y1, x2, y2 = map(int, track.to_ltrb())\n",
        "                face = frame[y1:y2, x1:x2]\n",
        "                if face.size > 0:\n",
        "                    face_img = Image.fromarray(cv2.cvtColor(face, cv2.COLOR_BGR2RGB))\n",
        "                    face_tensor = torch.tensor(np.array(face_img)).permute(2, 0, 1).unsqueeze(0).float().to(self.device)\n",
        "                    embedding = self.face_net(face_tensor).detach().cpu()\n",
        "                    face_embeddings.append(embedding)\n",
        "\n",
        "        hist = cv2.calcHist([frame], [0, 1, 2], None, [8, 8, 8], [0, 256, 0, 256, 0, 256])\n",
        "        hist = cv2.normalize(hist, hist).flatten()\n",
        "\n",
        "        return {\n",
        "            'histogram': hist,\n",
        "            'face_embeddings': face_embeddings,\n",
        "            'tracks': tracks\n",
        "        }\n",
        "\n",
        "    def transcribe_audio(self, audio_path):\n",
        "        result = self.whisper_model.transcribe(audio_path, language=self.lang)\n",
        "        segments = result['segments']\n",
        "        subtitle_data = []\n",
        "        for seg in segments:\n",
        "            start = int(seg['start'])\n",
        "            end = int(seg['end'])\n",
        "            text = seg['text'].strip()\n",
        "            subtitle_data.append((start, end, text))\n",
        "        return subtitle_data\n",
        "\n",
        "    def analyze_text_change(self, prev_text, curr_text):\n",
        "        if not prev_text or not curr_text:\n",
        "            return False\n",
        "        labels = ['диалог', 'вступление', 'вывод', 'действие', 'описание']\n",
        "        try:\n",
        "            res_prev = self.nlp_pipeline(prev_text, labels)\n",
        "            res_curr = self.nlp_pipeline(curr_text, labels)\n",
        "            return res_prev['labels'][0] != res_curr['labels'][0]\n",
        "        except:\n",
        "            return False\n",
        "\n",
        "    def process_video(self, video_path, use_whisper=True):\n",
        "        cap = cv2.VideoCapture(video_path)\n",
        "        fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "        frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "        duration = frame_count / fps\n",
        "\n",
        "        # Извлечь аудио\n",
        "        audio_path = \"temp_audio.wav\"\n",
        "        os.system(f\"ffmpeg -y -i {video_path} -vn -acodec pcm_s16le -ar 16000 {audio_path}\")\n",
        "\n",
        "        # Распознать субтитры\n",
        "        subtitle_data = self.transcribe_audio(audio_path) if use_whisper else []\n",
        "\n",
        "        # Извлечь аудио-признаки\n",
        "        audio_features = []\n",
        "        for i in range(int(duration)):\n",
        "            audio_features.append(self.extract_audio_features(audio_path))\n",
        "\n",
        "        prev_features = None\n",
        "        scene_start = 0\n",
        "        prev_subtitle = \"\"\n",
        "        prev_frame_features = None\n",
        "\n",
        "        for i in range(frame_count):\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                break\n",
        "\n",
        "            if i % int(fps) == 0:\n",
        "                frame_features = self.extract_frame_features(frame)\n",
        "                visual_features = self.extract_visual_features(frame)\n",
        "                self.visual_features.append(visual_features)\n",
        "\n",
        "                curr_time = i // fps\n",
        "                curr_energy = audio_features[curr_time]['energy']\n",
        "                energy_change = abs(curr_energy - audio_features[curr_time - 1]['energy']) if curr_time > 0 else 0\n",
        "\n",
        "                curr_subtitle = \"\"\n",
        "                for start, end, text in subtitle_data:\n",
        "                    if start <= curr_time <= end:\n",
        "                        curr_subtitle = text\n",
        "                        break\n",
        "\n",
        "                if prev_frame_features is not None:\n",
        "                    feature_change = cosine(prev_frame_features, frame_features)\n",
        "                    face_change = self.detect_dialog_change(prev_features, visual_features)\n",
        "                    text_change = self.analyze_text_change(prev_subtitle, curr_subtitle) if curr_subtitle else False\n",
        "                    energy_jump = energy_change > 0.05\n",
        "\n",
        "                    if feature_change > 0.2 or face_change or text_change or energy_jump:\n",
        "                        self.scenes.append((scene_start, i, prev_subtitle))\n",
        "                        scene_start = i\n",
        "                        prev_subtitle = curr_subtitle\n",
        "\n",
        "                prev_frame_features = frame_features\n",
        "                prev_features = visual_features\n",
        "\n",
        "        self.scenes.append((scene_start, frame_count, prev_subtitle))\n",
        "        cap.release()\n",
        "        self.cluster_scenes()\n",
        "        return self.scenes\n",
        "\n",
        "    def detect_dialog_change(self, prev, current):\n",
        "        if not prev['face_embeddings'] or not current['face_embeddings']:\n",
        "            return False\n",
        "        prev_main = prev['face_embeddings'][0].squeeze().numpy()\n",
        "        curr_main = current['face_embeddings'][0].squeeze().numpy()\n",
        "        return cosine(prev_main, curr_main) > 0.3\n",
        "\n",
        "    def cluster_scenes(self):\n",
        "        features = [feat['histogram'] for feat in self.visual_features]\n",
        "        clustering = DBSCAN(eps=0.5, min_samples=2).fit(features)\n",
        "\n",
        "        merged_scenes = []\n",
        "        current_label = clustering.labels_[0]\n",
        "        start, _, text = self.scenes[0]\n",
        "\n",
        "        for i, label in enumerate(clustering.labels_[1:], 1):\n",
        "            if label != current_label:\n",
        "                merged_scenes.append((start, self.scenes[i][1], self.scenes[i - 1][2]))\n",
        "                start = self.scenes[i][0]\n",
        "                current_label = label\n",
        "        merged_scenes.append((start, self.scenes[-1][1], self.scenes[-1][2]))\n",
        "        self.scenes = merged_scenes\n",
        "\n",
        "    def save_scenes(self, video_path, output_dir):\n",
        "        os.makedirs(output_dir, exist_ok=True)\n",
        "        os.makedirs(os.path.join(output_dir, 'videos'), exist_ok=True)\n",
        "\n",
        "        cap = cv2.VideoCapture(video_path)\n",
        "        fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "\n",
        "        scene_data = []\n",
        "\n",
        "        for i, (start, end, text) in enumerate(self.scenes):\n",
        "            video_out_path = os.path.join(output_dir, 'videos', f'scene_{i}.mp4')\n",
        "            fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "            out = cv2.VideoWriter(video_out_path, fourcc, fps, (width, height))\n",
        "\n",
        "            cap.set(cv2.CAP_PROP_POS_FRAMES, start)\n",
        "            for _ in range(start, end):\n",
        "                ret, frame = cap.read()\n",
        "                if not ret:\n",
        "                    break\n",
        "                if text:\n",
        "                    frame = self.draw_text_on_frame(frame, text)\n",
        "                out.write(frame)\n",
        "            out.release()\n",
        "\n",
        "            scene_data.append({\n",
        "                'scene_id': i,\n",
        "                'start_frame': start,\n",
        "                'end_frame': end,\n",
        "                'start_time': start / fps,\n",
        "                'end_time': end / fps,\n",
        "                'subtitle': text\n",
        "            })\n",
        "\n",
        "        # Сохранить JSON\n",
        "        json_path = os.path.join(output_dir, 'scenes.json')\n",
        "        with open(json_path, 'w', encoding='utf-8') as f:\n",
        "            json.dump(scene_data, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "    def draw_text_on_frame(self, frame, text, font_scale=0.7, thickness=2, color=(255, 255, 255), bg_color=(0, 0, 0)):\n",
        "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
        "        padding = 10\n",
        "        margin = 10\n",
        "        frame_height = frame.shape[0]\n",
        "        max_line_width = frame.shape[1] - 2 * margin\n",
        "\n",
        "        words = text.split(' ')\n",
        "        lines = []\n",
        "        line = ''\n",
        "        for word in words:\n",
        "            test_line = line + word + ' '\n",
        "            (text_width, text_height) = cv2.getTextSize(test_line, font, fontScale=font_scale, thickness=thickness)[0]\n",
        "            if text_width > max_line_width:\n",
        "                lines.append(line)\n",
        "                line = word + ' '\n",
        "            else:\n",
        "                line += word + ' '\n",
        "        lines.append(line)\n",
        "\n",
        "        total_height = len(lines) * (text_height + 5)\n",
        "        cv2.rectangle(frame, (margin, frame_height - total_height - padding),\n",
        "                      (frame.shape[1] - margin, frame_height - padding), bg_color, -1)\n",
        "\n",
        "        y = frame_height - total_height\n",
        "        for line in lines:\n",
        "            y += text_height + 5\n",
        "            cv2.putText(frame, line.strip(), (margin + 5, y), font, font_scale, color, thickness, cv2.LINE_AA)\n",
        "\n",
        "        return frame"
      ],
      "metadata": {
        "id": "txxRO2zChZzG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "video_path = '30 секунд (2023)_1080p.mp4'\n",
        "segmenter = SceneSegmenter(lang='ru')  # Поддержка русского языка\n",
        "scenes = segmenter.process_video(video_path, use_whisper=True)\n",
        "print(f\"Найдено сцен: {len(scenes)}\")\n",
        "segmenter.save_scenes(video_path, 'output_scenes')"
      ],
      "metadata": {
        "id": "Yx0hfXJ1hZwm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "from IPython.display import HTML, display\n",
        "from base64 import b64encode\n",
        "\n",
        "def show_video(path):\n",
        "    mp4 = open(path, 'rb').read()\n",
        "    data_url = \"video/mp4;base64,\" + b64encode(mp4).decode()\n",
        "    display(HTML(f\"\"\"<video width=320 controls><source src=\"{data_url}\" type=\"video/mp4\"></video>\"\"\"))\n",
        "\n",
        "files = sorted(glob.glob('output_scenes/videos/*.mp4'))[:3]\n",
        "for f in files:\n",
        "    print(f\"Сцена: {f}\")\n",
        "    show_video(f)"
      ],
      "metadata": {
        "id": "kAxGdC0bhZte"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('output_scenes/scenes.json', 'r', encoding='utf-8') as f:\n",
        "    scenes_json = json.load(f)\n",
        "    print(\"\\nJSON с информацией о сценах:\")\n",
        "    print(json.dumps(scenes_json, ensure_ascii=False, indent=2))"
      ],
      "metadata": {
        "id": "t_gOZXEPhZqs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "t-1ph5CihZn4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ESMjBQa5hZlC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "u7ktepMShZiQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yGSurnsjhZfT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yfZZq3LVhZcM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QVSyjw3ihZZY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "haAiYj5EhZWr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Z4iQFRPKhZTm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SX8-LtlOhZRE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PFI68GUyhZOO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "r1ZfqM6WhZLg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4wNMzT8HhZJC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oLOQF2exhZGU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "A4pXwlq8hZDe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AJ6Bti8ghZAo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mtRLEY3DhY9a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jTHDHbRQhYzV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KL7sG6RZdx7H"
      },
      "outputs": [],
      "source": [
        "# 2. Импорт библиотек\n",
        "import cv2  # Работа с видео и кадрами\n",
        "import numpy as np  # Работа с массивами\n",
        "import torch  # Работа с моделями на PyTorch\n",
        "import torch.nn as nn  # Нейросетевые слои\n",
        "import whisper  # Распознавание речи\n",
        "from ultralytics import YOLO  # YOLO для детекции объектов\n",
        "from deep_sort_realtime.deepsort_tracker import DeepSort  # Трекинг объектов\n",
        "from facenet_pytorch import InceptionResnetV1  # FaceNet для идентификации лиц\n",
        "from sklearn.cluster import DBSCAN  # Кластеризация сцен\n",
        "from scipy.spatial.distance import cosine  # Сравнение эмбеддингов\n",
        "from transformers import pipeline  # NLP-модель для анализа текста\n",
        "import torchaudio  # Работа с аудио\n",
        "import torchaudio.transforms as T  # Преобразования аудиосигнала\n",
        "import os  # Работа с файлами\n",
        "import json  # Сохранение метаданных о сценах\n",
        "from torchvision import models, transforms  # Работа с изображениями для ResNet\n",
        "\n",
        "class SceneSegmenter:\n",
        "    def __init__(self, device=None, lang='ru'):\n",
        "        \"\"\"\n",
        "        Инициализация сегментатора видео.\n",
        "        \"\"\"\n",
        "        self.device = device if device else ('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        self.model = YOLO('yolov8n.pt').to(self.device)  # YOLO для детекции объектов\n",
        "\n",
        "        # Используем ResNet18 без последнего слоя как feature extractor\n",
        "        resnet = models.resnet18(pretrained=True)\n",
        "        self.feature_extractor = nn.Sequential(*list(resnet.children())[:-1])\n",
        "        self.feature_extractor = self.feature_extractor.to(self.device).eval()\n",
        "\n",
        "        # Трансформации для ResNet\n",
        "        self.transform = transforms.Compose([\n",
        "            transforms.ToPILImage(),\n",
        "            transforms.Resize((224, 224)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "        ])\n",
        "\n",
        "        # DeepSORT для трекинга объектов\n",
        "        self.tracker = DeepSort(max_age=30)\n",
        "\n",
        "        # FaceNet для идентификации лиц\n",
        "        self.face_net = InceptionResnetV1(pretrained='vggface2').eval().to(self.device)\n",
        "\n",
        "        # Хранилища для признаков и сцен\n",
        "        self.visual_features = []\n",
        "        self.scenes = []\n",
        "\n",
        "        # Язык для распознавания речи\n",
        "        self.lang = lang\n",
        "\n",
        "        # Whisper для распознавания речи\n",
        "        self.whisper_model = whisper.load_model(\"base\", device=self.device)\n",
        "\n",
        "        # NLP модель для анализа текста (русский)\n",
        "        self.nlp_pipeline = pipeline(\n",
        "            \"zero-shot-classification\",\n",
        "            model=\"cointegrated/rubert-tiny2\",\n",
        "            device=0 if self.device == 'cuda' else -1\n",
        "        )\n",
        "\n",
        "    def extract_frame_features(self, frame):\n",
        "        \"\"\"\n",
        "        Извлечение фичей кадра с помощью ResNet18 без выходного слоя.\n",
        "        \"\"\"\n",
        "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)  # Конвертируем в RGB\n",
        "        frame_tensor = self.transform(frame).unsqueeze(0).to(self.device)  # Применяем трансформации\n",
        "        with torch.no_grad():\n",
        "            features = self.feature_extractor(frame_tensor)  # Получаем фичи\n",
        "        return features.squeeze().cpu().numpy()  # Возвращаем в виде numpy-массива\n",
        "\n",
        "    def extract_audio_features(self, audio_path):\n",
        "        \"\"\"\n",
        "        Извлечение аудиопризнаков: энергия и MFCC\n",
        "        \"\"\"\n",
        "        waveform, sample_rate = torchaudio.load(audio_path)\n",
        "        mfcc = T.MFCC(sample_rate=sample_rate)(waveform)\n",
        "        energy = waveform.pow(2).mean(dim=1).sqrt().item()  # Энергия аудио\n",
        "        return {\n",
        "            'mfcc': mfcc.mean(dim=1),\n",
        "            'energy': energy,\n",
        "        }\n",
        "\n",
        "    def extract_visual_features(self, frame):\n",
        "        \"\"\"\n",
        "        Детекция объектов и лиц на кадре.\n",
        "        \"\"\"\n",
        "        results = self.model(frame)\n",
        "\n",
        "        boxes = results[0].boxes.xyxy.cpu() if results[0].boxes is not None else None\n",
        "        confs = results[0].boxes.conf.cpu() if results[0].boxes is not None else None\n",
        "        classes = results[0].boxes.cls.cpu() if results[0].boxes is not None else None\n",
        "\n",
        "        # Подготовка данных для DeepSort\n",
        "        if boxes is None or len(boxes) == 0:\n",
        "            raw_detections = []\n",
        "        else:\n",
        "            boxes_np = boxes.numpy()\n",
        "            if boxes_np.ndim == 1:\n",
        "                boxes_np = boxes_np.reshape(1, 4)\n",
        "            boxes_np = boxes_np.astype(np.float32)\n",
        "\n",
        "            confs_np = confs.numpy()\n",
        "            if confs_np.ndim == 0:\n",
        "                confs_np = confs_np.reshape(1)\n",
        "            confs_np = confs_np.astype(np.float32)\n",
        "\n",
        "            classes_np = classes.numpy()\n",
        "            if classes_np.ndim == 0:\n",
        "                classes_np = classes_np.reshape(1)\n",
        "            classes_np = classes_np.astype(np.int64)\n",
        "\n",
        "            raw_detections = []\n",
        "            for i in range(len(boxes_np)):\n",
        "                box = boxes_np[i]\n",
        "                conf = confs_np[i]\n",
        "                cls = classes_np[i]\n",
        "                raw_detections.append((box, conf, cls))\n",
        "\n",
        "        # Обновление трекинга\n",
        "        tracks = self.tracker.update_tracks(raw_detections, frame=frame)\n",
        "\n",
        "        # Извлечение лиц\n",
        "        face_embeddings = []\n",
        "        for track in tracks:\n",
        "            if track.get_class() == 0:  # class 0 — это 'person'\n",
        "                x1, y1, x2, y2 = map(int, track.to_ltrb())\n",
        "                face = frame[y1:y2, x1:x2]\n",
        "                if face.size > 0:\n",
        "                    face_img = Image.fromarray(cv2.cvtColor(face, cv2.COLOR_BGR2RGB))\n",
        "                    face_tensor = torch.tensor(np.array(face_img)).permute(2, 0, 1).unsqueeze(0).float().to(self.device)\n",
        "                    embedding = self.face_net(face_tensor).detach().cpu()\n",
        "                    face_embeddings.append(embedding)\n",
        "\n",
        "        # Гистограмма цвета кадра\n",
        "        hist = cv2.calcHist([frame], [0, 1, 2], None, [8, 8, 8], [0, 256, 0, 256, 0, 256])\n",
        "        hist = cv2.normalize(hist, hist).flatten()\n",
        "\n",
        "        return {\n",
        "            'histogram': hist,\n",
        "            'face_embeddings': face_embeddings,\n",
        "            'tracks': tracks\n",
        "        }\n",
        "\n",
        "    def transcribe_audio(self, audio_path):\n",
        "        \"\"\"\n",
        "        Распознавание речи через Whisper.\n",
        "        \"\"\"\n",
        "        result = self.whisper_model.transcribe(audio_path, language=self.lang)\n",
        "        segments = result['segments']\n",
        "        subtitle_data = []\n",
        "        for seg in segments:\n",
        "            start = int(seg['start'])\n",
        "            end = int(seg['end'])\n",
        "            text = seg['text'].strip()\n",
        "            subtitle_data.append((start, end, text))\n",
        "        return subtitle_data\n",
        "\n",
        "    def analyze_text_change(self, prev_text, curr_text):\n",
        "        \"\"\"\n",
        "        Анализ смены темы диалога с помощью NLP.\n",
        "        \"\"\"\n",
        "        if not prev_text or not curr_text:\n",
        "            return False\n",
        "        labels = ['диалог', 'вступление', 'вывод', 'действие', 'описание']\n",
        "        try:\n",
        "            res_prev = self.nlp_pipeline(prev_text, labels)\n",
        "            res_curr = self.nlp_pipeline(curr_text, labels)\n",
        "            return res_prev['labels'][0] != res_curr['labels'][0]\n",
        "        except:\n",
        "            return False\n",
        "\n",
        "    def process_video(self, video_path, use_whisper=True):\n",
        "        \"\"\"\n",
        "        Основной процесс обработки видео.\n",
        "        \"\"\"\n",
        "        cap = cv2.VideoCapture(video_path)\n",
        "        fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "        frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "        duration = frame_count / fps\n",
        "\n",
        "        # Извлечение аудио\n",
        "        audio_path = \"temp_audio.wav\"\n",
        "        os.system(f\"ffmpeg -y -i {video_path} -vn -acodec pcm_s16le -ar 16000 {audio_path}\")\n",
        "\n",
        "        # Распознавание субтитров\n",
        "        subtitle_data = self.transcribe_audio(audio_path) if use_whisper else []\n",
        "\n",
        "        # Извлечение аудио-признаков\n",
        "        audio_features = []\n",
        "        for i in range(int(duration)):\n",
        "            audio_features.append(self.extract_audio_features(audio_path))\n",
        "\n",
        "        prev_features = None\n",
        "        scene_start = 0\n",
        "        prev_subtitle = \"\"\n",
        "        prev_frame_features = None\n",
        "\n",
        "        # Обработка кадров\n",
        "        for i in range(frame_count):\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                break\n",
        "\n",
        "            if i % int(fps) == 0:  # Обрабатываем 1 кадр в секунду\n",
        "                frame_features = self.extract_frame_features(frame)\n",
        "                visual_features = self.extract_visual_features(frame)\n",
        "                self.visual_features.append(visual_features)\n",
        "\n",
        "                curr_time = i // fps\n",
        "                curr_energy = audio_features[curr_time]['energy']\n",
        "                energy_change = abs(curr_energy - audio_features[curr_time - 1]['energy']) if curr_time > 0 else 0\n",
        "\n",
        "                # Получаем текущий текст из субтитров\n",
        "                curr_subtitle = \"\"\n",
        "                for start, end, text in subtitle_data:\n",
        "                    if start <= curr_time <= end:\n",
        "                        curr_subtitle = text\n",
        "                        break\n",
        "\n",
        "                # Обнаружение смены сцены\n",
        "                if prev_frame_features is not None:\n",
        "                    feature_change = cosine(prev_frame_features, frame_features)\n",
        "                    face_change = self.detect_dialog_change(prev_features, visual_features)\n",
        "                    text_change = self.analyze_text_change(prev_subtitle, curr_subtitle) if curr_subtitle else False\n",
        "                    energy_jump = energy_change > 0.05\n",
        "\n",
        "                    if feature_change > 0.2 or face_change or text_change or energy_jump:\n",
        "                        self.scenes.append((scene_start, i, prev_subtitle))\n",
        "                        scene_start = i\n",
        "                        prev_subtitle = curr_subtitle\n",
        "\n",
        "                prev_frame_features = frame_features\n",
        "                prev_features = visual_features\n",
        "\n",
        "        self.scenes.append((scene_start, frame_count, prev_subtitle))\n",
        "        cap.release()\n",
        "\n",
        "        self.cluster_scenes()\n",
        "        return self.scenes\n",
        "\n",
        "    def detect_dialog_change(self, prev, current):\n",
        "        \"\"\"\n",
        "        Обнаружение смены персонажа по лицам.\n",
        "        \"\"\"\n",
        "        if not prev['face_embeddings'] or not current['face_embeddings']:\n",
        "            return False\n",
        "        prev_main = prev['face_embeddings'][0].squeeze().numpy()\n",
        "        curr_main = current['face_embeddings'][0].squeeze().numpy()\n",
        "        return cosine(prev_main, curr_main) > 0.3\n",
        "\n",
        "    def cluster_scenes(self):\n",
        "        \"\"\"\n",
        "        Кластеризация сцен по цветовой гистограмме.\n",
        "        \"\"\"\n",
        "        features = [feat['histogram'] for feat in self.visual_features]\n",
        "        clustering = DBSCAN(eps=0.5, min_samples=2).fit(features)\n",
        "\n",
        "        merged_scenes = []\n",
        "        current_label = clustering.labels_[0]\n",
        "        start, _, text = self.scenes[0]\n",
        "\n",
        "        for i, label in enumerate(clustering.labels_[1:], 1):\n",
        "            if label != current_label:\n",
        "                merged_scenes.append((start, self.scenes[i][1], self.scenes[i - 1][2]))\n",
        "                start = self.scenes[i][0]\n",
        "                current_label = label\n",
        "        merged_scenes.append((start, self.scenes[-1][1], self.scenes[-1][2]))\n",
        "        self.scenes = merged_scenes\n",
        "\n",
        "    def save_scenes(self, video_path, output_dir):\n",
        "        \"\"\"\n",
        "        Сохранение сцен как видеофайлов и JSON с метаданными.\n",
        "        \"\"\"\n",
        "        os.makedirs(output_dir, exist_ok=True)\n",
        "        os.makedirs(os.path.join(output_dir, 'videos'), exist_ok=True)\n",
        "\n",
        "        cap = cv2.VideoCapture(video_path)\n",
        "        fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "\n",
        "        scene_data = []\n",
        "\n",
        "        for i, (start, end, text) in enumerate(self.scenes):\n",
        "            video_out_path = os.path.join(output_dir, 'videos', f'scene_{i}.mp4')\n",
        "            fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "            out = cv2.VideoWriter(video_out_path, fourcc, fps, (width, height))\n",
        "\n",
        "            cap.set(cv2.CAP_PROP_POS_FRAMES, start)\n",
        "            for _ in range(start, end):\n",
        "                ret, frame = cap.read()\n",
        "                if not ret:\n",
        "                    break\n",
        "                if text:\n",
        "                    frame = self.draw_text_on_frame(frame, text)\n",
        "                out.write(frame)\n",
        "            out.release()\n",
        "\n",
        "            scene_data.append({\n",
        "                'scene_id': i,\n",
        "                'start_frame': start,\n",
        "                'end_frame': end,\n",
        "                'start_time': start / fps,\n",
        "                'end_time': end / fps,\n",
        "                'subtitle': text\n",
        "            })\n",
        "\n",
        "        # Сохранение JSON\n",
        "        json_path = os.path.join(output_dir, 'scenes.json')\n",
        "        with open(json_path, 'w', encoding='utf-8') as f:\n",
        "            json.dump(scene_data, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "    def draw_text_on_frame(self, frame, text, font_scale=0.7, thickness=2, color=(255, 255, 255), bg_color=(0, 0, 0)):\n",
        "        \"\"\"\n",
        "        Добавление субтитров на кадр.\n",
        "        \"\"\"\n",
        "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
        "        padding = 10\n",
        "        margin = 10\n",
        "        frame_height = frame.shape[0]\n",
        "        max_line_width = frame.shape[1] - 2 * margin\n",
        "\n",
        "        # Разбивка текста на строки\n",
        "        words = text.split(' ')\n",
        "        lines = []\n",
        "        line = ''\n",
        "        for word in words:\n",
        "            test_line = line + word + ' '\n",
        "            (text_width, text_height) = cv2.getTextSize(test_line, font, fontScale=font_scale, thickness=thickness)[0]\n",
        "            if text_width > max_line_width:\n",
        "                lines.append(line)\n",
        "                line = word + ' '\n",
        "            else:\n",
        "                line += word + ' '\n",
        "        lines.append(line)\n",
        "\n",
        "        # Вычисление высоты текста\n",
        "        total_height = len(lines) * (text_height + 5)\n",
        "\n",
        "        # Отрисовка фона\n",
        "        cv2.rectangle(frame, (margin, frame_height - total_height - padding),\n",
        "                      (frame.shape[1] - margin, frame_height - padding), bg_color, -1)\n",
        "\n",
        "        # Отрисовка текста\n",
        "        y = frame_height - total_height\n",
        "        for line in lines:\n",
        "            y += text_height + 5\n",
        "            cv2.putText(frame, line.strip(), (margin + 5, y), font, font_scale, color, thickness, cv2.LINE_AA)\n",
        "\n",
        "        return frame\n",
        "\n",
        "# 3. Пример использования\n",
        "video_path = '30 секунд (2023)_1080p.mp4'\n",
        "segmenter = SceneSegmenter(lang='ru')  # Создаём сегментатор\n",
        "scenes = segmenter.process_video(video_path, use_whisper=True)  # Обрабатываем видео\n",
        "print(f\"Найдено сцен: {len(scenes)}\")\n",
        "segmenter.save_scenes(video_path, 'output_scenes')  # Сохраняем сцены\n",
        "\n",
        "# 4. Просмотр первых 3 сцен\n",
        "import glob\n",
        "from IPython.display import HTML, display\n",
        "from base64 import b64encode\n",
        "\n",
        "def show_video(path):\n",
        "    mp4 = open(path, 'rb').read()\n",
        "    data_url = \"video/mp4;base64,\" + b64encode(mp4).decode()\n",
        "    display(HTML(f\"\"\"<video width=320 controls><source src=\"{data_url}\" type=\"video/mp4\"></video>\"\"\"))\n",
        "\n",
        "files = sorted(glob.glob('output_scenes/videos/*.mp4'))[:3]\n",
        "for f in files:\n",
        "    print(f\"Сцена: {f}\")\n",
        "    show_video(f)\n",
        "\n",
        "# 5. Вывод JSON с метаданными\n",
        "with open('output_scenes/scenes.json', 'r', encoding='utf-8') as f:\n",
        "    scenes_json = json.load(f)\n",
        "    print(\"\\nJSON с информацией о сценах:\")\n",
        "    print(json.dumps(scenes_json, ensure_ascii=False, indent=2))\n"
      ]
    }
  ]
}