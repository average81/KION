{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyObKgBk6XVWC5CUj043Xnew",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/average81/KION/blob/scene_segmentation/Hakaton_4_0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Комплексный анализ:\n",
        "\n",
        "Видео: через анализ изменения контента\n",
        "\n",
        "Аудио: через спектральный анализ\n",
        "\n",
        "Субтитры: через семантическую схожесть\n",
        "\n",
        "Объекты: через YOLO + ByteTrack\n",
        "\n",
        "Гибкие настройки:\n",
        "\n",
        "Весовые коэффициенты для каждого типа анализа\n",
        "\n",
        "Настраиваемые пороги детекции\n",
        "\n",
        "Поддержка русского языка для субтитров\n",
        "\n",
        "Визуализация результатов:\n",
        "\n",
        "График временной шкалы сценами\n",
        "\n",
        "Подробный текстовый вывод\n",
        "\n",
        "Оптимизации:\n",
        "\n",
        "Эффективный трекинг объектов\n",
        "\n",
        "Пакетная обработка данных\n",
        "\n",
        "Четкое разделение этапов анализа\n",
        "\n",
        "Как использовать:\n",
        "Установите зависимости: pip install -r requirements.txt\n",
        "\n",
        "Поместите видео и субтитры в одну папку\n",
        "\n",
        "Укажите пути к файлам в конце скрипта\n",
        "\n",
        "Запустите: python scene_analysis.py"
      ],
      "metadata": {
        "id": "STWlOpX1B0Dh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download ru_core_news_md\n",
        "!pip install -q torch torchvision torchaudio\n",
        "!pip install -q opencv-python pytube moviepy pydub scenedetect[opencv] transformers\n",
        "!pip install -q ultralytics\n",
        "!pip install -q git+https://github.com/facebookresearch/detectron2.git\n",
        "!pip install -q librosa pandas matplotlib seaborn\n",
        "!pip install -q speechrecognition\n",
        "!pip install opencv-python numpy ultralytics scenedetect librosa spacy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DCfJA0gENUz1",
        "outputId": "fe86adde-c174-4855-a950-ece8521d5436"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ru-core-news-md==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/ru_core_news_md-3.8.0/ru_core_news_md-3.8.0-py3-none-any.whl (41.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.9/41.9 MB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pymorphy3>=1.0.0 (from ru-core-news-md==3.8.0)\n",
            "  Downloading pymorphy3-2.0.4-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting dawg2-python>=0.8.0 (from pymorphy3>=1.0.0->ru-core-news-md==3.8.0)\n",
            "  Downloading dawg2_python-0.9.0-py3-none-any.whl.metadata (7.5 kB)\n",
            "Collecting pymorphy3-dicts-ru (from pymorphy3>=1.0.0->ru-core-news-md==3.8.0)\n",
            "  Downloading pymorphy3_dicts_ru-2.4.417150.4580142-py2.py3-none-any.whl.metadata (2.0 kB)\n",
            "Downloading pymorphy3-2.0.4-py3-none-any.whl (54 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.1/54.1 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dawg2_python-0.9.0-py3-none-any.whl (9.3 kB)\n",
            "Downloading pymorphy3_dicts_ru-2.4.417150.4580142-py2.py3-none-any.whl (8.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m82.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pymorphy3-dicts-ru, dawg2-python, pymorphy3, ru-core-news-md\n",
            "Successfully installed dawg2-python-0.9.0 pymorphy3-2.0.4 pymorphy3-dicts-ru-2.4.417150.4580142 ru-core-news-md-3.8.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('ru_core_news_md')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m43.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m43.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m36.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m41.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.6/131.6 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.3/81.3 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m57.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for detectron2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m32.9/32.9 MB\u001b[0m \u001b[31m65.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.12.0.88)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: ultralytics in /usr/local/lib/python3.11/dist-packages (8.3.169)\n",
            "Requirement already satisfied: scenedetect in /usr/local/lib/python3.11/dist-packages (0.6.6)\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.11/dist-packages (0.11.0)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.11/dist-packages (3.8.7)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (11.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.16.0)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.21.0+cu124)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.2.2)\n",
            "Requirement already satisfied: ultralytics-thop>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.0.14)\n",
            "Requirement already satisfied: Click in /usr/local/lib/python3.11/dist-packages (from scenedetect) (8.2.1)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from scenedetect) (4.3.8)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.11/dist-packages (from librosa) (3.0.1)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.60.0)\n",
            "Requirement already satisfied: scikit-learn>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.6.1)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.5.1)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.13.1)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.5.0.post1)\n",
            "Requirement already satisfied: typing_extensions>=4.1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (4.14.1)\n",
            "Requirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.1.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.13)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.10)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (8.3.6)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.16.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.11.7)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy) (75.2.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (25.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.5.0)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.59.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.51.0->librosa) (0.43.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2025.7.14)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.1.0->librosa) (3.6.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile>=0.12.1->librosa) (1.17.1)\n",
            "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.0)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2025.7.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.21.1)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.3.0.post1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy) (3.0.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.22)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.19.2)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import re\n",
        "import chardet\n",
        "from dataclasses import dataclass\n",
        "from typing import List, Tuple, Dict\n",
        "from collections import defaultdict\n",
        "from statistics import mean\n",
        "import matplotlib.pyplot as plt\n",
        "import librosa\n",
        "import spacy\n",
        "from scenedetect import VideoManager, SceneManager, ContentDetector\n",
        "from ultralytics import YOLO\n",
        "from moviepy.editor import VideoFileClip\n",
        "import subprocess\n",
        "import warnings\n",
        "import matplotlib.pyplot as plt\n",
        "from pytube import YouTube\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "0UuJwAyEYAP2"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Весовые коэффициенты и параметры\n",
        "WEIGHTS = {\n",
        "    'video': 0.5,               # вес для видео-анализа (ContentDetector)\n",
        "    'audio': 0.3,               # вес для аудио-анализа\n",
        "    'subtitles': 0.2,           # вес для анализа субтитров\n",
        "    'min_duration': 10.0,        # минимальная длительность сцены (сек)\n",
        "    'max_duration': 600.0,      # максимальная длительность сцены (сек)\n",
        "    'rms_threshold': 0.3,       # порог для RMS энергии в аудио\n",
        "    'centroid_threshold': 0.4,  # порог для спектрального центроида\n",
        "    'sub_min_duration': 10.0,   # мин. длительность сцены по субтитрам\n",
        "    'sub_time_gap': 3.0,        # макс. разрыв между репликами (сек)\n",
        "    'sub_similarity': 0.55,     # порог семантической схожести текста\n",
        "}\n",
        "\n",
        "def download_youtube_video(url, output_path='./video.mp4'):\n",
        "    yt = YouTube(url)\n",
        "    stream = yt.streams.filter(file_extension='mp4', progressive=True).order_by('resolution').desc().first()\n",
        "    stream.download(output_path=os.path.dirname(output_path), filename=os.path.basename(output_path))\n",
        "    return output_path\n",
        "\n",
        "def extract_audio_with_ffmpeg(video_path, audio_path='audio.wav'):\n",
        "    cmd = ['ffmpeg', '-i', video_path, '-vn', '-acodec', 'pcm_s16le', audio_path]\n",
        "    proc = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
        "    out, err = proc.communicate()\n",
        "    try:\n",
        "        print(err.decode('utf-8'))\n",
        "    except UnicodeDecodeError:\n",
        "        print(err.decode('latin-1'))\n",
        "    return audio_path\n",
        "\n",
        "def extract_audio(video_path, audio_path='audio.wav'):\n",
        "    video = VideoFileClip(video_path)\n",
        "    audio = video.audio\n",
        "    audio.write_audiofile(audio_path, codec='pcm_s16le')\n",
        "    return audio_path\n",
        "\n",
        "def analyze_audio(audio_path, frame_length=2048, hop_length=512):\n",
        "    y, sr = librosa.load(audio_path)\n",
        "    rms = librosa.feature.rms(y=y, frame_length=frame_length, hop_length=hop_length)[0]\n",
        "    rms_normalized = (rms - np.min(rms)) / (np.max(rms) - np.min(rms))\n",
        "\n",
        "    spectral_centroid = librosa.feature.spectral_centroid(y=y, sr=sr, n_fft=frame_length, hop_length=hop_length)[0]\n",
        "    spectral_centroid_normalized = (spectral_centroid - np.min(spectral_centroid)) / (np.max(spectral_centroid) - np.min(spectral_centroid))\n",
        "\n",
        "    zcr = librosa.feature.zero_crossing_rate(y, frame_length=frame_length, hop_length=hop_length)[0]\n",
        "    times = librosa.times_like(rms, sr=sr, hop_length=hop_length, n_fft=frame_length)\n",
        "\n",
        "    return {\n",
        "        'times': times,\n",
        "        'rms': rms_normalized,\n",
        "        'spectral_centroid': spectral_centroid_normalized,\n",
        "        'zcr': zcr\n",
        "    }\n",
        "\n",
        "def plot_audio_features(audio_features):\n",
        "    plt.figure(figsize=(15, 10))\n",
        "    plt.subplot(3, 1, 1)\n",
        "    plt.plot(audio_features['times'], audio_features['rms'], label='RMS Energy')\n",
        "    plt.title('Normalized RMS Energy')\n",
        "    plt.xlabel('Time (s)')\n",
        "    plt.ylabel('Amplitude')\n",
        "\n",
        "    plt.subplot(3, 1, 2)\n",
        "    plt.plot(audio_features['times'], audio_features['spectral_centroid'], label='Spectral Centroid', color='orange')\n",
        "    plt.title('Normalized Spectral Centroid')\n",
        "    plt.xlabel('Time (s)')\n",
        "    plt.ylabel('Frequency')\n",
        "\n",
        "    plt.subplot(3, 1, 3)\n",
        "    plt.plot(audio_features['times'], audio_features['zcr'], label='Zero Crossing Rate', color='green')\n",
        "    plt.title('Zero Crossing Rate')\n",
        "    plt.xlabel('Time (s)')\n",
        "    plt.ylabel('Rate')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def detect_video_scenes(video_path, threshold=30.0):\n",
        "    video = VideoManager([video_path])\n",
        "    scene_manager = SceneManager()\n",
        "    scene_manager.add_detector(ContentDetector(threshold=threshold))\n",
        "    video.set_downscale_factor()\n",
        "    video.start()\n",
        "    scene_manager.detect_scenes(frame_source=video)\n",
        "    scene_list = scene_manager.get_scene_list()\n",
        "    scenes = [(scene[0].get_seconds(), scene[1].get_seconds()) for scene in scene_list]\n",
        "    return scenes\n",
        "\n",
        "def detect_audio_scenes(audio_features):\n",
        "    times = audio_features['times']\n",
        "    rms = audio_features['rms']\n",
        "    spectral_centroid = audio_features['spectral_centroid']\n",
        "    scenes = []\n",
        "    current_scene_start = 0.0\n",
        "\n",
        "    for i in range(1, len(times)):\n",
        "        rms_change = abs(rms[i] - rms[i-1])\n",
        "        centroid_change = abs(spectral_centroid[i] - spectral_centroid[i-1])\n",
        "\n",
        "        if rms_change > WEIGHTS['rms_threshold'] or centroid_change > WEIGHTS['centroid_threshold']:\n",
        "            scene_duration = times[i] - current_scene_start\n",
        "            if scene_duration >= WEIGHTS['min_duration']:\n",
        "                scenes.append((current_scene_start, times[i]))\n",
        "                current_scene_start = times[i]\n",
        "\n",
        "    if current_scene_start < times[-1]:\n",
        "        scenes.append((current_scene_start, times[-1]))\n",
        "    return scenes\n",
        "\n",
        "def extract_embedded_subtitles(video_path, output_srt_path='embedded_subtitles.srt'):\n",
        "    \"\"\"Извлекает встроенные субтитры из видеофайла с помощью ffmpeg\"\"\"\n",
        "    try:\n",
        "        cmd = [\n",
        "            'ffmpeg',\n",
        "            '-i', video_path,\n",
        "            '-map', '0:s:0',\n",
        "            '-c:s', 'srt',\n",
        "            output_srt_path\n",
        "        ]\n",
        "        subprocess.run(cmd, check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
        "\n",
        "        if os.path.exists(output_srt_path) and os.path.getsize(output_srt_path) > 0:\n",
        "            print(f\"Извлечены встроенные субтитры в {output_srt_path}\")\n",
        "            return output_srt_path\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        print(f\"Не удалось извлечь встроенные субтитры: {e}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Ошибка при извлечении субтитров: {e}\")\n",
        "    return None\n",
        "\n",
        "def process_subtitles(srt_file_path):\n",
        "    def read_srt_file(file_path):\n",
        "        try:\n",
        "            with open(file_path, 'r', encoding='utf-8') as file:\n",
        "                return file.read()\n",
        "        except UnicodeDecodeError:\n",
        "            with open(file_path, 'r', encoding='cp1251') as file:\n",
        "                return file.read()\n",
        "\n",
        "    def parse_srt(srt_text):\n",
        "        subtitles = []\n",
        "        blocks = re.split(r'\\n\\s*\\n', srt_text.strip())\n",
        "\n",
        "        for block in blocks:\n",
        "            lines = block.strip().split('\\n')\n",
        "            if len(lines) < 3:\n",
        "                continue\n",
        "\n",
        "            try:\n",
        "                index = int(lines[0])\n",
        "                time_match = re.match(r'(\\d{2}):(\\d{2}):(\\d{2}),(\\d{3}) --> (\\d{2}):(\\d{2}):(\\d{2}),(\\d{3})', lines[1])\n",
        "                if not time_match:\n",
        "                    continue\n",
        "\n",
        "                h1, m1, s1, ms1 = map(int, time_match.groups()[:4])\n",
        "                h2, m2, s2, ms2 = map(int, time_match.groups()[4:8])\n",
        "                start = h1 * 3600 + m1 * 60 + s1 + ms1 / 1000\n",
        "                end = h2 * 3600 + m2 * 60 + s2 + ms2 / 1000\n",
        "                text = '\\n'.join(lines[2:])\n",
        "                subtitles.append({'start': start, 'end': end, 'text': text})\n",
        "            except Exception as e:\n",
        "                continue\n",
        "\n",
        "        return subtitles\n",
        "\n",
        "    def group_into_scenes(subtitles):\n",
        "        if not subtitles:\n",
        "            return []\n",
        "\n",
        "        scenes = []\n",
        "        current_scene = [subtitles[0]]\n",
        "\n",
        "        for prev, curr in zip(subtitles, subtitles[1:]):\n",
        "            time_gap = curr['start'] - prev['end']\n",
        "            if time_gap > WEIGHTS['sub_time_gap']:\n",
        "                scenes.append(current_scene)\n",
        "                current_scene = [curr]\n",
        "            else:\n",
        "                current_scene.append(curr)\n",
        "\n",
        "        scenes.append(current_scene)\n",
        "        scene_boundaries = []\n",
        "\n",
        "        for scene in scenes:\n",
        "            scene_start = scene[0]['start']\n",
        "            scene_end = scene[-1]['end']\n",
        "            if scene_end - scene_start >= WEIGHTS['sub_min_duration']:\n",
        "                scene_boundaries.append((scene_start, scene_end))\n",
        "\n",
        "        return scene_boundaries\n",
        "\n",
        "    srt_text = read_srt_file(srt_file_path)\n",
        "    subtitles = parse_srt(srt_text)\n",
        "    return group_into_scenes(subtitles), subtitles\n",
        "\n",
        "def merge_scenes(video_scenes, audio_scenes, subtitle_scenes=None):\n",
        "    weighted_scenes = []\n",
        "\n",
        "    for start, end in video_scenes:\n",
        "        duration = end - start\n",
        "        if duration >= WEIGHTS['min_duration']:\n",
        "            weighted_scenes.append({\n",
        "                'start': start,\n",
        "                'end': end,\n",
        "                'weight': WEIGHTS['video'],\n",
        "                'type': 'video'\n",
        "            })\n",
        "\n",
        "    for start, end in audio_scenes:\n",
        "        duration = end - start\n",
        "        if duration >= WEIGHTS['min_duration']:\n",
        "            weighted_scenes.append({\n",
        "                'start': start,\n",
        "                'end': end,\n",
        "                'weight': WEIGHTS['audio'],\n",
        "                'type': 'audio'\n",
        "            })\n",
        "\n",
        "    if subtitle_scenes:\n",
        "        for start, end in subtitle_scenes:\n",
        "            duration = end - start\n",
        "            if duration >= WEIGHTS['min_duration']:\n",
        "                weighted_scenes.append({\n",
        "                    'start': start,\n",
        "                    'end': end,\n",
        "                    'weight': WEIGHTS['subtitles'],\n",
        "                    'type': 'subtitles'\n",
        "                })\n",
        "\n",
        "    if not weighted_scenes:\n",
        "        return []\n",
        "\n",
        "    weighted_scenes.sort(key=lambda x: x['start'])\n",
        "    merged_scenes = []\n",
        "    current_scene = weighted_scenes[0].copy()\n",
        "\n",
        "    for scene in weighted_scenes[1:]:\n",
        "        scene_overlap = (scene['start'] <= current_scene['end'] + 2.0)\n",
        "        duration_exceeded = (scene['end'] - current_scene['start']) > WEIGHTS['max_duration']\n",
        "\n",
        "        if scene_overlap and not duration_exceeded:\n",
        "            if scene['type'] == 'video' and current_scene['type'] != 'video':\n",
        "                current_scene['end'] = scene['end']\n",
        "                current_scene['weight'] += scene['weight']\n",
        "                current_scene['type'] = 'mixed'\n",
        "            elif scene['weight'] > current_scene['weight']:\n",
        "                current_scene['end'] = scene['end']\n",
        "                current_scene['weight'] += scene['weight']\n",
        "                if scene['type'] != current_scene['type']:\n",
        "                    current_scene['type'] = 'mixed'\n",
        "            else:\n",
        "                current_scene['end'] = max(current_scene['end'], scene['end'])\n",
        "                current_scene['weight'] += scene['weight'] * 0.5\n",
        "        else:\n",
        "            if current_scene['end'] - current_scene['start'] >= WEIGHTS['min_duration']:\n",
        "                merged_scenes.append((current_scene['start'], current_scene['end']))\n",
        "            current_scene = scene.copy()\n",
        "\n",
        "    if current_scene['end'] - current_scene['start'] >= WEIGHTS['min_duration']:\n",
        "        merged_scenes.append((current_scene['start'], current_scene['end']))\n",
        "\n",
        "    merged_scenes = [(start, end) for start, end in merged_scenes\n",
        "                    if end - start >= WEIGHTS['min_duration']]\n",
        "    return merged_scenes\n",
        "\n",
        "def track_objects(video_path, output_path='output_tracked.mp4'):\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
        "    model = YOLO('yolov8l.pt')\n",
        "    tracks_info = defaultdict(list)\n",
        "    frame_count = 0\n",
        "\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        results = model.track(frame, persist=True, tracker=\"bytetrack.yaml\")\n",
        "        annotated_frame = results[0].plot()\n",
        "\n",
        "        if results[0].boxes.id is not None:\n",
        "            for box, track_id in zip(results[0].boxes, results[0].boxes.id):\n",
        "                x1, y1, x2, y2 = box.xyxy[0].tolist()\n",
        "                conf = box.conf[0].item()\n",
        "                cls = box.cls[0].item()\n",
        "\n",
        "                tracks_info[int(track_id)].append({\n",
        "                    'frame': frame_count,\n",
        "                    'time': frame_count / fps,\n",
        "                    'bbox': [x1, y1, x2, y2],\n",
        "                    'confidence': conf,\n",
        "                    'class': cls\n",
        "                })\n",
        "\n",
        "        out.write(annotated_frame)\n",
        "        frame_count += 1\n",
        "\n",
        "    cap.release()\n",
        "    out.release()\n",
        "    return tracks_info, output_path\n",
        "\n",
        "def final_scene_segmentation(merged_scenes, tracks_info, subtitles=None):\n",
        "    final_scenes = []\n",
        "\n",
        "    for scene_start, scene_end in merged_scenes:\n",
        "        if scene_end - scene_start < WEIGHTS['min_duration']:\n",
        "            continue\n",
        "\n",
        "        scene_tracks = {}\n",
        "        for track_id, track_data in tracks_info.items():\n",
        "            objects_in_scene = [obj for obj in track_data if scene_start <= obj['time'] <= scene_end]\n",
        "            if objects_in_scene:\n",
        "                scene_tracks[track_id] = objects_in_scene\n",
        "\n",
        "        scene_text = \"\"\n",
        "        if subtitles:\n",
        "            for sub in subtitles:\n",
        "                if scene_start <= sub['start'] <= scene_end or scene_start <= sub['end'] <= scene_end:\n",
        "                    scene_text += sub['text'] + \" \"\n",
        "\n",
        "        final_scenes.append({\n",
        "            'start': scene_start,\n",
        "            'end': scene_end,\n",
        "            'duration': scene_end - scene_start,\n",
        "            'objects': scene_tracks,\n",
        "            'text': scene_text.strip() if scene_text else None\n",
        "        })\n",
        "\n",
        "    return final_scenes\n",
        "\n",
        "def visualize_scenes(final_scenes, video_path):\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    duration = cap.get(cv2.CAP_PROP_POS_MSEC) / 1000\n",
        "    cap.release()\n",
        "\n",
        "    plt.figure(figsize=(15, 5))\n",
        "    for i, scene in enumerate(final_scenes):\n",
        "        plt.axvspan(scene['start'], scene['end'], alpha=0.3, color=f'C{i}', label=f'Scene {i+1}')\n",
        "    plt.title('Video Scene Segmentation')\n",
        "    plt.xlabel('Time (seconds)')\n",
        "    plt.ylabel('Scenes')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "def save_scenes_as_videos(video_path, final_scenes, output_dir='./scenes'):\n",
        "    if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "\n",
        "    video_name = os.path.splitext(os.path.basename(video_path))[0]\n",
        "\n",
        "    for i, scene in enumerate(final_scenes):\n",
        "        output_path = os.path.join(output_dir, f\"{video_name}_scene_{i+1}.mp4\")\n",
        "        clip = VideoFileClip(video_path).subclip(scene['start'], scene['end'])\n",
        "        clip.write_videofile(output_path, codec='libx264', audio_codec='aac')\n",
        "        print(f\"Saved scene {i+1} to {output_path}\")\n",
        "\n",
        "def generate_report(final_scenes, output_path='report.csv'):\n",
        "    def determine_scene_category(scene):\n",
        "        object_classes = []\n",
        "        for track_data in scene['objects'].values():\n",
        "            for obj in track_data:\n",
        "                object_classes.append(obj['class'])\n",
        "\n",
        "        text = scene.get('text', '')\n",
        "        text_length = len(text.split()) if text else 0\n",
        "\n",
        "        if text_length > 30 and len(object_classes) < 3:\n",
        "            return \"Диалог\"\n",
        "        elif len(object_classes) > 5:\n",
        "            return \"Экшен\"\n",
        "        elif any(cls in [0, 1, 2, 3, 5, 7] for cls in object_classes):\n",
        "            return \"Персонажи\"\n",
        "        elif text_length > 10:\n",
        "            return \"Диалог/Наррация\"\n",
        "        else:\n",
        "            return \"Пейзаж/Обстановка\"\n",
        "\n",
        "    report_data = []\n",
        "    for i, scene in enumerate(final_scenes):\n",
        "        category = determine_scene_category(scene)\n",
        "        scene_text = scene.get('text', '')\n",
        "        if len(scene_text) > 200:\n",
        "            scene_text = scene_text[:200] + \"...\"\n",
        "\n",
        "        scene_info = {\n",
        "            '№ сцены': i + 1,\n",
        "            'Время начала': f\"{scene['start']:.2f}\",\n",
        "            'Время конца': f\"{scene['end']:.2f}\",\n",
        "            'Длительность (сек)': f\"{scene['duration']:.2f}\",\n",
        "            'Текст': scene_text,\n",
        "            'Категория': category,\n",
        "            'Объектов': len(scene['objects'])\n",
        "        }\n",
        "        report_data.append(scene_info)\n",
        "\n",
        "    df = pd.DataFrame(report_data)\n",
        "    columns_order = ['№ сцены', 'Время начала', 'Время конца', 'Длительность (сек)',\n",
        "                    'Категория', 'Объектов', 'Текст']\n",
        "    df = df[columns_order]\n",
        "    df.to_csv(output_path, index=False, encoding='utf-8-sig')\n",
        "    print(f\"Отчет сохранен в {output_path}\")\n",
        "    return df\n",
        "\n",
        "def main(video_path='mister-i-missis-smit-2005.mp4', srt_path=None):\n",
        "    # 1. Извлечение аудио\n",
        "    audio_path = extract_audio(video_path)\n",
        "    audio_features = analyze_audio(audio_path)\n",
        "    plot_audio_features(audio_features)\n",
        "\n",
        "    # 2. Детекция сцен\n",
        "    video_scenes = detect_video_scenes(video_path)\n",
        "    audio_scenes = detect_audio_scenes(audio_features)\n",
        "\n",
        "    # 3. Обработка субтитров\n",
        "    subtitle_scenes, subtitles = None, None\n",
        "\n",
        "    if srt_path and os.path.exists(srt_path):\n",
        "        print(f\"Используется внешний файл субтитров: {srt_path}\")\n",
        "        subtitle_scenes, subtitles = process_subtitles(srt_path)\n",
        "    else:\n",
        "        embedded_srt = extract_embedded_subtitles(video_path)\n",
        "        if embedded_srt:\n",
        "            print(\"Используются встроенные субтитры\")\n",
        "            subtitle_scenes, subtitles = process_subtitles(embedded_srt)\n",
        "        else:\n",
        "            print(\"Субтитры не найдены, анализ будет без учета субтитров\")\n",
        "\n",
        "    # 4. Объединение сцен\n",
        "    merged_scenes = merge_scenes(video_scenes, audio_scenes, subtitle_scenes)\n",
        "\n",
        "    # 5. Трекинг объектов\n",
        "    tracks_info, _ = track_objects(video_path)\n",
        "\n",
        "    # 6. Финальная сегментация\n",
        "    final_scenes = final_scene_segmentation(merged_scenes, tracks_info, subtitles)\n",
        "\n",
        "    # 7. Визуализация и сохранение результатов\n",
        "    visualize_scenes(final_scenes, video_path)\n",
        "    save_scenes_as_videos(video_path, final_scenes)\n",
        "    report_df = generate_report(final_scenes)\n",
        "\n",
        "    return final_scenes, report_df\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Пример использования:\n",
        "    # С внешними субтитрами\n",
        "    # final_scenes, report = main(video_path='video.mp4', srt_path='subtitles.srt')\n",
        "\n",
        "    # С автоматическим определением субтитров\n",
        "    final_scenes, report = main(video_path='S1E01 - Pilot.mkv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "4OY-GCARlueQ",
        "outputId": "f9dde169-592c-45db-c94c-899432045957"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "t:  76%|███████▌  | 392/518 [01:00<00:16,  7.80it/s, now=None]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Writing audio in audio.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "chunk:   0%|          | 0/29264 [00:00<?, ?it/s, now=None]\u001b[A\n",
            "chunk:   1%|          | 286/29264 [00:00<00:10, 2855.45it/s, now=None]\u001b[A\n",
            "chunk:   2%|▏         | 572/29264 [00:00<00:10, 2613.44it/s, now=None]\u001b[A\n",
            "chunk:   3%|▎         | 856/29264 [00:00<00:10, 2677.37it/s, now=None]\u001b[A\n",
            "chunk:   4%|▍         | 1143/29264 [00:00<00:10, 2749.48it/s, now=None]\u001b[A\n",
            "chunk:   5%|▍         | 1419/29264 [00:00<00:10, 2553.57it/s, now=None]\u001b[A\n",
            "chunk:   6%|▌         | 1709/29264 [00:00<00:10, 2613.46it/s, now=None]\u001b[A\n",
            "chunk:   7%|▋         | 1995/29264 [00:00<00:10, 2688.09it/s, now=None]\u001b[A\n",
            "chunk:   8%|▊         | 2266/29264 [00:00<00:10, 2680.09it/s, now=None]\u001b[A\n",
            "chunk:   9%|▊         | 2548/29264 [00:00<00:09, 2720.52it/s, now=None]\u001b[A\n",
            "chunk:  10%|▉         | 2821/29264 [00:01<00:09, 2666.04it/s, now=None]\u001b[A\n",
            "chunk:  11%|█         | 3089/29264 [00:01<00:09, 2617.75it/s, now=None]\u001b[A\n",
            "chunk:  11%|█▏        | 3355/29264 [00:01<00:09, 2626.27it/s, now=None]\u001b[A\n",
            "chunk:  12%|█▏        | 3622/29264 [00:01<00:09, 2638.20it/s, now=None]\u001b[A\n",
            "chunk:  13%|█▎        | 3904/29264 [00:01<00:09, 2690.85it/s, now=None]\u001b[A\n",
            "chunk:  14%|█▍        | 4174/29264 [00:01<00:09, 2521.75it/s, now=None]\u001b[A\n",
            "chunk:  15%|█▌        | 4450/29264 [00:01<00:09, 2588.06it/s, now=None]\u001b[A\n",
            "chunk:  16%|█▌        | 4722/29264 [00:01<00:09, 2596.49it/s, now=None]\u001b[A\n",
            "chunk:  17%|█▋        | 5000/29264 [00:01<00:09, 2647.91it/s, now=None]\u001b[A\n",
            "chunk:  18%|█▊        | 5272/29264 [00:01<00:08, 2668.45it/s, now=None]\u001b[A\n",
            "chunk:  19%|█▉        | 5540/29264 [00:02<00:08, 2645.60it/s, now=None]\u001b[A\n",
            "chunk:  20%|█▉        | 5815/29264 [00:02<00:08, 2675.66it/s, now=None]\u001b[A\n",
            "chunk:  21%|██        | 6084/29264 [00:02<00:08, 2676.23it/s, now=None]\u001b[A\n",
            "chunk:  22%|██▏       | 6364/29264 [00:02<00:08, 2711.81it/s, now=None]\u001b[A\n",
            "chunk:  23%|██▎       | 6636/29264 [00:02<00:08, 2641.36it/s, now=None]\u001b[A\n",
            "chunk:  24%|██▎       | 6901/29264 [00:02<00:08, 2538.04it/s, now=None]\u001b[A\n",
            "chunk:  25%|██▍       | 7182/29264 [00:02<00:08, 2594.63it/s, now=None]\u001b[A\n",
            "chunk:  25%|██▌       | 7459/29264 [00:02<00:08, 2644.60it/s, now=None]\u001b[A\n",
            "chunk:  26%|██▋       | 7733/29264 [00:02<00:08, 2671.29it/s, now=None]\u001b[A\n",
            "chunk:  27%|██▋       | 8001/29264 [00:03<00:08, 2649.01it/s, now=None]\u001b[A\n",
            "chunk:  28%|██▊       | 8287/29264 [00:03<00:07, 2659.65it/s, now=None]\u001b[A\n",
            "chunk:  29%|██▉       | 8554/29264 [00:03<00:09, 2261.26it/s, now=None]\u001b[A\n",
            "chunk:  30%|███       | 8791/29264 [00:03<00:09, 2148.73it/s, now=None]\u001b[A\n",
            "chunk:  31%|███       | 9014/29264 [00:03<00:09, 2059.56it/s, now=None]\u001b[A\n",
            "chunk:  32%|███▏      | 9225/29264 [00:03<00:10, 1961.18it/s, now=None]\u001b[A\n",
            "chunk:  32%|███▏      | 9425/29264 [00:03<00:10, 1941.07it/s, now=None]\u001b[A\n",
            "chunk:  33%|███▎      | 9622/29264 [00:03<00:10, 1942.71it/s, now=None]\u001b[A\n",
            "chunk:  34%|███▎      | 9818/29264 [00:03<00:10, 1924.89it/s, now=None]\u001b[A\n",
            "chunk:  34%|███▍      | 10012/29264 [00:04<00:10, 1905.24it/s, now=None]\u001b[A\n",
            "chunk:  35%|███▍      | 10204/29264 [00:04<00:10, 1858.60it/s, now=None]\u001b[A\n",
            "chunk:  36%|███▌      | 10395/29264 [00:04<00:10, 1846.55it/s, now=None]\u001b[A\n",
            "chunk:  36%|███▌      | 10596/29264 [00:04<00:10, 1861.64it/s, now=None]\u001b[A\n",
            "chunk:  37%|███▋      | 10797/29264 [00:04<00:09, 1884.96it/s, now=None]\u001b[A\n",
            "chunk:  38%|███▊      | 10998/29264 [00:04<00:09, 1909.52it/s, now=None]\u001b[A\n",
            "chunk:  38%|███▊      | 11190/29264 [00:04<00:09, 1859.52it/s, now=None]\u001b[A\n",
            "chunk:  39%|███▉      | 11377/29264 [00:04<00:10, 1745.24it/s, now=None]\u001b[A\n",
            "chunk:  39%|███▉      | 11553/29264 [00:04<00:10, 1677.97it/s, now=None]\u001b[A\n",
            "chunk:  40%|████      | 11751/29264 [00:05<00:10, 1733.81it/s, now=None]\u001b[A\n",
            "chunk:  41%|████      | 11952/29264 [00:05<00:09, 1780.00it/s, now=None]\u001b[A\n",
            "chunk:  41%|████▏     | 12131/29264 [00:05<00:09, 1775.92it/s, now=None]\u001b[A\n",
            "chunk:  42%|████▏     | 12323/29264 [00:05<00:09, 1816.97it/s, now=None]\u001b[A\n",
            "chunk:  43%|████▎     | 12506/29264 [00:05<00:09, 1814.75it/s, now=None]\u001b[A\n",
            "chunk:  43%|████▎     | 12705/29264 [00:05<00:09, 1819.41it/s, now=None]\u001b[A\n",
            "chunk:  44%|████▍     | 12906/29264 [00:05<00:08, 1823.38it/s, now=None]\u001b[A\n",
            "chunk:  45%|████▍     | 13089/29264 [00:05<00:09, 1758.07it/s, now=None]\u001b[A\n",
            "chunk:  45%|████▌     | 13266/29264 [00:05<00:09, 1727.69it/s, now=None]\u001b[A\n",
            "chunk:  46%|████▌     | 13454/29264 [00:06<00:08, 1770.87it/s, now=None]\u001b[A\n",
            "chunk:  47%|████▋     | 13639/29264 [00:06<00:08, 1793.26it/s, now=None]\u001b[A\n",
            "chunk:  47%|████▋     | 13819/29264 [00:06<00:08, 1758.22it/s, now=None]\u001b[A\n",
            "chunk:  48%|████▊     | 13996/29264 [00:06<00:08, 1729.03it/s, now=None]\u001b[A\n",
            "chunk:  48%|████▊     | 14170/29264 [00:06<00:08, 1721.26it/s, now=None]\u001b[A\n",
            "chunk:  49%|████▉     | 14353/29264 [00:06<00:08, 1752.54it/s, now=None]\u001b[A\n",
            "chunk:  50%|████▉     | 14529/29264 [00:06<00:08, 1738.80it/s, now=None]\u001b[A\n",
            "chunk:  50%|█████     | 14713/29264 [00:06<00:08, 1761.18it/s, now=None]\u001b[A\n",
            "chunk:  51%|█████     | 14945/29264 [00:06<00:07, 1925.77it/s, now=None]\u001b[A\n",
            "chunk:  52%|█████▏    | 15197/29264 [00:06<00:06, 2100.20it/s, now=None]\u001b[A\n",
            "chunk:  53%|█████▎    | 15459/29264 [00:07<00:06, 2254.48it/s, now=None]\u001b[A\n",
            "chunk:  54%|█████▎    | 15724/29264 [00:07<00:05, 2372.33it/s, now=None]\u001b[A\n",
            "chunk:  55%|█████▍    | 15969/29264 [00:07<00:05, 2386.92it/s, now=None]\u001b[A\n",
            "chunk:  55%|█████▌    | 16239/29264 [00:07<00:05, 2479.98it/s, now=None]\u001b[A\n",
            "chunk:  56%|█████▋    | 16513/29264 [00:07<00:04, 2556.40it/s, now=None]\u001b[A\n",
            "chunk:  57%|█████▋    | 16772/29264 [00:07<00:04, 2524.71it/s, now=None]\u001b[A\n",
            "chunk:  58%|█████▊    | 17045/29264 [00:07<00:04, 2583.95it/s, now=None]\u001b[A\n",
            "chunk:  59%|█████▉    | 17304/29264 [00:07<00:04, 2581.54it/s, now=None]\u001b[A\n",
            "chunk:  60%|██████    | 17563/29264 [00:07<00:04, 2512.79it/s, now=None]\u001b[A\n",
            "chunk:  61%|██████    | 17815/29264 [00:07<00:04, 2470.12it/s, now=None]\u001b[A\n",
            "chunk:  62%|██████▏   | 18072/29264 [00:08<00:04, 2499.06it/s, now=None]\u001b[A\n",
            "chunk:  63%|██████▎   | 18326/29264 [00:08<00:04, 2509.16it/s, now=None]\u001b[A\n",
            "chunk:  63%|██████▎   | 18579/29264 [00:08<00:04, 2494.67it/s, now=None]\u001b[A\n",
            "chunk:  64%|██████▍   | 18863/29264 [00:08<00:04, 2594.98it/s, now=None]\u001b[A\n",
            "chunk:  65%|██████▌   | 19132/29264 [00:08<00:03, 2582.49it/s, now=None]\u001b[A\n",
            "chunk:  66%|██████▋   | 19391/29264 [00:08<00:03, 2579.31it/s, now=None]\u001b[A\n",
            "chunk:  67%|██████▋   | 19662/29264 [00:08<00:03, 2616.41it/s, now=None]\u001b[A\n",
            "chunk:  68%|██████▊   | 19933/29264 [00:08<00:03, 2642.82it/s, now=None]\u001b[A\n",
            "chunk:  69%|██████▉   | 20198/29264 [00:08<00:03, 2592.66it/s, now=None]\u001b[A\n",
            "chunk:  70%|██████▉   | 20458/29264 [00:08<00:03, 2496.52it/s, now=None]\u001b[A\n",
            "chunk:  71%|███████   | 20733/29264 [00:09<00:03, 2568.43it/s, now=None]\u001b[A\n",
            "chunk:  72%|███████▏  | 20993/29264 [00:09<00:03, 2576.94it/s, now=None]\u001b[A\n",
            "chunk:  73%|███████▎  | 21252/29264 [00:09<00:03, 2509.60it/s, now=None]\u001b[A\n",
            "chunk:  74%|███████▎  | 21526/29264 [00:09<00:03, 2576.24it/s, now=None]\u001b[A\n",
            "chunk:  74%|███████▍  | 21793/29264 [00:09<00:02, 2588.03it/s, now=None]\u001b[A\n",
            "chunk:  75%|███████▌  | 22057/29264 [00:09<00:02, 2602.56it/s, now=None]\u001b[A\n",
            "chunk:  76%|███████▋  | 22329/29264 [00:09<00:02, 2635.98it/s, now=None]\u001b[A\n",
            "chunk:  77%|███████▋  | 22596/29264 [00:09<00:02, 2614.14it/s, now=None]\u001b[A\n",
            "chunk:  78%|███████▊  | 22866/29264 [00:09<00:02, 2637.93it/s, now=None]\u001b[A\n",
            "chunk:  79%|███████▉  | 23131/29264 [00:10<00:02, 2528.41it/s, now=None]\u001b[A\n",
            "chunk:  80%|███████▉  | 23391/29264 [00:10<00:02, 2548.41it/s, now=None]\u001b[A\n",
            "chunk:  81%|████████  | 23647/29264 [00:10<00:02, 2533.23it/s, now=None]\u001b[A\n",
            "chunk:  82%|████████▏ | 23905/29264 [00:10<00:02, 2541.24it/s, now=None]\u001b[A\n",
            "chunk:  83%|████████▎ | 24184/29264 [00:10<00:01, 2613.70it/s, now=None]\u001b[A\n",
            "chunk:  84%|████████▎ | 24454/29264 [00:10<00:01, 2607.86it/s, now=None]\u001b[A\n",
            "chunk:  84%|████████▍ | 24716/29264 [00:10<00:01, 2599.75it/s, now=None]\u001b[A\n",
            "chunk:  85%|████████▌ | 24980/29264 [00:10<00:01, 2610.29it/s, now=None]\u001b[A\n",
            "chunk:  86%|████████▋ | 25257/29264 [00:10<00:01, 2643.79it/s, now=None]\u001b[A\n",
            "chunk:  87%|████████▋ | 25522/29264 [00:10<00:01, 2622.78it/s, now=None]\u001b[A\n",
            "chunk:  88%|████████▊ | 25785/29264 [00:11<00:01, 2501.79it/s, now=None]\u001b[A\n",
            "chunk:  89%|████████▉ | 26047/29264 [00:11<00:01, 2534.42it/s, now=None]\u001b[A\n",
            "chunk:  90%|████████▉ | 26302/29264 [00:11<00:01, 2518.20it/s, now=None]\u001b[A\n",
            "chunk:  91%|█████████ | 26566/29264 [00:11<00:01, 2552.69it/s, now=None]\u001b[A\n",
            "chunk:  92%|█████████▏| 26854/29264 [00:11<00:00, 2647.73it/s, now=None]\u001b[A\n",
            "chunk:  93%|█████████▎| 27120/29264 [00:11<00:00, 2558.98it/s, now=None]\u001b[A\n",
            "chunk:  94%|█████████▎| 27391/29264 [00:11<00:00, 2600.89it/s, now=None]\u001b[A\n",
            "chunk:  95%|█████████▍| 27667/29264 [00:11<00:00, 2606.99it/s, now=None]\u001b[A\n",
            "chunk:  95%|█████████▌| 27935/29264 [00:11<00:00, 2627.42it/s, now=None]\u001b[A\n",
            "chunk:  96%|█████████▋| 28204/29264 [00:11<00:00, 2644.62it/s, now=None]\u001b[A\n",
            "chunk:  97%|█████████▋| 28469/29264 [00:12<00:00, 2380.86it/s, now=None]\u001b[A\n",
            "chunk:  98%|█████████▊| 28713/29264 [00:12<00:00, 2282.83it/s, now=None]\u001b[A\n",
            "chunk:  99%|█████████▉| 28973/29264 [00:12<00:00, 2350.92it/s, now=None]\u001b[A\n",
            "t:  76%|███████▌  | 392/518 [01:12<00:16,  7.80it/s, now=None]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x1000 with 3 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:pyscenedetect:VideoManager is deprecated and will be removed.\n",
            "INFO:pyscenedetect:Loaded 1 video, framerate: 23.976 FPS, resolution: 1908 x 1068\n",
            "INFO:pyscenedetect:Detecting scenes...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Speed: 3.4ms preprocess, 27.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 wine glass, 1 cup, 1 potted plant, 1 vase, 26.6ms\n",
            "Speed: 3.8ms preprocess, 26.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 wine glass, 1 cup, 1 potted plant, 1 vase, 26.6ms\n",
            "Speed: 3.2ms preprocess, 26.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 wine glass, 1 cup, 1 potted plant, 1 vase, 27.7ms\n",
            "Speed: 3.3ms preprocess, 27.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 wine glass, 1 cup, 1 potted plant, 1 vase, 27.1ms\n",
            "Speed: 3.3ms preprocess, 27.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 wine glass, 1 cup, 1 potted plant, 1 vase, 26.8ms\n",
            "Speed: 3.7ms preprocess, 26.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 wine glass, 1 cup, 1 potted plant, 1 vase, 26.6ms\n",
            "Speed: 8.4ms preprocess, 26.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 wine glass, 1 cup, 1 potted plant, 1 vase, 27.1ms\n",
            "Speed: 3.8ms preprocess, 27.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 wine glass, 1 cup, 1 potted plant, 1 vase, 27.0ms\n",
            "Speed: 3.3ms preprocess, 27.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 wine glass, 1 cup, 1 potted plant, 1 vase, 26.3ms\n",
            "Speed: 3.4ms preprocess, 26.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 wine glass, 1 cup, 1 potted plant, 1 vase, 26.3ms\n",
            "Speed: 3.2ms preprocess, 26.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 wine glass, 1 cup, 1 potted plant, 1 vase, 26.3ms\n",
            "Speed: 3.2ms preprocess, 26.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 wine glass, 1 cup, 1 potted plant, 1 vase, 26.4ms\n",
            "Speed: 5.5ms preprocess, 26.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 wine glass, 1 cup, 1 potted plant, 1 vase, 26.3ms\n",
            "Speed: 3.3ms preprocess, 26.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 wine glass, 1 cup, 1 potted plant, 1 vase, 26.4ms\n",
            "Speed: 3.4ms preprocess, 26.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 wine glass, 1 cup, 1 potted plant, 1 vase, 26.3ms\n",
            "Speed: 3.4ms preprocess, 26.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 wine glass, 1 cup, 1 potted plant, 1 vase, 26.5ms\n",
            "Speed: 3.4ms preprocess, 26.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 wine glass, 1 cup, 1 potted plant, 1 vase, 26.4ms\n",
            "Speed: 3.4ms preprocess, 26.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 wine glass, 1 cup, 1 potted plant, 1 vase, 26.3ms\n",
            "Speed: 5.4ms preprocess, 26.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 wine glass, 1 cup, 1 potted plant, 1 vase, 26.3ms\n",
            "Speed: 3.3ms preprocess, 26.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 wine glass, 1 cup, 1 potted plant, 1 vase, 26.3ms\n",
            "Speed: 3.1ms preprocess, 26.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 wine glass, 1 cup, 1 potted plant, 1 vase, 26.3ms\n",
            "Speed: 3.4ms preprocess, 26.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 wine glass, 1 cup, 1 potted plant, 1 vase, 26.3ms\n",
            "Speed: 4.2ms preprocess, 26.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 wine glass, 1 cup, 1 potted plant, 1 vase, 26.4ms\n",
            "Speed: 3.8ms preprocess, 26.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 wine glass, 1 cup, 1 potted plant, 1 vase, 26.3ms\n",
            "Speed: 3.5ms preprocess, 26.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 wine glass, 1 cup, 1 potted plant, 1 vase, 27.4ms\n",
            "Speed: 3.3ms preprocess, 27.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 wine glass, 1 cup, 1 potted plant, 1 vase, 26.7ms\n",
            "Speed: 3.1ms preprocess, 26.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 wine glass, 1 cup, 1 potted plant, 1 vase, 26.3ms\n",
            "Speed: 3.1ms preprocess, 26.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 wine glass, 1 cup, 1 potted plant, 1 vase, 26.3ms\n",
            "Speed: 3.1ms preprocess, 26.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 wine glass, 1 cup, 1 potted plant, 1 vase, 26.4ms\n",
            "Speed: 4.5ms preprocess, 26.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 wine glass, 1 cup, 1 potted plant, 1 vase, 28.1ms\n",
            "Speed: 3.2ms preprocess, 28.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 wine glass, 1 cup, 1 potted plant, 1 vase, 26.4ms\n",
            "Speed: 3.2ms preprocess, 26.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 wine glass, 1 cup, 1 potted plant, 1 vase, 26.3ms\n",
            "Speed: 3.2ms preprocess, 26.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 wine glass, 1 cup, 1 potted plant, 1 vase, 28.5ms\n",
            "Speed: 3.0ms preprocess, 28.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 wine glass, 1 cup, 1 potted plant, 1 vase, 27.3ms\n",
            "Speed: 3.2ms preprocess, 27.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 wine glass, 1 cup, 1 potted plant, 1 vase, 26.3ms\n",
            "Speed: 3.3ms preprocess, 26.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 wine glass, 1 cup, 1 potted plant, 1 vase, 26.3ms\n",
            "Speed: 3.4ms preprocess, 26.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 wine glass, 1 cup, 1 potted plant, 1 vase, 26.3ms\n",
            "Speed: 11.6ms preprocess, 26.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 wine glass, 1 cup, 1 potted plant, 1 vase, 26.3ms\n",
            "Speed: 3.2ms preprocess, 26.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 wine glass, 1 cup, 1 potted plant, 1 vase, 26.3ms\n",
            "Speed: 3.2ms preprocess, 26.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 wine glass, 1 cup, 1 potted plant, 1 vase, 26.5ms\n",
            "Speed: 3.2ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 wine glass, 1 cup, 1 potted plant, 1 vase, 27.8ms\n",
            "Speed: 8.6ms preprocess, 27.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 wine glass, 1 cup, 1 potted plant, 1 vase, 27.5ms\n",
            "Speed: 3.3ms preprocess, 27.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 26.9ms\n",
            "Speed: 3.6ms preprocess, 26.9ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 2 wine glasss, 2 chairs, 1 potted plant, 1 dining table, 31.3ms\n",
            "Speed: 3.1ms preprocess, 31.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 2 wine glasss, 2 chairs, 1 potted plant, 1 dining table, 26.3ms\n",
            "Speed: 3.2ms preprocess, 26.3ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 2 wine glasss, 2 chairs, 1 potted plant, 1 dining table, 30.9ms\n",
            "Speed: 3.2ms preprocess, 30.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 2 wine glasss, 2 chairs, 1 potted plant, 1 dining table, 26.7ms\n",
            "Speed: 3.4ms preprocess, 26.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 2 wine glasss, 2 chairs, 1 potted plant, 1 dining table, 26.3ms\n",
            "Speed: 3.3ms preprocess, 26.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 2 wine glasss, 2 chairs, 1 potted plant, 1 dining table, 26.3ms\n",
            "Speed: 3.2ms preprocess, 26.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 2 wine glasss, 2 chairs, 1 potted plant, 1 dining table, 32.0ms\n",
            "Speed: 3.3ms preprocess, 32.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 2 wine glasss, 2 chairs, 1 potted plant, 1 dining table, 26.3ms\n",
            "Speed: 3.9ms preprocess, 26.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 2 wine glasss, 2 chairs, 1 potted plant, 1 dining table, 26.3ms\n",
            "Speed: 3.2ms preprocess, 26.3ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 2 wine glasss, 2 chairs, 1 potted plant, 1 dining table, 27.0ms\n",
            "Speed: 4.6ms preprocess, 27.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 2 wine glasss, 2 chairs, 1 potted plant, 1 dining table, 27.1ms\n",
            "Speed: 3.2ms preprocess, 27.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 2 wine glasss, 2 chairs, 1 potted plant, 1 dining table, 26.3ms\n",
            "Speed: 3.3ms preprocess, 26.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 2 wine glasss, 2 chairs, 1 potted plant, 1 dining table, 28.3ms\n",
            "Speed: 3.3ms preprocess, 28.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 2 wine glasss, 2 chairs, 1 potted plant, 1 dining table, 26.3ms\n",
            "Speed: 4.2ms preprocess, 26.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 2 wine glasss, 2 chairs, 1 potted plant, 1 dining table, 27.4ms\n",
            "Speed: 3.3ms preprocess, 27.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 2 wine glasss, 2 chairs, 1 potted plant, 1 dining table, 27.3ms\n",
            "Speed: 3.2ms preprocess, 27.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 2 wine glasss, 2 chairs, 1 potted plant, 1 dining table, 26.3ms\n",
            "Speed: 3.3ms preprocess, 26.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 2 wine glasss, 2 chairs, 1 potted plant, 1 dining table, 26.3ms\n",
            "Speed: 3.2ms preprocess, 26.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 2 wine glasss, 2 chairs, 1 potted plant, 1 dining table, 26.3ms\n",
            "Speed: 3.3ms preprocess, 26.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 2 wine glasss, 2 chairs, 1 potted plant, 1 dining table, 30.8ms\n",
            "Speed: 5.0ms preprocess, 30.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 2 wine glasss, 2 chairs, 1 potted plant, 1 dining table, 30.5ms\n",
            "Speed: 3.4ms preprocess, 30.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 2 wine glasss, 2 chairs, 1 potted plant, 1 dining table, 30.7ms\n",
            "Speed: 5.1ms preprocess, 30.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 2 wine glasss, 2 chairs, 1 potted plant, 1 dining table, 30.7ms\n",
            "Speed: 3.4ms preprocess, 30.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 2 wine glasss, 2 chairs, 1 potted plant, 1 dining table, 29.2ms\n",
            "Speed: 4.6ms preprocess, 29.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 2 wine glasss, 2 chairs, 1 potted plant, 1 dining table, 29.8ms\n",
            "Speed: 3.2ms preprocess, 29.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 2 wine glasss, 2 chairs, 1 potted plant, 1 dining table, 30.3ms\n",
            "Speed: 3.2ms preprocess, 30.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 2 wine glasss, 2 chairs, 1 potted plant, 1 dining table, 29.7ms\n",
            "Speed: 3.2ms preprocess, 29.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 2 wine glasss, 2 chairs, 1 potted plant, 1 dining table, 29.2ms\n",
            "Speed: 4.3ms preprocess, 29.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 2 wine glasss, 2 chairs, 1 potted plant, 1 dining table, 29.2ms\n",
            "Speed: 4.2ms preprocess, 29.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 2 wine glasss, 2 chairs, 1 potted plant, 1 dining table, 30.3ms\n",
            "Speed: 7.2ms preprocess, 30.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 2 wine glasss, 2 chairs, 1 potted plant, 1 dining table, 29.2ms\n",
            "Speed: 4.2ms preprocess, 29.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 2 wine glasss, 2 chairs, 1 potted plant, 1 dining table, 29.3ms\n",
            "Speed: 3.8ms preprocess, 29.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 2 wine glasss, 2 chairs, 1 potted plant, 1 dining table, 29.2ms\n",
            "Speed: 3.2ms preprocess, 29.2ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 2 wine glasss, 2 chairs, 1 potted plant, 1 dining table, 29.2ms\n",
            "Speed: 4.6ms preprocess, 29.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 2 wine glasss, 2 chairs, 1 potted plant, 1 dining table, 29.2ms\n",
            "Speed: 3.1ms preprocess, 29.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 2 wine glasss, 2 chairs, 1 potted plant, 1 dining table, 29.2ms\n",
            "Speed: 3.2ms preprocess, 29.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 2 wine glasss, 2 chairs, 1 potted plant, 1 dining table, 29.2ms\n",
            "Speed: 4.2ms preprocess, 29.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 2 wine glasss, 2 chairs, 1 potted plant, 1 dining table, 29.2ms\n",
            "Speed: 5.6ms preprocess, 29.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 2 wine glasss, 2 chairs, 1 potted plant, 1 dining table, 29.2ms\n",
            "Speed: 4.4ms preprocess, 29.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 2 wine glasss, 2 chairs, 1 potted plant, 1 dining table, 29.3ms\n",
            "Speed: 3.4ms preprocess, 29.3ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 2 wine glasss, 2 chairs, 1 potted plant, 1 dining table, 30.4ms\n",
            "Speed: 4.4ms preprocess, 30.4ms inference, 8.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 2 wine glasss, 2 chairs, 1 potted plant, 1 dining table, 31.5ms\n",
            "Speed: 3.2ms preprocess, 31.5ms inference, 5.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 2 wine glasss, 2 chairs, 1 potted plant, 1 dining table, 31.4ms\n",
            "Speed: 3.2ms preprocess, 31.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 2 wine glasss, 2 chairs, 1 potted plant, 1 dining table, 32.0ms\n",
            "Speed: 3.2ms preprocess, 32.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 2 wine glasss, 2 chairs, 1 potted plant, 1 dining table, 36.4ms\n",
            "Speed: 3.2ms preprocess, 36.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 2 wine glasss, 2 chairs, 1 potted plant, 1 dining table, 34.0ms\n",
            "Speed: 3.8ms preprocess, 34.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 2 wine glasss, 2 chairs, 1 potted plant, 1 dining table, 32.5ms\n",
            "Speed: 9.0ms preprocess, 32.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 5 persons, 2 wine glasss, 2 chairs, 1 potted plant, 1 dining table, 35.4ms\n",
            "Speed: 3.5ms preprocess, 35.4ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 2 wine glasss, 2 chairs, 1 potted plant, 1 dining table, 32.6ms\n",
            "Speed: 3.9ms preprocess, 32.6ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 2 wine glasss, 2 chairs, 1 potted plant, 1 dining table, 33.1ms\n",
            "Speed: 5.2ms preprocess, 33.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 2 wine glasss, 2 chairs, 1 potted plant, 1 dining table, 33.1ms\n",
            "Speed: 3.6ms preprocess, 33.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 2 wine glasss, 2 chairs, 1 potted plant, 1 dining table, 33.6ms\n",
            "Speed: 3.3ms preprocess, 33.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 2 wine glasss, 2 chairs, 1 potted plant, 1 dining table, 33.6ms\n",
            "Speed: 3.1ms preprocess, 33.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 2 wine glasss, 2 chairs, 1 potted plant, 1 dining table, 32.8ms\n",
            "Speed: 3.6ms preprocess, 32.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 2 wine glasss, 2 chairs, 1 potted plant, 1 dining table, 33.2ms\n",
            "Speed: 3.3ms preprocess, 33.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 2 wine glasss, 2 chairs, 1 potted plant, 1 dining table, 31.5ms\n",
            "Speed: 3.0ms preprocess, 31.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 2 wine glasss, 2 chairs, 1 potted plant, 1 dining table, 31.6ms\n",
            "Speed: 3.1ms preprocess, 31.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 2 wine glasss, 2 chairs, 1 potted plant, 1 dining table, 31.5ms\n",
            "Speed: 3.3ms preprocess, 31.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 2 wine glasss, 2 chairs, 1 potted plant, 1 dining table, 31.5ms\n",
            "Speed: 3.1ms preprocess, 31.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 2 wine glasss, 2 chairs, 1 potted plant, 1 dining table, 27.7ms\n",
            "Speed: 3.1ms preprocess, 27.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 2 wine glasss, 2 chairs, 1 potted plant, 1 dining table, 27.2ms\n",
            "Speed: 3.1ms preprocess, 27.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 2 wine glasss, 2 chairs, 1 potted plant, 1 dining table, 27.0ms\n",
            "Speed: 7.8ms preprocess, 27.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 2 wine glasss, 2 chairs, 1 potted plant, 1 dining table, 27.6ms\n",
            "Speed: 3.7ms preprocess, 27.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 couch, 1 dining table, 27.0ms\n",
            "Speed: 3.4ms preprocess, 27.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 cup, 2 bowls, 1 chair, 1 couch, 2 dining tables, 26.9ms\n",
            "Speed: 3.4ms preprocess, 26.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 cup, 2 bowls, 1 chair, 2 couchs, 2 dining tables, 26.9ms\n",
            "Speed: 3.2ms preprocess, 26.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 cup, 2 bowls, 2 chairs, 2 couchs, 2 dining tables, 26.9ms\n",
            "Speed: 3.2ms preprocess, 26.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 handbag, 1 cup, 2 bowls, 2 chairs, 2 couchs, 2 dining tables, 26.9ms\n",
            "Speed: 3.4ms preprocess, 26.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 handbag, 1 cup, 2 bowls, 2 chairs, 2 couchs, 2 dining tables, 26.9ms\n",
            "Speed: 3.2ms preprocess, 26.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 handbag, 1 cup, 2 bowls, 2 chairs, 2 couchs, 2 dining tables, 26.9ms\n",
            "Speed: 3.3ms preprocess, 26.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 handbag, 1 cup, 2 bowls, 2 chairs, 2 couchs, 2 dining tables, 27.6ms\n",
            "Speed: 3.4ms preprocess, 27.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 handbag, 1 cup, 2 bowls, 2 chairs, 2 couchs, 2 dining tables, 26.9ms\n",
            "Speed: 3.4ms preprocess, 26.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 handbag, 1 cup, 2 bowls, 2 chairs, 2 couchs, 2 dining tables, 27.0ms\n",
            "Speed: 3.4ms preprocess, 27.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 handbag, 1 cup, 2 bowls, 2 chairs, 2 couchs, 2 dining tables, 2 remotes, 27.1ms\n",
            "Speed: 4.1ms preprocess, 27.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 handbag, 1 cup, 2 bowls, 2 chairs, 2 couchs, 2 dining tables, 2 remotes, 27.8ms\n",
            "Speed: 2.6ms preprocess, 27.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 handbag, 1 cup, 2 bowls, 2 chairs, 2 couchs, 2 dining tables, 2 remotes, 29.0ms\n",
            "Speed: 3.3ms preprocess, 29.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 handbag, 1 cup, 2 bowls, 2 chairs, 2 couchs, 2 dining tables, 2 remotes, 26.9ms\n",
            "Speed: 3.3ms preprocess, 26.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 handbag, 1 cup, 2 bowls, 2 chairs, 2 couchs, 2 dining tables, 2 remotes, 27.0ms\n",
            "Speed: 3.2ms preprocess, 27.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 handbag, 1 cup, 2 bowls, 2 chairs, 2 couchs, 2 dining tables, 2 remotes, 26.9ms\n",
            "Speed: 3.1ms preprocess, 26.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 handbag, 1 cup, 2 bowls, 2 chairs, 2 couchs, 2 dining tables, 2 remotes, 1 book, 27.0ms\n",
            "Speed: 4.2ms preprocess, 27.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 handbag, 1 cup, 2 bowls, 2 chairs, 2 couchs, 2 dining tables, 2 remotes, 1 book, 26.4ms\n",
            "Speed: 3.1ms preprocess, 26.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 handbag, 1 cup, 2 bowls, 2 chairs, 2 couchs, 2 dining tables, 1 laptop, 2 remotes, 1 book, 26.3ms\n",
            "Speed: 3.2ms preprocess, 26.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 handbag, 1 cup, 2 bowls, 2 chairs, 2 couchs, 2 dining tables, 1 laptop, 2 remotes, 1 book, 26.3ms\n",
            "Speed: 3.4ms preprocess, 26.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 handbag, 1 cup, 2 bowls, 2 chairs, 2 couchs, 2 dining tables, 1 laptop, 2 remotes, 1 book, 26.7ms\n",
            "Speed: 3.2ms preprocess, 26.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 handbag, 1 cup, 2 bowls, 2 chairs, 2 couchs, 2 dining tables, 1 laptop, 2 remotes, 1 book, 26.3ms\n",
            "Speed: 3.3ms preprocess, 26.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 handbag, 1 cup, 2 bowls, 2 chairs, 2 couchs, 2 dining tables, 1 laptop, 2 remotes, 1 book, 26.3ms\n",
            "Speed: 3.3ms preprocess, 26.3ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 handbag, 1 cup, 2 bowls, 2 chairs, 2 couchs, 2 dining tables, 2 remotes, 1 book, 29.0ms\n",
            "Speed: 3.7ms preprocess, 29.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 handbag, 1 cup, 1 spoon, 2 bowls, 1 donut, 2 chairs, 2 couchs, 2 dining tables, 1 book, 26.3ms\n",
            "Speed: 3.2ms preprocess, 26.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 handbag, 1 cup, 1 spoon, 2 bowls, 1 donut, 2 chairs, 2 couchs, 2 dining tables, 1 book, 32.2ms\n",
            "Speed: 3.2ms preprocess, 32.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 handbag, 1 cup, 1 spoon, 2 bowls, 1 donut, 2 chairs, 2 couchs, 2 dining tables, 1 book, 28.9ms\n",
            "Speed: 3.2ms preprocess, 28.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 handbag, 1 cup, 2 bowls, 1 donut, 2 chairs, 2 couchs, 2 dining tables, 1 remote, 1 book, 31.2ms\n",
            "Speed: 3.4ms preprocess, 31.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 handbag, 2 cups, 2 bowls, 1 donut, 2 chairs, 2 couchs, 2 dining tables, 1 remote, 1 book, 26.3ms\n",
            "Speed: 3.6ms preprocess, 26.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 handbag, 2 cups, 1 knife, 2 bowls, 1 donut, 2 chairs, 2 couchs, 2 dining tables, 1 remote, 1 book, 30.7ms\n",
            "Speed: 3.2ms preprocess, 30.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 handbag, 2 cups, 1 knife, 2 bowls, 1 donut, 2 chairs, 2 couchs, 2 dining tables, 1 remote, 1 book, 30.1ms\n",
            "Speed: 3.3ms preprocess, 30.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 handbag, 2 cups, 1 knife, 2 bowls, 2 chairs, 2 couchs, 2 dining tables, 2 remotes, 1 book, 26.3ms\n",
            "Speed: 3.2ms preprocess, 26.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 handbag, 2 cups, 1 knife, 2 bowls, 2 chairs, 2 couchs, 2 dining tables, 1 remote, 2 books, 26.3ms\n",
            "Speed: 3.3ms preprocess, 26.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 handbag, 2 cups, 1 knife, 2 bowls, 2 chairs, 2 couchs, 2 dining tables, 1 remote, 2 books, 26.4ms\n",
            "Speed: 3.4ms preprocess, 26.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 handbag, 2 cups, 1 knife, 2 bowls, 2 chairs, 2 couchs, 2 dining tables, 1 remote, 2 books, 26.4ms\n",
            "Speed: 3.9ms preprocess, 26.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 handbag, 2 cups, 1 knife, 2 bowls, 2 chairs, 2 couchs, 2 dining tables, 1 remote, 2 books, 26.4ms\n",
            "Speed: 3.4ms preprocess, 26.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 handbag, 2 cups, 1 knife, 2 bowls, 2 chairs, 2 couchs, 2 dining tables, 1 remote, 2 books, 26.4ms\n",
            "Speed: 7.6ms preprocess, 26.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 handbag, 2 cups, 1 spoon, 2 bowls, 2 chairs, 2 couchs, 2 dining tables, 1 remote, 2 books, 27.9ms\n",
            "Speed: 3.3ms preprocess, 27.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 handbag, 2 cups, 1 spoon, 2 bowls, 2 chairs, 2 couchs, 2 dining tables, 1 remote, 2 books, 27.9ms\n",
            "Speed: 9.6ms preprocess, 27.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 handbag, 2 cups, 1 spoon, 2 bowls, 2 chairs, 2 couchs, 2 dining tables, 1 remote, 2 books, 28.5ms\n",
            "Speed: 4.9ms preprocess, 28.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 handbag, 2 cups, 1 spoon, 2 bowls, 2 chairs, 2 couchs, 2 dining tables, 1 laptop, 1 remote, 2 books, 28.4ms\n",
            "Speed: 3.1ms preprocess, 28.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 handbag, 2 cups, 2 bowls, 2 chairs, 2 couchs, 2 dining tables, 1 laptop, 2 remotes, 2 books, 28.4ms\n",
            "Speed: 3.3ms preprocess, 28.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 couch, 28.7ms\n",
            "Speed: 3.2ms preprocess, 28.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 couch, 1 laptop, 5 books, 28.4ms\n",
            "Speed: 3.4ms preprocess, 28.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 couch, 1 laptop, 5 books, 28.8ms\n",
            "Speed: 3.4ms preprocess, 28.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 couch, 1 laptop, 5 books, 28.8ms\n",
            "Speed: 3.4ms preprocess, 28.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 couch, 1 laptop, 5 books, 29.0ms\n",
            "Speed: 3.2ms preprocess, 29.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 couch, 1 laptop, 5 books, 29.5ms\n",
            "Speed: 3.4ms preprocess, 29.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 couch, 1 laptop, 6 books, 29.2ms\n",
            "Speed: 3.2ms preprocess, 29.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 couch, 1 laptop, 6 books, 30.6ms\n",
            "Speed: 3.3ms preprocess, 30.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 couch, 1 laptop, 6 books, 29.2ms\n",
            "Speed: 3.0ms preprocess, 29.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 couch, 6 books, 30.3ms\n",
            "Speed: 3.2ms preprocess, 30.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 couch, 6 books, 29.6ms\n",
            "Speed: 7.0ms preprocess, 29.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 couch, 6 books, 29.6ms\n",
            "Speed: 3.3ms preprocess, 29.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 couch, 6 books, 28.3ms\n",
            "Speed: 4.0ms preprocess, 28.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 couch, 6 books, 26.9ms\n",
            "Speed: 3.0ms preprocess, 26.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 couch, 6 books, 26.9ms\n",
            "Speed: 3.2ms preprocess, 26.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 couch, 6 books, 26.7ms\n",
            "Speed: 3.2ms preprocess, 26.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 couch, 6 books, 26.7ms\n",
            "Speed: 3.4ms preprocess, 26.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 couch, 6 books, 26.7ms\n",
            "Speed: 3.3ms preprocess, 26.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 couch, 6 books, 26.7ms\n",
            "Speed: 3.4ms preprocess, 26.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 couch, 6 books, 26.7ms\n",
            "Speed: 3.2ms preprocess, 26.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 couch, 6 books, 26.7ms\n",
            "Speed: 3.2ms preprocess, 26.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 couch, 6 books, 26.7ms\n",
            "Speed: 10.3ms preprocess, 26.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 couch, 1 cell phone, 6 books, 26.7ms\n",
            "Speed: 3.4ms preprocess, 26.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 couch, 1 cell phone, 6 books, 26.7ms\n",
            "Speed: 3.3ms preprocess, 26.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 couch, 6 books, 26.7ms\n",
            "Speed: 3.3ms preprocess, 26.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 couch, 6 books, 26.7ms\n",
            "Speed: 3.2ms preprocess, 26.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 couch, 6 books, 26.8ms\n",
            "Speed: 4.5ms preprocess, 26.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 couch, 6 books, 26.7ms\n",
            "Speed: 3.9ms preprocess, 26.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 couch, 5 books, 26.7ms\n",
            "Speed: 3.2ms preprocess, 26.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 couch, 5 books, 26.7ms\n",
            "Speed: 8.6ms preprocess, 26.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 couch, 4 books, 27.0ms\n",
            "Speed: 3.1ms preprocess, 27.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 couch, 4 books, 26.7ms\n",
            "Speed: 3.3ms preprocess, 26.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 couch, 5 books, 26.3ms\n",
            "Speed: 3.3ms preprocess, 26.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 couch, 4 books, 26.3ms\n",
            "Speed: 3.3ms preprocess, 26.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 couch, 4 books, 26.3ms\n",
            "Speed: 3.0ms preprocess, 26.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 couch, 4 books, 26.3ms\n",
            "Speed: 3.2ms preprocess, 26.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 couch, 4 books, 26.3ms\n",
            "Speed: 3.2ms preprocess, 26.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 couch, 4 books, 26.4ms\n",
            "Speed: 3.2ms preprocess, 26.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 couch, 4 books, 26.3ms\n",
            "Speed: 3.4ms preprocess, 26.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 couch, 3 books, 26.3ms\n",
            "Speed: 3.7ms preprocess, 26.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 3 books, 26.3ms\n",
            "Speed: 3.9ms preprocess, 26.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 4 books, 26.4ms\n",
            "Speed: 4.2ms preprocess, 26.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 couch, 5 books, 26.3ms\n",
            "Speed: 3.2ms preprocess, 26.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 couch, 5 books, 26.4ms\n",
            "Speed: 3.2ms preprocess, 26.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 couch, 5 books, 26.3ms\n",
            "Speed: 4.2ms preprocess, 26.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 couch, 5 books, 28.3ms\n",
            "Speed: 3.5ms preprocess, 28.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 couch, 5 books, 26.4ms\n",
            "Speed: 3.1ms preprocess, 26.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 couch, 6 books, 26.3ms\n",
            "Speed: 3.2ms preprocess, 26.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 couch, 5 books, 26.3ms\n",
            "Speed: 3.1ms preprocess, 26.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 couch, 5 books, 26.3ms\n",
            "Speed: 3.2ms preprocess, 26.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 couch, 5 books, 26.4ms\n",
            "Speed: 3.1ms preprocess, 26.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 couch, 6 books, 26.3ms\n",
            "Speed: 3.3ms preprocess, 26.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 couch, 6 books, 26.4ms\n",
            "Speed: 4.1ms preprocess, 26.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 couch, 5 books, 26.4ms\n",
            "Speed: 3.2ms preprocess, 26.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 couch, 5 books, 26.3ms\n",
            "Speed: 3.0ms preprocess, 26.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 couch, 5 books, 32.8ms\n",
            "Speed: 3.2ms preprocess, 32.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 couch, 5 books, 26.3ms\n",
            "Speed: 6.5ms preprocess, 26.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 couch, 5 books, 26.3ms\n",
            "Speed: 3.0ms preprocess, 26.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 couch, 5 books, 26.4ms\n",
            "Speed: 3.4ms preprocess, 26.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 couch, 5 books, 27.5ms\n",
            "Speed: 3.4ms preprocess, 27.5ms inference, 6.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 couch, 5 books, 27.4ms\n",
            "Speed: 4.1ms preprocess, 27.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 couch, 5 books, 27.1ms\n",
            "Speed: 3.2ms preprocess, 27.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 couch, 5 books, 26.8ms\n",
            "Speed: 3.2ms preprocess, 26.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 couchs, 5 books, 26.6ms\n",
            "Speed: 7.2ms preprocess, 26.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 couchs, 5 books, 26.6ms\n",
            "Speed: 3.1ms preprocess, 26.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 couchs, 5 books, 26.7ms\n",
            "Speed: 3.9ms preprocess, 26.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 2 couchs, 5 books, 26.8ms\n",
            "Speed: 3.3ms preprocess, 26.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 couchs, 5 books, 26.6ms\n",
            "Speed: 3.2ms preprocess, 26.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 couchs, 5 books, 26.6ms\n",
            "Speed: 3.2ms preprocess, 26.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 couchs, 5 books, 26.6ms\n",
            "Speed: 3.3ms preprocess, 26.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 couchs, 5 books, 26.5ms\n",
            "Speed: 9.0ms preprocess, 26.5ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 couchs, 5 books, 30.4ms\n",
            "Speed: 3.4ms preprocess, 30.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 couchs, 5 books, 26.7ms\n",
            "Speed: 3.3ms preprocess, 26.7ms inference, 6.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 couchs, 5 books, 26.6ms\n",
            "Speed: 3.2ms preprocess, 26.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 couch, 5 books, 26.6ms\n",
            "Speed: 3.1ms preprocess, 26.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 couch, 5 books, 33.0ms\n",
            "Speed: 3.1ms preprocess, 33.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 couch, 5 books, 26.6ms\n",
            "Speed: 3.6ms preprocess, 26.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 couch, 5 books, 26.6ms\n",
            "Speed: 4.6ms preprocess, 26.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 couch, 5 books, 26.5ms\n",
            "Speed: 3.4ms preprocess, 26.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 couch, 5 books, 28.5ms\n",
            "Speed: 3.3ms preprocess, 28.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 chair, 26.9ms\n",
            "Speed: 5.3ms preprocess, 26.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 1 cup, 1 chair, 26.6ms\n",
            "Speed: 4.4ms preprocess, 26.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 1 cup, 1 chair, 31.7ms\n",
            "Speed: 3.3ms preprocess, 31.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 1 cup, 1 chair, 31.0ms\n",
            "Speed: 3.2ms preprocess, 31.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 1 cup, 1 chair, 31.0ms\n",
            "Speed: 4.4ms preprocess, 31.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 1 cup, 1 chair, 30.9ms\n",
            "Speed: 4.3ms preprocess, 30.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 1 cup, 1 chair, 33.7ms\n",
            "Speed: 3.3ms preprocess, 33.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 1 cup, 1 chair, 31.9ms\n",
            "Speed: 3.2ms preprocess, 31.9ms inference, 5.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 1 cup, 1 chair, 30.2ms\n",
            "Speed: 3.2ms preprocess, 30.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 1 cup, 1 chair, 30.0ms\n",
            "Speed: 3.1ms preprocess, 30.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 1 cup, 1 chair, 30.1ms\n",
            "Speed: 3.7ms preprocess, 30.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 1 cup, 1 chair, 35.0ms\n",
            "Speed: 3.3ms preprocess, 35.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 1 cup, 1 chair, 30.1ms\n",
            "Speed: 5.2ms preprocess, 30.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 1 cup, 1 chair, 30.1ms\n",
            "Speed: 3.8ms preprocess, 30.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 1 cup, 1 chair, 30.1ms\n",
            "Speed: 4.0ms preprocess, 30.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 1 cup, 1 chair, 30.0ms\n",
            "Speed: 7.0ms preprocess, 30.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 1 cup, 1 chair, 29.9ms\n",
            "Speed: 3.5ms preprocess, 29.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 1 cup, 1 chair, 29.2ms\n",
            "Speed: 4.2ms preprocess, 29.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 1 cup, 1 chair, 29.2ms\n",
            "Speed: 4.1ms preprocess, 29.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 1 cup, 1 chair, 29.2ms\n",
            "Speed: 3.6ms preprocess, 29.2ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 1 cup, 1 chair, 29.2ms\n",
            "Speed: 3.2ms preprocess, 29.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 1 cup, 1 chair, 29.2ms\n",
            "Speed: 7.3ms preprocess, 29.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 1 cup, 1 chair, 29.2ms\n",
            "Speed: 3.2ms preprocess, 29.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 1 cup, 1 chair, 29.4ms\n",
            "Speed: 4.3ms preprocess, 29.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 1 cup, 1 chair, 29.2ms\n",
            "Speed: 4.0ms preprocess, 29.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 1 cup, 1 chair, 27.9ms\n",
            "Speed: 3.2ms preprocess, 27.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 1 cup, 1 chair, 35.0ms\n",
            "Speed: 4.2ms preprocess, 35.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 1 cup, 1 chair, 32.6ms\n",
            "Speed: 3.3ms preprocess, 32.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 couch, 3 books, 28.8ms\n",
            "Speed: 5.0ms preprocess, 28.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 chair, 1 couch, 4 books, 28.4ms\n",
            "Speed: 4.3ms preprocess, 28.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 chair, 2 couchs, 4 books, 27.9ms\n",
            "Speed: 11.4ms preprocess, 27.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 chair, 2 couchs, 4 books, 30.8ms\n",
            "Speed: 3.3ms preprocess, 30.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 chair, 2 couchs, 4 books, 28.0ms\n",
            "Speed: 3.3ms preprocess, 28.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 chair, 2 couchs, 4 books, 27.9ms\n",
            "Speed: 3.3ms preprocess, 27.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 chair, 2 couchs, 4 books, 27.9ms\n",
            "Speed: 3.3ms preprocess, 27.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 chair, 2 couchs, 1 laptop, 4 books, 32.1ms\n",
            "Speed: 3.3ms preprocess, 32.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 chair, 2 couchs, 1 laptop, 4 books, 29.1ms\n",
            "Speed: 3.1ms preprocess, 29.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 chair, 2 couchs, 1 laptop, 4 books, 28.3ms\n",
            "Speed: 3.3ms preprocess, 28.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 2 couchs, 1 laptop, 4 books, 27.9ms\n",
            "Speed: 6.4ms preprocess, 27.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 2 couchs, 5 books, 31.7ms\n",
            "Speed: 3.3ms preprocess, 31.7ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 2 couchs, 5 books, 30.7ms\n",
            "Speed: 3.3ms preprocess, 30.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 2 couchs, 5 books, 28.9ms\n",
            "Speed: 3.0ms preprocess, 28.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 2 couchs, 5 books, 36.3ms\n",
            "Speed: 4.9ms preprocess, 36.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 2 couchs, 4 books, 33.6ms\n",
            "Speed: 3.4ms preprocess, 33.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 2 couchs, 1 laptop, 3 books, 33.6ms\n",
            "Speed: 3.3ms preprocess, 33.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 2 couchs, 1 laptop, 3 books, 28.8ms\n",
            "Speed: 3.4ms preprocess, 28.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 2 couchs, 1 laptop, 3 books, 28.8ms\n",
            "Speed: 3.3ms preprocess, 28.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 2 couchs, 1 laptop, 3 books, 28.8ms\n",
            "Speed: 3.3ms preprocess, 28.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 3 chairs, 2 couchs, 1 laptop, 3 books, 28.8ms\n",
            "Speed: 3.2ms preprocess, 28.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 3 chairs, 2 couchs, 3 books, 34.3ms\n",
            "Speed: 3.3ms preprocess, 34.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 3 chairs, 2 couchs, 3 books, 31.2ms\n",
            "Speed: 3.5ms preprocess, 31.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 3 chairs, 2 couchs, 3 books, 31.2ms\n",
            "Speed: 3.3ms preprocess, 31.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 3 chairs, 2 couchs, 3 books, 28.8ms\n",
            "Speed: 3.6ms preprocess, 28.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 3 chairs, 2 couchs, 3 books, 28.8ms\n",
            "Speed: 3.5ms preprocess, 28.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 3 chairs, 2 couchs, 1 laptop, 3 books, 30.7ms\n",
            "Speed: 3.4ms preprocess, 30.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 2 couchs, 1 laptop, 3 books, 28.8ms\n",
            "Speed: 3.4ms preprocess, 28.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 2 couchs, 1 laptop, 3 books, 28.8ms\n",
            "Speed: 3.2ms preprocess, 28.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 2 couchs, 1 laptop, 3 books, 29.3ms\n",
            "Speed: 5.5ms preprocess, 29.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 3 couchs, 1 laptop, 3 books, 28.8ms\n",
            "Speed: 3.1ms preprocess, 28.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 chair, 3 couchs, 1 laptop, 3 books, 28.8ms\n",
            "Speed: 3.4ms preprocess, 28.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 chair, 2 couchs, 1 laptop, 1 book, 28.8ms\n",
            "Speed: 3.3ms preprocess, 28.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 chair, 2 couchs, 1 laptop, 1 book, 29.0ms\n",
            "Speed: 3.5ms preprocess, 29.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 chair, 2 couchs, 1 laptop, 1 book, 28.8ms\n",
            "Speed: 3.3ms preprocess, 28.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 chair, 2 couchs, 1 laptop, 1 book, 28.8ms\n",
            "Speed: 3.2ms preprocess, 28.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 chair, 2 couchs, 1 laptop, 1 book, 28.8ms\n",
            "Speed: 4.3ms preprocess, 28.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 chair, 2 couchs, 1 laptop, 1 book, 28.8ms\n",
            "Speed: 4.5ms preprocess, 28.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 chair, 2 couchs, 1 laptop, 1 book, 28.8ms\n",
            "Speed: 3.3ms preprocess, 28.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 chair, 2 couchs, 1 cell phone, 1 book, 29.5ms\n",
            "Speed: 3.3ms preprocess, 29.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 chair, 2 couchs, 1 cell phone, 27.9ms\n",
            "Speed: 3.2ms preprocess, 27.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 chair, 2 couchs, 1 laptop, 27.8ms\n",
            "Speed: 3.1ms preprocess, 27.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 2 couchs, 1 laptop, 27.7ms\n",
            "Speed: 3.6ms preprocess, 27.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 2 couchs, 1 cell phone, 27.4ms\n",
            "Speed: 3.1ms preprocess, 27.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 2 couchs, 1 cell phone, 27.7ms\n",
            "Speed: 3.3ms preprocess, 27.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 2 couchs, 1 cell phone, 27.2ms\n",
            "Speed: 6.4ms preprocess, 27.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 2 couchs, 1 laptop, 1 book, 26.9ms\n",
            "Speed: 3.3ms preprocess, 26.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 2 couchs, 1 laptop, 1 book, 26.5ms\n",
            "Speed: 3.2ms preprocess, 26.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 2 couchs, 1 cell phone, 2 books, 27.7ms\n",
            "Speed: 3.3ms preprocess, 27.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 2 couchs, 1 cell phone, 3 books, 26.7ms\n",
            "Speed: 5.3ms preprocess, 26.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 2 couchs, 1 laptop, 3 books, 26.6ms\n",
            "Speed: 3.4ms preprocess, 26.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 2 couchs, 1 laptop, 3 books, 26.6ms\n",
            "Speed: 3.5ms preprocess, 26.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 2 couchs, 1 laptop, 3 books, 26.6ms\n",
            "Speed: 3.2ms preprocess, 26.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 2 couchs, 1 laptop, 3 books, 26.6ms\n",
            "Speed: 3.9ms preprocess, 26.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 2 couchs, 1 laptop, 3 books, 26.6ms\n",
            "Speed: 3.3ms preprocess, 26.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 2 couchs, 1 laptop, 3 books, 26.6ms\n",
            "Speed: 3.4ms preprocess, 26.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 2 couchs, 1 laptop, 3 books, 26.6ms\n",
            "Speed: 3.1ms preprocess, 26.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 2 couchs, 1 remote, 3 books, 28.6ms\n",
            "Speed: 3.3ms preprocess, 28.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 2 couchs, 1 remote, 3 books, 26.6ms\n",
            "Speed: 9.1ms preprocess, 26.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 3 couchs, 1 remote, 3 books, 26.6ms\n",
            "Speed: 3.2ms preprocess, 26.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 2 couchs, 1 remote, 3 books, 26.6ms\n",
            "Speed: 3.4ms preprocess, 26.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 2 couchs, 1 remote, 3 books, 26.8ms\n",
            "Speed: 3.2ms preprocess, 26.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 2 couchs, 1 remote, 3 books, 28.1ms\n",
            "Speed: 5.9ms preprocess, 28.1ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 2 couchs, 1 remote, 3 books, 26.6ms\n",
            "Speed: 3.4ms preprocess, 26.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 2 couchs, 1 remote, 3 books, 32.5ms\n",
            "Speed: 3.3ms preprocess, 32.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 2 couchs, 1 remote, 3 books, 29.9ms\n",
            "Speed: 3.4ms preprocess, 29.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 2 couchs, 1 remote, 3 books, 26.6ms\n",
            "Speed: 5.9ms preprocess, 26.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 2 couchs, 1 remote, 3 books, 28.2ms\n",
            "Speed: 3.4ms preprocess, 28.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 2 couchs, 1 remote, 3 books, 28.2ms\n",
            "Speed: 3.1ms preprocess, 28.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 2 couchs, 1 remote, 3 books, 28.5ms\n",
            "Speed: 4.7ms preprocess, 28.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 2 couchs, 1 cell phone, 3 books, 27.9ms\n",
            "Speed: 3.7ms preprocess, 27.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 2 couchs, 1 remote, 3 books, 27.3ms\n",
            "Speed: 3.5ms preprocess, 27.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 2 couchs, 1 remote, 3 books, 27.0ms\n",
            "Speed: 3.3ms preprocess, 27.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 2 couchs, 1 remote, 3 books, 26.9ms\n",
            "Speed: 3.3ms preprocess, 26.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 1 couch, 1 remote, 3 books, 26.9ms\n",
            "Speed: 3.3ms preprocess, 26.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 1 couch, 1 remote, 3 books, 27.0ms\n",
            "Speed: 3.3ms preprocess, 27.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 2 couchs, 1 remote, 3 books, 29.8ms\n",
            "Speed: 3.5ms preprocess, 29.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 2 couchs, 1 remote, 3 books, 26.3ms\n",
            "Speed: 3.2ms preprocess, 26.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 2 couchs, 1 remote, 3 books, 26.3ms\n",
            "Speed: 3.0ms preprocess, 26.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 2 couchs, 1 remote, 3 books, 26.3ms\n",
            "Speed: 3.2ms preprocess, 26.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 2 couchs, 1 remote, 3 books, 26.3ms\n",
            "Speed: 3.0ms preprocess, 26.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 2 couchs, 1 remote, 3 books, 26.3ms\n",
            "Speed: 10.1ms preprocess, 26.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 chair, 26.3ms\n",
            "Speed: 3.1ms preprocess, 26.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 1 cup, 1 chair, 28.6ms\n",
            "Speed: 3.4ms preprocess, 28.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 1 cup, 1 chair, 26.3ms\n",
            "Speed: 4.0ms preprocess, 26.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 1 cup, 1 chair, 26.3ms\n",
            "Speed: 3.3ms preprocess, 26.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 1 cup, 1 chair, 26.7ms\n",
            "Speed: 3.4ms preprocess, 26.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 1 cup, 1 chair, 26.4ms\n",
            "Speed: 3.2ms preprocess, 26.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 1 cup, 1 chair, 26.4ms\n",
            "Speed: 4.1ms preprocess, 26.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 1 cup, 1 chair, 28.4ms\n",
            "Speed: 4.5ms preprocess, 28.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 1 cup, 1 chair, 26.4ms\n",
            "Speed: 3.3ms preprocess, 26.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 1 cup, 1 chair, 26.3ms\n",
            "Speed: 3.5ms preprocess, 26.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 1 cup, 1 chair, 26.4ms\n",
            "Speed: 4.0ms preprocess, 26.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 1 cup, 1 chair, 26.3ms\n",
            "Speed: 4.7ms preprocess, 26.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 1 cup, 1 chair, 26.3ms\n",
            "Speed: 3.3ms preprocess, 26.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 1 cup, 1 chair, 26.3ms\n",
            "Speed: 3.0ms preprocess, 26.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 1 cup, 1 chair, 26.4ms\n",
            "Speed: 3.7ms preprocess, 26.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 1 cup, 1 chair, 26.3ms\n",
            "Speed: 3.3ms preprocess, 26.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 1 cup, 1 chair, 26.5ms\n",
            "Speed: 3.1ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 1 cup, 1 chair, 26.3ms\n",
            "Speed: 4.2ms preprocess, 26.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 1 cup, 1 chair, 26.6ms\n",
            "Speed: 3.3ms preprocess, 26.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 1 cup, 1 chair, 26.4ms\n",
            "Speed: 3.1ms preprocess, 26.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 1 cup, 1 chair, 27.6ms\n",
            "Speed: 3.4ms preprocess, 27.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 1 cup, 1 chair, 25.9ms\n",
            "Speed: 3.2ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 1 cup, 1 chair, 32.4ms\n",
            "Speed: 3.2ms preprocess, 32.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 1 cup, 1 chair, 30.2ms\n",
            "Speed: 3.3ms preprocess, 30.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 1 cup, 1 chair, 25.9ms\n",
            "Speed: 3.1ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 1 cup, 1 chair, 25.9ms\n",
            "Speed: 3.2ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 1 cup, 1 chair, 25.9ms\n",
            "Speed: 3.1ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 1 cup, 1 chair, 25.9ms\n",
            "Speed: 3.2ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 1 cup, 1 chair, 26.0ms\n",
            "Speed: 3.0ms preprocess, 26.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 1 cup, 1 chair, 25.8ms\n",
            "Speed: 3.1ms preprocess, 25.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 1 cup, 1 chair, 25.8ms\n",
            "Speed: 3.1ms preprocess, 25.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 25.9ms\n",
            "Speed: 3.2ms preprocess, 25.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 bicycle, 1 car, 25.9ms\n",
            "Speed: 3.2ms preprocess, 25.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 bicycle, 1 car, 25.9ms\n",
            "Speed: 10.0ms preprocess, 25.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 bicycle, 1 car, 25.9ms\n",
            "Speed: 3.3ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 bicycle, 1 car, 27.0ms\n",
            "Speed: 3.2ms preprocess, 27.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 bicycle, 1 car, 27.7ms\n",
            "Speed: 3.5ms preprocess, 27.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 bicycle, 1 car, 26.9ms\n",
            "Speed: 4.1ms preprocess, 26.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 bicycle, 1 car, 26.6ms\n",
            "Speed: 6.6ms preprocess, 26.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 bicycle, 1 car, 26.6ms\n",
            "Speed: 3.2ms preprocess, 26.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 bicycle, 1 car, 26.6ms\n",
            "Speed: 3.2ms preprocess, 26.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 bicycle, 1 car, 27.1ms\n",
            "Speed: 3.0ms preprocess, 27.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 bicycle, 1 car, 27.0ms\n",
            "Speed: 3.4ms preprocess, 27.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 bicycle, 1 car, 26.3ms\n",
            "Speed: 3.2ms preprocess, 26.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 bicycle, 1 car, 26.3ms\n",
            "Speed: 3.5ms preprocess, 26.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 car, 26.5ms\n",
            "Speed: 3.1ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 car, 26.3ms\n",
            "Speed: 3.3ms preprocess, 26.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 car, 26.3ms\n",
            "Speed: 3.2ms preprocess, 26.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 car, 26.3ms\n",
            "Speed: 3.3ms preprocess, 26.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 car, 26.3ms\n",
            "Speed: 3.3ms preprocess, 26.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 car, 26.3ms\n",
            "Speed: 3.1ms preprocess, 26.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 car, 26.3ms\n",
            "Speed: 3.3ms preprocess, 26.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 car, 28.3ms\n",
            "Speed: 3.3ms preprocess, 28.3ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 car, 27.0ms\n",
            "Speed: 3.3ms preprocess, 27.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 car, 26.3ms\n",
            "Speed: 3.3ms preprocess, 26.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 car, 26.3ms\n",
            "Speed: 3.2ms preprocess, 26.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 bicycle, 1 car, 28.1ms\n",
            "Speed: 3.6ms preprocess, 28.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 car, 26.3ms\n",
            "Speed: 3.5ms preprocess, 26.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 bicycle, 1 car, 26.4ms\n",
            "Speed: 3.4ms preprocess, 26.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 bicycle, 1 car, 26.3ms\n",
            "Speed: 4.2ms preprocess, 26.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 bicycle, 1 car, 26.3ms\n",
            "Speed: 3.2ms preprocess, 26.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 bicycle, 1 car, 26.3ms\n",
            "Speed: 3.2ms preprocess, 26.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 bicycle, 1 car, 1 knife, 26.3ms\n",
            "Speed: 3.3ms preprocess, 26.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 bicycle, 1 car, 1 knife, 30.3ms\n",
            "Speed: 3.1ms preprocess, 30.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 bicycle, 1 car, 1 knife, 26.3ms\n",
            "Speed: 6.8ms preprocess, 26.3ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 bicycle, 1 car, 1 knife, 26.3ms\n",
            "Speed: 7.9ms preprocess, 26.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 bicycle, 1 knife, 26.3ms\n",
            "Speed: 3.3ms preprocess, 26.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 bicycle, 1 knife, 33.1ms\n",
            "Speed: 3.5ms preprocess, 33.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 bicycle, 1 knife, 30.4ms\n",
            "Speed: 3.5ms preprocess, 30.4ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 bicycle, 1 knife, 27.9ms\n",
            "Speed: 4.5ms preprocess, 27.9ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 bicycle, 1 knife, 29.8ms\n",
            "Speed: 4.1ms preprocess, 29.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 bicycle, 1 knife, 28.4ms\n",
            "Speed: 3.5ms preprocess, 28.4ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 bicycle, 1 cell phone, 35.6ms\n",
            "Speed: 3.2ms preprocess, 35.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 bicycle, 28.8ms\n",
            "Speed: 3.3ms preprocess, 28.8ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 bicycle, 29.6ms\n",
            "Speed: 3.3ms preprocess, 29.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 bicycle, 29.8ms\n",
            "Speed: 6.1ms preprocess, 29.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 bicycle, 28.4ms\n",
            "Speed: 3.1ms preprocess, 28.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 bicycle, 28.4ms\n",
            "Speed: 3.2ms preprocess, 28.4ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 bicycle, 30.4ms\n",
            "Speed: 3.3ms preprocess, 30.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 bicycle, 28.4ms\n",
            "Speed: 10.7ms preprocess, 28.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 bicycle, 1 potted plant, 31.3ms\n",
            "Speed: 3.3ms preprocess, 31.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 bicycle, 1 potted plant, 30.3ms\n",
            "Speed: 3.2ms preprocess, 30.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 bicycle, 1 potted plant, 28.4ms\n",
            "Speed: 6.3ms preprocess, 28.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 bicycle, 1 potted plant, 31.9ms\n",
            "Speed: 5.0ms preprocess, 31.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 bicycle, 1 potted plant, 28.4ms\n",
            "Speed: 3.4ms preprocess, 28.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 1 potted plant, 28.4ms\n",
            "Speed: 3.2ms preprocess, 28.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 1 handbag, 1 potted plant, 28.5ms\n",
            "Speed: 3.9ms preprocess, 28.5ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bicycle, 1 potted plant, 28.4ms\n",
            "Speed: 3.9ms preprocess, 28.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 bicycle, 1 potted plant, 28.5ms\n",
            "Speed: 3.4ms preprocess, 28.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 bicycle, 1 potted plant, 28.5ms\n",
            "Speed: 3.6ms preprocess, 28.5ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 bicycle, 28.6ms\n",
            "Speed: 9.8ms preprocess, 28.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 bicycle, 29.5ms\n",
            "Speed: 3.2ms preprocess, 29.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 bicycle, 28.4ms\n",
            "Speed: 4.1ms preprocess, 28.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 bicycle, 28.4ms\n",
            "Speed: 4.1ms preprocess, 28.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 bicycle, 28.4ms\n",
            "Speed: 3.9ms preprocess, 28.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 bicycle, 29.6ms\n",
            "Speed: 4.7ms preprocess, 29.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 bicycle, 33.7ms\n",
            "Speed: 3.9ms preprocess, 33.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 motorcycle, 32.0ms\n",
            "Speed: 3.3ms preprocess, 32.0ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 34.3ms\n",
            "Speed: 3.2ms preprocess, 34.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 30.3ms\n",
            "Speed: 3.2ms preprocess, 30.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 30.5ms\n",
            "Speed: 3.3ms preprocess, 30.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 30.5ms\n",
            "Speed: 3.4ms preprocess, 30.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 30.1ms\n",
            "Speed: 3.2ms preprocess, 30.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 29.2ms\n",
            "Speed: 3.3ms preprocess, 29.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 33.6ms\n",
            "Speed: 3.1ms preprocess, 33.6ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 29.2ms\n",
            "Speed: 3.3ms preprocess, 29.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 29.2ms\n",
            "Speed: 3.3ms preprocess, 29.2ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 parking meter, 30.9ms\n",
            "Speed: 3.4ms preprocess, 30.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 parking meter, 29.2ms\n",
            "Speed: 3.2ms preprocess, 29.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 parking meter, 29.2ms\n",
            "Speed: 3.4ms preprocess, 29.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 parking meter, 33.1ms\n",
            "Speed: 3.3ms preprocess, 33.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 parking meter, 29.2ms\n",
            "Speed: 3.2ms preprocess, 29.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 parking meter, 35.6ms\n",
            "Speed: 3.2ms preprocess, 35.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 parking meter, 29.2ms\n",
            "Speed: 3.1ms preprocess, 29.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 parking meter, 29.2ms\n",
            "Speed: 3.3ms preprocess, 29.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 parking meter, 29.2ms\n",
            "Speed: 7.6ms preprocess, 29.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 parking meter, 29.2ms\n",
            "Speed: 10.2ms preprocess, 29.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 parking meter, 31.6ms\n",
            "Speed: 4.5ms preprocess, 31.6ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 parking meter, 1 handbag, 29.4ms\n",
            "Speed: 11.2ms preprocess, 29.4ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 parking meter, 1 handbag, 36.9ms\n",
            "Speed: 3.2ms preprocess, 36.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 parking meter, 1 handbag, 29.2ms\n",
            "Speed: 3.2ms preprocess, 29.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 parking meter, 1 handbag, 29.2ms\n",
            "Speed: 3.4ms preprocess, 29.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 parking meter, 1 handbag, 28.4ms\n",
            "Speed: 3.4ms preprocess, 28.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 parking meter, 1 handbag, 28.4ms\n",
            "Speed: 3.2ms preprocess, 28.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 parking meter, 1 handbag, 28.4ms\n",
            "Speed: 3.1ms preprocess, 28.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 parking meter, 1 handbag, 27.8ms\n",
            "Speed: 6.2ms preprocess, 27.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 parking meter, 1 handbag, 27.9ms\n",
            "Speed: 3.8ms preprocess, 27.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 parking meter, 1 handbag, 27.8ms\n",
            "Speed: 3.2ms preprocess, 27.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 parking meter, 27.7ms\n",
            "Speed: 3.5ms preprocess, 27.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 parking meter, 27.9ms\n",
            "Speed: 3.4ms preprocess, 27.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 parking meter, 27.4ms\n",
            "Speed: 3.2ms preprocess, 27.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 parking meter, 27.4ms\n",
            "Speed: 3.2ms preprocess, 27.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 parking meter, 1 handbag, 27.4ms\n",
            "Speed: 4.0ms preprocess, 27.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 parking meter, 1 handbag, 27.0ms\n",
            "Speed: 3.2ms preprocess, 27.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 parking meter, 1 handbag, 26.5ms\n",
            "Speed: 3.4ms preprocess, 26.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 parking meter, 1 handbag, 26.3ms\n",
            "Speed: 3.6ms preprocess, 26.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 parking meter, 1 handbag, 26.3ms\n",
            "Speed: 3.1ms preprocess, 26.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 parking meter, 1 handbag, 26.3ms\n",
            "Speed: 3.0ms preprocess, 26.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 parking meter, 26.3ms\n",
            "Speed: 3.3ms preprocess, 26.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 parking meter, 26.3ms\n",
            "Speed: 3.2ms preprocess, 26.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 parking meter, 27.1ms\n",
            "Speed: 3.2ms preprocess, 27.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 parking meter, 26.3ms\n",
            "Speed: 3.2ms preprocess, 26.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 parking meter, 26.4ms\n",
            "Speed: 3.9ms preprocess, 26.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 parking meter, 27.3ms\n",
            "Speed: 7.8ms preprocess, 27.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 parking meter, 26.6ms\n",
            "Speed: 3.5ms preprocess, 26.6ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 parking meter, 26.3ms\n",
            "Speed: 3.5ms preprocess, 26.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 parking meter, 26.6ms\n",
            "Speed: 3.2ms preprocess, 26.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 parking meter, 26.3ms\n",
            "Speed: 3.2ms preprocess, 26.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 parking meter, 26.3ms\n",
            "Speed: 3.3ms preprocess, 26.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 parking meter, 26.3ms\n",
            "Speed: 11.3ms preprocess, 26.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 parking meter, 26.3ms\n",
            "Speed: 3.3ms preprocess, 26.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 parking meter, 33.2ms\n",
            "Speed: 3.2ms preprocess, 33.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 parking meter, 26.3ms\n",
            "Speed: 3.3ms preprocess, 26.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 parking meter, 26.3ms\n",
            "Speed: 3.2ms preprocess, 26.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 parking meter, 31.9ms\n",
            "Speed: 3.3ms preprocess, 31.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 parking meter, 26.4ms\n",
            "Speed: 3.1ms preprocess, 26.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 26.3ms\n",
            "Speed: 8.5ms preprocess, 26.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 26.3ms\n",
            "Speed: 3.1ms preprocess, 26.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 29.0ms\n",
            "Speed: 6.0ms preprocess, 29.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 34.4ms\n",
            "Speed: 6.4ms preprocess, 34.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 26.3ms\n",
            "Speed: 3.2ms preprocess, 26.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 27.3ms\n",
            "Speed: 4.1ms preprocess, 27.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 27.7ms\n",
            "Speed: 3.2ms preprocess, 27.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 26.9ms\n",
            "Speed: 3.4ms preprocess, 26.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 26.6ms\n",
            "Speed: 3.3ms preprocess, 26.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 26.6ms\n",
            "Speed: 3.3ms preprocess, 26.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 27.3ms\n",
            "Speed: 3.5ms preprocess, 27.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 27.1ms\n",
            "Speed: 3.3ms preprocess, 27.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 28.9ms\n",
            "Speed: 3.8ms preprocess, 28.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 26.6ms\n",
            "Speed: 3.2ms preprocess, 26.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 26.4ms\n",
            "Speed: 5.0ms preprocess, 26.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 29.2ms\n",
            "Speed: 3.3ms preprocess, 29.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 26.3ms\n",
            "Speed: 3.1ms preprocess, 26.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 26.5ms\n",
            "Speed: 3.3ms preprocess, 26.5ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 34.6ms\n",
            "Speed: 3.1ms preprocess, 34.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 26.7ms\n",
            "Speed: 3.4ms preprocess, 26.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 27.7ms\n",
            "Speed: 3.2ms preprocess, 27.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 26.9ms\n",
            "Speed: 3.2ms preprocess, 26.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 26.7ms\n",
            "Speed: 11.4ms preprocess, 26.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 26.6ms\n",
            "Speed: 3.2ms preprocess, 26.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 27.4ms\n",
            "Speed: 3.3ms preprocess, 27.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 26.5ms\n",
            "Speed: 3.1ms preprocess, 26.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 33.0ms\n",
            "Speed: 3.2ms preprocess, 33.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 26.7ms\n",
            "Speed: 3.2ms preprocess, 26.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 30.8ms\n",
            "Speed: 3.3ms preprocess, 30.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 27.1ms\n",
            "Speed: 3.5ms preprocess, 27.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 26.3ms\n",
            "Speed: 3.4ms preprocess, 26.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 baseball bat, 26.3ms\n",
            "Speed: 3.2ms preprocess, 26.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 baseball bat, 26.3ms\n",
            "Speed: 3.3ms preprocess, 26.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 baseball bat, 26.5ms\n",
            "Speed: 3.1ms preprocess, 26.5ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 1 baseball bat, 26.3ms\n",
            "Speed: 3.3ms preprocess, 26.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 1 baseball bat, 26.3ms\n",
            "Speed: 10.6ms preprocess, 26.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 baseball bat, 26.3ms\n",
            "Speed: 3.1ms preprocess, 26.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 baseball bat, 30.7ms\n",
            "Speed: 3.2ms preprocess, 30.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 1 baseball bat, 26.3ms\n",
            "Speed: 4.5ms preprocess, 26.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 1 baseball bat, 26.3ms\n",
            "Speed: 3.7ms preprocess, 26.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 1 baseball bat, 26.3ms\n",
            "Speed: 6.3ms preprocess, 26.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 1 baseball bat, 26.3ms\n",
            "Speed: 7.0ms preprocess, 26.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 1 baseball bat, 26.5ms\n",
            "Speed: 3.4ms preprocess, 26.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 26.3ms\n",
            "Speed: 3.2ms preprocess, 26.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 26.4ms\n",
            "Speed: 3.2ms preprocess, 26.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 26.3ms\n",
            "Speed: 3.5ms preprocess, 26.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 26.5ms\n",
            "Speed: 3.2ms preprocess, 26.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 26.5ms\n",
            "Speed: 3.2ms preprocess, 26.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 26.2ms\n",
            "Speed: 3.5ms preprocess, 26.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 26.0ms\n",
            "Speed: 3.4ms preprocess, 26.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 25.2ms\n",
            "Speed: 3.8ms preprocess, 25.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 25.5ms\n",
            "Speed: 3.1ms preprocess, 25.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 25.2ms\n",
            "Speed: 3.4ms preprocess, 25.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 25.3ms\n",
            "Speed: 3.1ms preprocess, 25.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 knife, 25.3ms\n",
            "Speed: 3.1ms preprocess, 25.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 knife, 25.3ms\n",
            "Speed: 3.1ms preprocess, 25.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 knife, 25.2ms\n",
            "Speed: 3.3ms preprocess, 25.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 cell phone, 25.3ms\n",
            "Speed: 3.3ms preprocess, 25.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 cell phone, 25.3ms\n",
            "Speed: 3.4ms preprocess, 25.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 25.3ms\n",
            "Speed: 4.5ms preprocess, 25.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 25.3ms\n",
            "Speed: 3.3ms preprocess, 25.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 25.3ms\n",
            "Speed: 3.2ms preprocess, 25.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 25.3ms\n",
            "Speed: 3.8ms preprocess, 25.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 25.3ms\n",
            "Speed: 4.1ms preprocess, 25.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 33.9ms\n",
            "Speed: 3.5ms preprocess, 33.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 25.2ms\n",
            "Speed: 3.3ms preprocess, 25.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 25.3ms\n",
            "Speed: 3.1ms preprocess, 25.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 25.3ms\n",
            "Speed: 3.1ms preprocess, 25.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 25.2ms\n",
            "Speed: 3.3ms preprocess, 25.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 25.3ms\n",
            "Speed: 4.3ms preprocess, 25.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 25.3ms\n",
            "Speed: 3.1ms preprocess, 25.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 25.2ms\n",
            "Speed: 3.3ms preprocess, 25.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 25.0ms\n",
            "Speed: 3.3ms preprocess, 25.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 24.8ms\n",
            "Speed: 3.1ms preprocess, 24.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 23.8ms\n",
            "Speed: 3.1ms preprocess, 23.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 23.9ms\n",
            "Speed: 3.2ms preprocess, 23.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 23.3ms\n",
            "Speed: 4.1ms preprocess, 23.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 22.7ms\n",
            "Speed: 4.3ms preprocess, 22.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 22.8ms\n",
            "Speed: 3.4ms preprocess, 22.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 22.7ms\n",
            "Speed: 3.1ms preprocess, 22.7ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 24.6ms\n",
            "Speed: 3.2ms preprocess, 24.6ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 22.7ms\n",
            "Speed: 5.1ms preprocess, 22.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 22.7ms\n",
            "Speed: 3.1ms preprocess, 22.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 22.8ms\n",
            "Speed: 3.4ms preprocess, 22.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 23.7ms\n",
            "Speed: 3.3ms preprocess, 23.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 22.8ms\n",
            "Speed: 4.3ms preprocess, 22.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 24.6ms\n",
            "Speed: 3.7ms preprocess, 24.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 26.9ms\n",
            "Speed: 3.3ms preprocess, 26.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 23.0ms\n",
            "Speed: 3.8ms preprocess, 23.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 27.3ms\n",
            "Speed: 3.3ms preprocess, 27.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 22.7ms\n",
            "Speed: 3.3ms preprocess, 22.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 22.7ms\n",
            "Speed: 3.1ms preprocess, 22.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 22.9ms\n",
            "Speed: 3.1ms preprocess, 22.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 22.8ms\n",
            "Speed: 3.2ms preprocess, 22.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 28.2ms\n",
            "Speed: 3.2ms preprocess, 28.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 24.2ms\n",
            "Speed: 3.2ms preprocess, 24.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 22.7ms\n",
            "Speed: 3.2ms preprocess, 22.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 22.8ms\n",
            "Speed: 3.4ms preprocess, 22.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 22.8ms\n",
            "Speed: 3.3ms preprocess, 22.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 24.0ms\n",
            "Speed: 3.2ms preprocess, 24.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 22.8ms\n",
            "Speed: 3.3ms preprocess, 22.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 22.8ms\n",
            "Speed: 4.5ms preprocess, 22.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 25.9ms\n",
            "Speed: 3.2ms preprocess, 25.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 22.8ms\n",
            "Speed: 4.0ms preprocess, 22.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 22.5ms\n",
            "Speed: 3.2ms preprocess, 22.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 22.0ms\n",
            "Speed: 3.6ms preprocess, 22.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 22.8ms\n",
            "Speed: 3.3ms preprocess, 22.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 21.8ms\n",
            "Speed: 3.2ms preprocess, 21.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 21.8ms\n",
            "Speed: 3.8ms preprocess, 21.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 21.8ms\n",
            "Speed: 3.7ms preprocess, 21.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 22.2ms\n",
            "Speed: 2.9ms preprocess, 22.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 22.3ms\n",
            "Speed: 9.1ms preprocess, 22.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 24.6ms\n",
            "Speed: 3.1ms preprocess, 24.6ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 21.7ms\n",
            "Speed: 6.5ms preprocess, 21.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 24.0ms\n",
            "Speed: 3.2ms preprocess, 24.0ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 30.8ms\n",
            "Speed: 3.3ms preprocess, 30.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 21.8ms\n",
            "Speed: 3.3ms preprocess, 21.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 24.8ms\n",
            "Speed: 3.4ms preprocess, 24.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 21.8ms\n",
            "Speed: 3.2ms preprocess, 21.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 23.2ms\n",
            "Speed: 4.5ms preprocess, 23.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 23.0ms\n",
            "Speed: 4.2ms preprocess, 23.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 21.8ms\n",
            "Speed: 3.6ms preprocess, 21.8ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 21.8ms\n",
            "Speed: 7.7ms preprocess, 21.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 23.2ms\n",
            "Speed: 3.2ms preprocess, 23.2ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 25.0ms\n",
            "Speed: 3.2ms preprocess, 25.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 34.6ms\n",
            "Speed: 3.3ms preprocess, 34.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 24.5ms\n",
            "Speed: 3.6ms preprocess, 24.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 26.2ms\n",
            "Speed: 3.3ms preprocess, 26.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 27.9ms\n",
            "Speed: 3.4ms preprocess, 27.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 truck, 30.3ms\n",
            "Speed: 3.4ms preprocess, 30.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 car, 1 truck, 1 parking meter, 25.7ms\n",
            "Speed: 3.5ms preprocess, 25.7ms inference, 6.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 car, 1 truck, 1 parking meter, 27.7ms\n",
            "Speed: 3.2ms preprocess, 27.7ms inference, 6.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 car, 1 truck, 1 parking meter, 29.8ms\n",
            "Speed: 4.2ms preprocess, 29.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 car, 1 truck, 1 parking meter, 28.9ms\n",
            "Speed: 3.6ms preprocess, 28.9ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 car, 1 truck, 1 parking meter, 28.3ms\n",
            "Speed: 3.7ms preprocess, 28.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 car, 1 truck, 1 parking meter, 28.2ms\n",
            "Speed: 3.7ms preprocess, 28.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 car, 1 truck, 1 parking meter, 31.1ms\n",
            "Speed: 3.6ms preprocess, 31.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 car, 1 truck, 29.3ms\n",
            "Speed: 3.3ms preprocess, 29.3ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 car, 1 truck, 30.8ms\n",
            "Speed: 3.2ms preprocess, 30.8ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 car, 1 truck, 33.2ms\n",
            "Speed: 5.3ms preprocess, 33.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 car, 1 truck, 29.2ms\n",
            "Speed: 3.6ms preprocess, 29.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 car, 1 truck, 1 parking meter, 29.6ms\n",
            "Speed: 3.3ms preprocess, 29.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 car, 1 truck, 1 parking meter, 29.6ms\n",
            "Speed: 3.3ms preprocess, 29.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 car, 1 truck, 30.1ms\n",
            "Speed: 4.4ms preprocess, 30.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 car, 1 truck, 30.1ms\n",
            "Speed: 4.6ms preprocess, 30.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 1 car, 1 truck, 1 parking meter, 31.6ms\n",
            "Speed: 3.3ms preprocess, 31.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 1 car, 1 truck, 1 parking meter, 31.2ms\n",
            "Speed: 3.3ms preprocess, 31.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 1 car, 1 truck, 1 parking meter, 31.5ms\n",
            "Speed: 4.9ms preprocess, 31.5ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 1 car, 1 truck, 1 parking meter, 34.0ms\n",
            "Speed: 5.9ms preprocess, 34.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 1 car, 1 truck, 1 parking meter, 32.0ms\n",
            "Speed: 3.8ms preprocess, 32.0ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 1 car, 1 truck, 1 parking meter, 32.0ms\n",
            "Speed: 4.6ms preprocess, 32.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 1 car, 1 truck, 1 parking meter, 31.9ms\n",
            "Speed: 3.2ms preprocess, 31.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 1 car, 1 truck, 1 parking meter, 32.0ms\n",
            "Speed: 3.4ms preprocess, 32.0ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 1 car, 1 truck, 1 parking meter, 32.5ms\n",
            "Speed: 4.7ms preprocess, 32.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 32.5ms\n",
            "Speed: 4.9ms preprocess, 32.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 33.0ms\n",
            "Speed: 4.8ms preprocess, 33.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 33.7ms\n",
            "Speed: 3.2ms preprocess, 33.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 33.6ms\n",
            "Speed: 3.3ms preprocess, 33.6ms inference, 5.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 33.7ms\n",
            "Speed: 4.1ms preprocess, 33.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 34.8ms\n",
            "Speed: 3.6ms preprocess, 34.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 34.8ms\n",
            "Speed: 3.8ms preprocess, 34.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 34.3ms\n",
            "Speed: 4.0ms preprocess, 34.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 34.2ms\n",
            "Speed: 3.6ms preprocess, 34.2ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 34.8ms\n",
            "Speed: 3.4ms preprocess, 34.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 34.9ms\n",
            "Speed: 3.2ms preprocess, 34.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 39.3ms\n",
            "Speed: 3.6ms preprocess, 39.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 35.0ms\n",
            "Speed: 3.7ms preprocess, 35.0ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 36.8ms\n",
            "Speed: 3.3ms preprocess, 36.8ms inference, 5.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 37.4ms\n",
            "Speed: 3.4ms preprocess, 37.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 35.5ms\n",
            "Speed: 3.5ms preprocess, 35.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 36.6ms\n",
            "Speed: 3.1ms preprocess, 36.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 35.5ms\n",
            "Speed: 3.5ms preprocess, 35.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 35.5ms\n",
            "Speed: 3.3ms preprocess, 35.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 36.2ms\n",
            "Speed: 3.0ms preprocess, 36.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 36.1ms\n",
            "Speed: 3.1ms preprocess, 36.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 36.2ms\n",
            "Speed: 4.3ms preprocess, 36.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 car, 1 truck, 36.1ms\n",
            "Speed: 3.4ms preprocess, 36.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 car, 1 truck, 37.4ms\n",
            "Speed: 3.2ms preprocess, 37.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 car, 38.6ms\n",
            "Speed: 3.2ms preprocess, 38.6ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 car, 36.7ms\n",
            "Speed: 6.2ms preprocess, 36.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 car, 38.5ms\n",
            "Speed: 5.4ms preprocess, 38.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 car, 35.5ms\n",
            "Speed: 5.9ms preprocess, 35.5ms inference, 7.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 car, 35.4ms\n",
            "Speed: 6.3ms preprocess, 35.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 car, 34.4ms\n",
            "Speed: 4.6ms preprocess, 34.4ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 car, 36.7ms\n",
            "Speed: 3.2ms preprocess, 36.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 car, 32.5ms\n",
            "Speed: 3.3ms preprocess, 32.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 car, 32.5ms\n",
            "Speed: 6.3ms preprocess, 32.5ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 car, 32.5ms\n",
            "Speed: 5.7ms preprocess, 32.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 car, 32.6ms\n",
            "Speed: 3.2ms preprocess, 32.6ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 car, 33.0ms\n",
            "Speed: 6.5ms preprocess, 33.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 car, 32.3ms\n",
            "Speed: 3.3ms preprocess, 32.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 car, 32.7ms\n",
            "Speed: 3.2ms preprocess, 32.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 car, 31.0ms\n",
            "Speed: 6.2ms preprocess, 31.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 car, 32.3ms\n",
            "Speed: 6.0ms preprocess, 32.3ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 car, 31.0ms\n",
            "Speed: 3.9ms preprocess, 31.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 car, 30.7ms\n",
            "Speed: 4.4ms preprocess, 30.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 car, 33.8ms\n",
            "Speed: 3.3ms preprocess, 33.8ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 car, 33.6ms\n",
            "Speed: 6.1ms preprocess, 33.6ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 car, 30.2ms\n",
            "Speed: 4.1ms preprocess, 30.2ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 car, 30.1ms\n",
            "Speed: 3.2ms preprocess, 30.1ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 car, 30.0ms\n",
            "Speed: 4.3ms preprocess, 30.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 car, 30.0ms\n",
            "Speed: 3.2ms preprocess, 30.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 car, 30.0ms\n",
            "Speed: 3.6ms preprocess, 30.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 car, 27.9ms\n",
            "Speed: 5.0ms preprocess, 27.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 car, 27.2ms\n",
            "Speed: 8.5ms preprocess, 27.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 car, 27.0ms\n",
            "Speed: 3.5ms preprocess, 27.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 car, 26.9ms\n",
            "Speed: 3.2ms preprocess, 26.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 car, 26.9ms\n",
            "Speed: 3.5ms preprocess, 26.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 car, 27.1ms\n",
            "Speed: 3.3ms preprocess, 27.1ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 car, 26.7ms\n",
            "Speed: 3.3ms preprocess, 26.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 car, 26.3ms\n",
            "Speed: 6.6ms preprocess, 26.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 car, 26.4ms\n",
            "Speed: 3.3ms preprocess, 26.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 car, 26.3ms\n",
            "Speed: 3.0ms preprocess, 26.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 car, 26.4ms\n",
            "Speed: 3.5ms preprocess, 26.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 car, 26.3ms\n",
            "Speed: 3.7ms preprocess, 26.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 car, 26.3ms\n",
            "Speed: 3.2ms preprocess, 26.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 car, 26.3ms\n",
            "Speed: 3.3ms preprocess, 26.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 car, 27.7ms\n",
            "Speed: 3.4ms preprocess, 27.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 car, 26.3ms\n",
            "Speed: 3.3ms preprocess, 26.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 car, 26.4ms\n",
            "Speed: 3.3ms preprocess, 26.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 car, 26.3ms\n",
            "Speed: 3.2ms preprocess, 26.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 car, 26.3ms\n",
            "Speed: 3.2ms preprocess, 26.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 car, 27.2ms\n",
            "Speed: 3.3ms preprocess, 27.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 car, 28.0ms\n",
            "Speed: 3.5ms preprocess, 28.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 car, 26.6ms\n",
            "Speed: 3.1ms preprocess, 26.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 car, 26.3ms\n",
            "Speed: 3.3ms preprocess, 26.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 1 car, 1 truck, 29.3ms\n",
            "Speed: 4.0ms preprocess, 29.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 1 car, 1 truck, 26.3ms\n",
            "Speed: 3.0ms preprocess, 26.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 1 car, 26.3ms\n",
            "Speed: 3.2ms preprocess, 26.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 1 car, 26.3ms\n",
            "Speed: 3.2ms preprocess, 26.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 1 car, 26.3ms\n",
            "Speed: 4.0ms preprocess, 26.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 car, 26.3ms\n",
            "Speed: 3.3ms preprocess, 26.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 car, 26.3ms\n",
            "Speed: 3.3ms preprocess, 26.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 car, 26.3ms\n",
            "Speed: 3.8ms preprocess, 26.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 car, 26.3ms\n",
            "Speed: 3.3ms preprocess, 26.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 car, 1 truck, 25.7ms\n",
            "Speed: 3.5ms preprocess, 25.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 car, 1 truck, 25.4ms\n",
            "Speed: 8.9ms preprocess, 25.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 car, 1 truck, 24.7ms\n",
            "Speed: 3.6ms preprocess, 24.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 car, 1 truck, 24.7ms\n",
            "Speed: 3.3ms preprocess, 24.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 car, 24.7ms\n",
            "Speed: 3.2ms preprocess, 24.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 car, 24.7ms\n",
            "Speed: 3.3ms preprocess, 24.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 car, 24.7ms\n",
            "Speed: 3.3ms preprocess, 24.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 car, 26.7ms\n",
            "Speed: 6.6ms preprocess, 26.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 car, 24.7ms\n",
            "Speed: 3.1ms preprocess, 24.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 car, 24.7ms\n",
            "Speed: 3.5ms preprocess, 24.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 car, 24.7ms\n",
            "Speed: 3.0ms preprocess, 24.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 car, 24.6ms\n",
            "Speed: 5.3ms preprocess, 24.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 car, 24.6ms\n",
            "Speed: 3.4ms preprocess, 24.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 car, 23.7ms\n",
            "Speed: 3.1ms preprocess, 23.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 car, 23.2ms\n",
            "Speed: 3.2ms preprocess, 23.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 car, 23.1ms\n",
            "Speed: 3.4ms preprocess, 23.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 car, 23.2ms\n",
            "Speed: 4.2ms preprocess, 23.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 car, 23.2ms\n",
            "Speed: 3.3ms preprocess, 23.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 car, 23.2ms\n",
            "Speed: 3.3ms preprocess, 23.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 car, 23.2ms\n",
            "Speed: 2.9ms preprocess, 23.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 car, 23.3ms\n",
            "Speed: 3.4ms preprocess, 23.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 car, 23.1ms\n",
            "Speed: 3.3ms preprocess, 23.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 car, 23.2ms\n",
            "Speed: 3.1ms preprocess, 23.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 car, 23.9ms\n",
            "Speed: 3.3ms preprocess, 23.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 car, 23.2ms\n",
            "Speed: 3.4ms preprocess, 23.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 car, 28.0ms\n",
            "Speed: 4.0ms preprocess, 28.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 car, 23.1ms\n",
            "Speed: 3.2ms preprocess, 23.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 car, 23.2ms\n",
            "Speed: 3.4ms preprocess, 23.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 car, 23.2ms\n",
            "Speed: 4.8ms preprocess, 23.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 car, 23.2ms\n",
            "Speed: 3.3ms preprocess, 23.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 car, 23.1ms\n",
            "Speed: 3.2ms preprocess, 23.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 car, 23.2ms\n",
            "Speed: 3.4ms preprocess, 23.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 car, 23.2ms\n",
            "Speed: 3.3ms preprocess, 23.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 car, 23.2ms\n",
            "Speed: 3.4ms preprocess, 23.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 car, 23.2ms\n",
            "Speed: 4.4ms preprocess, 23.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 car, 23.4ms\n",
            "Speed: 3.3ms preprocess, 23.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 car, 26.4ms\n",
            "Speed: 3.5ms preprocess, 26.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 22.0ms\n",
            "Speed: 3.3ms preprocess, 22.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 28.8ms\n",
            "Speed: 3.5ms preprocess, 28.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 22.2ms\n",
            "Speed: 3.3ms preprocess, 22.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 30.8ms\n",
            "Speed: 9.3ms preprocess, 30.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 22.0ms\n",
            "Speed: 8.1ms preprocess, 22.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 22.0ms\n",
            "Speed: 3.2ms preprocess, 22.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 22.0ms\n",
            "Speed: 3.2ms preprocess, 22.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 22.0ms\n",
            "Speed: 3.3ms preprocess, 22.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 22.0ms\n",
            "Speed: 3.3ms preprocess, 22.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 22.0ms\n",
            "Speed: 3.2ms preprocess, 22.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 22.0ms\n",
            "Speed: 3.2ms preprocess, 22.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 22.0ms\n",
            "Speed: 3.8ms preprocess, 22.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 22.0ms\n",
            "Speed: 3.4ms preprocess, 22.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 21.9ms\n",
            "Speed: 3.2ms preprocess, 21.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 22.0ms\n",
            "Speed: 3.1ms preprocess, 22.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 22.5ms\n",
            "Speed: 3.2ms preprocess, 22.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 22.5ms\n",
            "Speed: 3.3ms preprocess, 22.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 26.5ms\n",
            "Speed: 3.8ms preprocess, 26.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 22.0ms\n",
            "Speed: 3.2ms preprocess, 22.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 30.0ms\n",
            "Speed: 3.2ms preprocess, 30.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 22.1ms\n",
            "Speed: 4.0ms preprocess, 22.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 22.0ms\n",
            "Speed: 3.1ms preprocess, 22.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 22.0ms\n",
            "Speed: 4.9ms preprocess, 22.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 26.6ms\n",
            "Speed: 3.3ms preprocess, 26.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 22.4ms\n",
            "Speed: 3.1ms preprocess, 22.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 24.8ms\n",
            "Speed: 10.2ms preprocess, 24.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 24.8ms\n",
            "Speed: 3.4ms preprocess, 24.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 23.9ms\n",
            "Speed: 6.4ms preprocess, 23.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 24.4ms\n",
            "Speed: 4.9ms preprocess, 24.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 24.0ms\n",
            "Speed: 3.3ms preprocess, 24.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 23.9ms\n",
            "Speed: 3.8ms preprocess, 23.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 24.7ms\n",
            "Speed: 3.3ms preprocess, 24.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 24.8ms\n",
            "Speed: 4.5ms preprocess, 24.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 24.4ms\n",
            "Speed: 3.2ms preprocess, 24.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 24.1ms\n",
            "Speed: 6.1ms preprocess, 24.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 24.2ms\n",
            "Speed: 3.2ms preprocess, 24.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 24.1ms\n",
            "Speed: 3.6ms preprocess, 24.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 25.3ms\n",
            "Speed: 3.5ms preprocess, 25.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 25.3ms\n",
            "Speed: 3.8ms preprocess, 25.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 24.4ms\n",
            "Speed: 4.5ms preprocess, 24.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 24.4ms\n",
            "Speed: 3.2ms preprocess, 24.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 24.4ms\n",
            "Speed: 3.2ms preprocess, 24.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 24.4ms\n",
            "Speed: 3.1ms preprocess, 24.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 24.2ms\n",
            "Speed: 3.3ms preprocess, 24.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 24.2ms\n",
            "Speed: 3.8ms preprocess, 24.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 23.9ms\n",
            "Speed: 3.3ms preprocess, 23.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 28.7ms\n",
            "Speed: 3.3ms preprocess, 28.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 23.6ms\n",
            "Speed: 3.3ms preprocess, 23.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 23.6ms\n",
            "Speed: 12.0ms preprocess, 23.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 23.6ms\n",
            "Speed: 3.4ms preprocess, 23.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 23.6ms\n",
            "Speed: 4.2ms preprocess, 23.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 25.1ms\n",
            "Speed: 3.1ms preprocess, 25.1ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 23.6ms\n",
            "Speed: 3.5ms preprocess, 23.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 23.6ms\n",
            "Speed: 3.1ms preprocess, 23.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 23.6ms\n",
            "Speed: 3.2ms preprocess, 23.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 27.0ms\n",
            "Speed: 3.3ms preprocess, 27.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 23.9ms\n",
            "Speed: 3.1ms preprocess, 23.9ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 24.7ms\n",
            "Speed: 3.5ms preprocess, 24.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 26.3ms\n",
            "Speed: 3.3ms preprocess, 26.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 23.6ms\n",
            "Speed: 3.5ms preprocess, 23.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 tie, 23.6ms\n",
            "Speed: 7.3ms preprocess, 23.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 tie, 23.7ms\n",
            "Speed: 3.6ms preprocess, 23.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 tie, 23.6ms\n",
            "Speed: 3.4ms preprocess, 23.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 tie, 23.8ms\n",
            "Speed: 5.2ms preprocess, 23.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 1 tie, 23.7ms\n",
            "Speed: 5.6ms preprocess, 23.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 1 tie, 26.7ms\n",
            "Speed: 4.9ms preprocess, 26.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 1 tie, 30.3ms\n",
            "Speed: 4.8ms preprocess, 30.3ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 1 tie, 25.3ms\n",
            "Speed: 3.3ms preprocess, 25.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 tie, 23.6ms\n",
            "Speed: 7.8ms preprocess, 23.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 tie, 29.9ms\n",
            "Speed: 6.6ms preprocess, 29.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 tie, 25.7ms\n",
            "Speed: 13.9ms preprocess, 25.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 tie, 28.5ms\n",
            "Speed: 3.2ms preprocess, 28.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 tie, 26.3ms\n",
            "Speed: 3.4ms preprocess, 26.3ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 tie, 37.3ms\n",
            "Speed: 3.3ms preprocess, 37.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 tie, 27.3ms\n",
            "Speed: 5.1ms preprocess, 27.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 tie, 27.3ms\n",
            "Speed: 3.4ms preprocess, 27.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 tie, 29.8ms\n",
            "Speed: 4.4ms preprocess, 29.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 1 tie, 27.0ms\n",
            "Speed: 3.3ms preprocess, 27.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 1 tie, 26.6ms\n",
            "Speed: 9.3ms preprocess, 26.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 1 tie, 27.2ms\n",
            "Speed: 6.2ms preprocess, 27.2ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 1 tie, 37.4ms\n",
            "Speed: 3.2ms preprocess, 37.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 1 tie, 26.7ms\n",
            "Speed: 4.5ms preprocess, 26.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 1 tie, 27.2ms\n",
            "Speed: 6.1ms preprocess, 27.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 1 tie, 27.4ms\n",
            "Speed: 3.2ms preprocess, 27.4ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 1 tie, 31.0ms\n",
            "Speed: 6.4ms preprocess, 31.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 tie, 26.6ms\n",
            "Speed: 4.3ms preprocess, 26.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 26.6ms\n",
            "Speed: 5.6ms preprocess, 26.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 27.6ms\n",
            "Speed: 4.0ms preprocess, 27.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 26.6ms\n",
            "Speed: 5.9ms preprocess, 26.6ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 26.6ms\n",
            "Speed: 6.9ms preprocess, 26.6ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 26.6ms\n",
            "Speed: 4.4ms preprocess, 26.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 26.6ms\n",
            "Speed: 7.3ms preprocess, 26.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 26.6ms\n",
            "Speed: 4.4ms preprocess, 26.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 26.6ms\n",
            "Speed: 4.1ms preprocess, 26.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 26.6ms\n",
            "Speed: 6.5ms preprocess, 26.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 26.6ms\n",
            "Speed: 4.2ms preprocess, 26.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 26.5ms\n",
            "Speed: 3.3ms preprocess, 26.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 27.1ms\n",
            "Speed: 3.3ms preprocess, 27.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 26.3ms\n",
            "Speed: 3.7ms preprocess, 26.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 27.7ms\n",
            "Speed: 3.3ms preprocess, 27.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 28.6ms\n",
            "Speed: 3.4ms preprocess, 28.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 30.0ms\n",
            "Speed: 3.4ms preprocess, 30.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 27.9ms\n",
            "Speed: 3.3ms preprocess, 27.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 26.6ms\n",
            "Speed: 3.5ms preprocess, 26.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 26.3ms\n",
            "Speed: 6.5ms preprocess, 26.3ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 27.5ms\n",
            "Speed: 6.2ms preprocess, 27.5ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 26.4ms\n",
            "Speed: 3.2ms preprocess, 26.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 26.3ms\n",
            "Speed: 4.1ms preprocess, 26.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 26.3ms\n",
            "Speed: 3.9ms preprocess, 26.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 27.7ms\n",
            "Speed: 6.0ms preprocess, 27.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 26.3ms\n",
            "Speed: 5.6ms preprocess, 26.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 26.3ms\n",
            "Speed: 4.1ms preprocess, 26.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 handbags, 26.3ms\n",
            "Speed: 4.2ms preprocess, 26.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 handbags, 26.3ms\n",
            "Speed: 3.3ms preprocess, 26.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 26.3ms\n",
            "Speed: 3.3ms preprocess, 26.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 30.0ms\n",
            "Speed: 3.3ms preprocess, 30.0ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 26.3ms\n",
            "Speed: 3.2ms preprocess, 26.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 26.4ms\n",
            "Speed: 3.6ms preprocess, 26.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 26.3ms\n",
            "Speed: 4.1ms preprocess, 26.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 29.1ms\n",
            "Speed: 3.8ms preprocess, 29.1ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 26.4ms\n",
            "Speed: 3.6ms preprocess, 26.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 26.3ms\n",
            "Speed: 5.8ms preprocess, 26.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 26.4ms\n",
            "Speed: 3.9ms preprocess, 26.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 34.3ms\n",
            "Speed: 3.3ms preprocess, 34.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 26.4ms\n",
            "Speed: 3.3ms preprocess, 26.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 28.0ms\n",
            "Speed: 4.5ms preprocess, 28.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 26.9ms\n",
            "Speed: 3.4ms preprocess, 26.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 27.9ms\n",
            "Speed: 4.2ms preprocess, 27.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 27.9ms\n",
            "Speed: 4.3ms preprocess, 27.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 27.7ms\n",
            "Speed: 3.6ms preprocess, 27.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 27.0ms\n",
            "Speed: 3.3ms preprocess, 27.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 27.0ms\n",
            "Speed: 3.4ms preprocess, 27.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 26.3ms\n",
            "Speed: 3.3ms preprocess, 26.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 27.7ms\n",
            "Speed: 4.1ms preprocess, 27.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 26.3ms\n",
            "Speed: 3.5ms preprocess, 26.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 26.3ms\n",
            "Speed: 3.4ms preprocess, 26.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 26.3ms\n",
            "Speed: 3.3ms preprocess, 26.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 26.3ms\n",
            "Speed: 3.7ms preprocess, 26.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 26.3ms\n",
            "Speed: 3.5ms preprocess, 26.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 26.4ms\n",
            "Speed: 3.4ms preprocess, 26.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 26.5ms\n",
            "Speed: 3.3ms preprocess, 26.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 26.5ms\n",
            "Speed: 3.2ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 25.9ms\n",
            "Speed: 3.3ms preprocess, 25.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 25.4ms\n",
            "Speed: 3.3ms preprocess, 25.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 24.8ms\n",
            "Speed: 3.2ms preprocess, 24.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 24.6ms\n",
            "Speed: 3.3ms preprocess, 24.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 24.3ms\n",
            "Speed: 3.3ms preprocess, 24.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 23.1ms\n",
            "Speed: 3.7ms preprocess, 23.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 23.4ms\n",
            "Speed: 3.2ms preprocess, 23.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 23.3ms\n",
            "Speed: 3.8ms preprocess, 23.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 23.1ms\n",
            "Speed: 3.6ms preprocess, 23.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 23.1ms\n",
            "Speed: 3.4ms preprocess, 23.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 23.1ms\n",
            "Speed: 3.4ms preprocess, 23.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 23.2ms\n",
            "Speed: 3.9ms preprocess, 23.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 23.2ms\n",
            "Speed: 3.5ms preprocess, 23.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 22.9ms\n",
            "Speed: 3.9ms preprocess, 22.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 22.6ms\n",
            "Speed: 3.8ms preprocess, 22.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 22.5ms\n",
            "Speed: 3.2ms preprocess, 22.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 22.4ms\n",
            "Speed: 3.1ms preprocess, 22.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 22.3ms\n",
            "Speed: 3.6ms preprocess, 22.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 22.3ms\n",
            "Speed: 3.2ms preprocess, 22.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 22.3ms\n",
            "Speed: 4.5ms preprocess, 22.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 22.3ms\n",
            "Speed: 3.4ms preprocess, 22.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 22.3ms\n",
            "Speed: 3.3ms preprocess, 22.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 26.3ms\n",
            "Speed: 3.2ms preprocess, 26.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 22.4ms\n",
            "Speed: 3.9ms preprocess, 22.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 22.3ms\n",
            "Speed: 5.3ms preprocess, 22.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 22.4ms\n",
            "Speed: 3.4ms preprocess, 22.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 22.3ms\n",
            "Speed: 5.9ms preprocess, 22.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 22.3ms\n",
            "Speed: 3.3ms preprocess, 22.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 22.4ms\n",
            "Speed: 3.1ms preprocess, 22.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 22.4ms\n",
            "Speed: 3.3ms preprocess, 22.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 22.3ms\n",
            "Speed: 3.3ms preprocess, 22.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 22.4ms\n",
            "Speed: 3.8ms preprocess, 22.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 22.4ms\n",
            "Speed: 3.3ms preprocess, 22.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 22.3ms\n",
            "Speed: 4.9ms preprocess, 22.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 22.3ms\n",
            "Speed: 3.2ms preprocess, 22.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 22.3ms\n",
            "Speed: 3.3ms preprocess, 22.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 22.3ms\n",
            "Speed: 3.2ms preprocess, 22.3ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 22.3ms\n",
            "Speed: 3.3ms preprocess, 22.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 22.8ms\n",
            "Speed: 3.3ms preprocess, 22.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 22.5ms\n",
            "Speed: 3.2ms preprocess, 22.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 22.3ms\n",
            "Speed: 3.9ms preprocess, 22.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 23.4ms\n",
            "Speed: 4.1ms preprocess, 23.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 23.4ms\n",
            "Speed: 4.3ms preprocess, 23.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 handbags, 22.9ms\n",
            "Speed: 3.8ms preprocess, 22.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 handbags, 23.6ms\n",
            "Speed: 3.3ms preprocess, 23.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 handbags, 23.7ms\n",
            "Speed: 4.5ms preprocess, 23.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 handbags, 24.9ms\n",
            "Speed: 4.6ms preprocess, 24.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 handbags, 25.6ms\n",
            "Speed: 3.6ms preprocess, 25.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 handbags, 24.2ms\n",
            "Speed: 3.2ms preprocess, 24.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 handbags, 23.3ms\n",
            "Speed: 3.3ms preprocess, 23.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 handbags, 24.0ms\n",
            "Speed: 3.6ms preprocess, 24.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 handbags, 23.7ms\n",
            "Speed: 3.2ms preprocess, 23.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 handbags, 23.3ms\n",
            "Speed: 3.4ms preprocess, 23.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 handbags, 23.1ms\n",
            "Speed: 3.1ms preprocess, 23.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 handbags, 23.3ms\n",
            "Speed: 3.4ms preprocess, 23.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 handbags, 23.0ms\n",
            "Speed: 3.4ms preprocess, 23.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 handbags, 22.7ms\n",
            "Speed: 3.2ms preprocess, 22.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 handbags, 25.3ms\n",
            "Speed: 3.3ms preprocess, 25.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 handbags, 23.4ms\n",
            "Speed: 4.3ms preprocess, 23.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 handbags, 22.7ms\n",
            "Speed: 3.2ms preprocess, 22.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 handbags, 22.7ms\n",
            "Speed: 3.6ms preprocess, 22.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 handbags, 22.7ms\n",
            "Speed: 11.2ms preprocess, 22.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 handbags, 22.7ms\n",
            "Speed: 3.2ms preprocess, 22.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 handbags, 22.7ms\n",
            "Speed: 3.2ms preprocess, 22.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 handbags, 22.7ms\n",
            "Speed: 3.2ms preprocess, 22.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 22.7ms\n",
            "Speed: 3.3ms preprocess, 22.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 22.7ms\n",
            "Speed: 3.3ms preprocess, 22.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 22.7ms\n",
            "Speed: 3.2ms preprocess, 22.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 22.7ms\n",
            "Speed: 3.3ms preprocess, 22.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 22.7ms\n",
            "Speed: 6.5ms preprocess, 22.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 22.8ms\n",
            "Speed: 3.1ms preprocess, 22.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 26.0ms\n",
            "Speed: 3.4ms preprocess, 26.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 22.7ms\n",
            "Speed: 3.2ms preprocess, 22.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 24.0ms\n",
            "Speed: 3.4ms preprocess, 24.0ms inference, 6.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 22.7ms\n",
            "Speed: 3.3ms preprocess, 22.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 22.8ms\n",
            "Speed: 3.4ms preprocess, 22.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 22.7ms\n",
            "Speed: 3.3ms preprocess, 22.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 22.8ms\n",
            "Speed: 6.8ms preprocess, 22.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 22.7ms\n",
            "Speed: 3.2ms preprocess, 22.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 22.7ms\n",
            "Speed: 3.1ms preprocess, 22.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 22.8ms\n",
            "Speed: 3.0ms preprocess, 22.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 22.7ms\n",
            "Speed: 6.5ms preprocess, 22.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 22.5ms\n",
            "Speed: 3.3ms preprocess, 22.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 22.2ms\n",
            "Speed: 3.8ms preprocess, 22.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 21.7ms\n",
            "Speed: 3.1ms preprocess, 21.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 22.0ms\n",
            "Speed: 3.1ms preprocess, 22.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 22.1ms\n",
            "Speed: 4.5ms preprocess, 22.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 21.8ms\n",
            "Speed: 3.7ms preprocess, 21.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 21.7ms\n",
            "Speed: 3.2ms preprocess, 21.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 21.7ms\n",
            "Speed: 3.1ms preprocess, 21.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 31.1ms\n",
            "Speed: 3.3ms preprocess, 31.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 22.4ms\n",
            "Speed: 3.4ms preprocess, 22.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 21.7ms\n",
            "Speed: 4.5ms preprocess, 21.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 22.5ms\n",
            "Speed: 3.1ms preprocess, 22.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 22.5ms\n",
            "Speed: 3.4ms preprocess, 22.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 22.1ms\n",
            "Speed: 3.3ms preprocess, 22.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 21.8ms\n",
            "Speed: 3.2ms preprocess, 21.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 21.6ms\n",
            "Speed: 3.3ms preprocess, 21.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 22.1ms\n",
            "Speed: 3.1ms preprocess, 22.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 22.1ms\n",
            "Speed: 3.4ms preprocess, 22.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 21.6ms\n",
            "Speed: 6.3ms preprocess, 21.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 21.6ms\n",
            "Speed: 4.2ms preprocess, 21.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 21.5ms\n",
            "Speed: 3.5ms preprocess, 21.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 21.6ms\n",
            "Speed: 3.3ms preprocess, 21.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 21.5ms\n",
            "Speed: 8.9ms preprocess, 21.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 21.5ms\n",
            "Speed: 3.3ms preprocess, 21.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 27.6ms\n",
            "Speed: 3.3ms preprocess, 27.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 21.7ms\n",
            "Speed: 3.3ms preprocess, 21.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 21.5ms\n",
            "Speed: 3.2ms preprocess, 21.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 21.7ms\n",
            "Speed: 3.8ms preprocess, 21.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 21.5ms\n",
            "Speed: 3.3ms preprocess, 21.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 21.5ms\n",
            "Speed: 3.5ms preprocess, 21.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 21.6ms\n",
            "Speed: 4.2ms preprocess, 21.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 21.5ms\n",
            "Speed: 10.2ms preprocess, 21.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 24.6ms\n",
            "Speed: 3.1ms preprocess, 24.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 22.7ms\n",
            "Speed: 3.2ms preprocess, 22.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 21.8ms\n",
            "Speed: 3.3ms preprocess, 21.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 21.5ms\n",
            "Speed: 10.0ms preprocess, 21.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 21.5ms\n",
            "Speed: 3.2ms preprocess, 21.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 21.5ms\n",
            "Speed: 3.2ms preprocess, 21.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 22.1ms\n",
            "Speed: 3.7ms preprocess, 22.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 22.3ms\n",
            "Speed: 3.2ms preprocess, 22.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 21.5ms\n",
            "Speed: 3.3ms preprocess, 21.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 22.9ms\n",
            "Speed: 5.5ms preprocess, 22.9ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 23.0ms\n",
            "Speed: 3.2ms preprocess, 23.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 22.4ms\n",
            "Speed: 3.2ms preprocess, 22.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 22.9ms\n",
            "Speed: 4.4ms preprocess, 22.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 23.3ms\n",
            "Speed: 4.1ms preprocess, 23.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 22.8ms\n",
            "Speed: 3.5ms preprocess, 22.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 22.7ms\n",
            "Speed: 3.7ms preprocess, 22.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 22.7ms\n",
            "Speed: 3.5ms preprocess, 22.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 22.7ms\n",
            "Speed: 3.2ms preprocess, 22.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 22.7ms\n",
            "Speed: 3.6ms preprocess, 22.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 22.7ms\n",
            "Speed: 3.1ms preprocess, 22.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 22.7ms\n",
            "Speed: 3.0ms preprocess, 22.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 1 couch, 3 books, 22.7ms\n",
            "Speed: 3.5ms preprocess, 22.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 1 couch, 3 books, 22.7ms\n",
            "Speed: 9.0ms preprocess, 22.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 1 couch, 3 books, 28.9ms\n",
            "Speed: 3.3ms preprocess, 28.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 1 couch, 3 books, 23.4ms\n",
            "Speed: 3.3ms preprocess, 23.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 1 couch, 3 books, 24.2ms\n",
            "Speed: 3.2ms preprocess, 24.2ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 1 couch, 3 books, 27.2ms\n",
            "Speed: 3.2ms preprocess, 27.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 1 couch, 3 books, 25.3ms\n",
            "Speed: 3.3ms preprocess, 25.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 1 couch, 3 books, 23.6ms\n",
            "Speed: 3.4ms preprocess, 23.6ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 1 couch, 3 books, 28.6ms\n",
            "Speed: 6.5ms preprocess, 28.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 1 couch, 1 laptop, 3 books, 26.4ms\n",
            "Speed: 7.0ms preprocess, 26.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 1 couch, 1 laptop, 3 books, 25.9ms\n",
            "Speed: 3.3ms preprocess, 25.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 1 couch, 1 laptop, 3 books, 29.1ms\n",
            "Speed: 3.4ms preprocess, 29.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 1 couch, 1 laptop, 3 books, 26.4ms\n",
            "Speed: 10.8ms preprocess, 26.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 1 couch, 1 laptop, 3 books, 26.1ms\n",
            "Speed: 9.7ms preprocess, 26.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 1 couch, 1 laptop, 3 books, 25.9ms\n",
            "Speed: 5.1ms preprocess, 25.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 1 couch, 1 laptop, 3 books, 26.5ms\n",
            "Speed: 3.2ms preprocess, 26.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 1 couch, 1 laptop, 3 books, 27.8ms\n",
            "Speed: 3.4ms preprocess, 27.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 1 couch, 1 laptop, 3 books, 27.8ms\n",
            "Speed: 3.2ms preprocess, 27.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 1 couch, 1 laptop, 3 books, 26.9ms\n",
            "Speed: 3.1ms preprocess, 26.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 1 couch, 1 laptop, 3 books, 27.8ms\n",
            "Speed: 7.3ms preprocess, 27.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 1 couch, 1 laptop, 3 books, 27.2ms\n",
            "Speed: 8.2ms preprocess, 27.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 1 couch, 1 laptop, 3 books, 28.2ms\n",
            "Speed: 3.1ms preprocess, 28.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 1 couch, 1 laptop, 3 books, 28.1ms\n",
            "Speed: 3.5ms preprocess, 28.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 2 couchs, 1 laptop, 3 books, 28.3ms\n",
            "Speed: 3.1ms preprocess, 28.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 3 couchs, 1 laptop, 3 books, 31.3ms\n",
            "Speed: 3.1ms preprocess, 31.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 3 couchs, 1 laptop, 3 books, 28.6ms\n",
            "Speed: 3.4ms preprocess, 28.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 3 couchs, 1 laptop, 3 books, 30.5ms\n",
            "Speed: 3.2ms preprocess, 30.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 2 couchs, 1 laptop, 3 books, 29.3ms\n",
            "Speed: 3.2ms preprocess, 29.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 2 couchs, 1 laptop, 4 books, 31.6ms\n",
            "Speed: 3.3ms preprocess, 31.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 2 couchs, 4 books, 29.2ms\n",
            "Speed: 3.5ms preprocess, 29.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 2 couchs, 4 books, 33.0ms\n",
            "Speed: 3.8ms preprocess, 33.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 2 couchs, 4 books, 30.8ms\n",
            "Speed: 3.4ms preprocess, 30.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 31.0ms\n",
            "Speed: 3.1ms preprocess, 31.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 5 bottles, 1 cup, 1 chair, 32.7ms\n",
            "Speed: 3.2ms preprocess, 32.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 5 bottles, 1 cup, 1 chair, 32.6ms\n",
            "Speed: 3.4ms preprocess, 32.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 5 bottles, 1 cup, 2 chairs, 31.9ms\n",
            "Speed: 4.5ms preprocess, 31.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 5 bottles, 1 cup, 2 chairs, 32.0ms\n",
            "Speed: 5.3ms preprocess, 32.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 5 bottles, 1 cup, 2 chairs, 31.7ms\n",
            "Speed: 4.0ms preprocess, 31.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 5 bottles, 1 cup, 2 chairs, 31.1ms\n",
            "Speed: 4.7ms preprocess, 31.1ms inference, 5.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 5 bottles, 1 cup, 2 chairs, 31.0ms\n",
            "Speed: 3.3ms preprocess, 31.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 5 bottles, 1 cup, 2 chairs, 31.0ms\n",
            "Speed: 3.2ms preprocess, 31.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 5 bottles, 1 cup, 2 chairs, 31.5ms\n",
            "Speed: 3.2ms preprocess, 31.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 5 bottles, 1 cup, 2 chairs, 31.0ms\n",
            "Speed: 4.6ms preprocess, 31.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 5 bottles, 1 cup, 2 chairs, 31.0ms\n",
            "Speed: 4.4ms preprocess, 31.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 5 bottles, 1 cup, 2 chairs, 31.0ms\n",
            "Speed: 8.3ms preprocess, 31.0ms inference, 5.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 5 bottles, 1 cup, 2 chairs, 31.0ms\n",
            "Speed: 4.3ms preprocess, 31.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 5 bottles, 1 cup, 2 chairs, 31.0ms\n",
            "Speed: 3.2ms preprocess, 31.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 5 bottles, 1 cup, 2 chairs, 31.0ms\n",
            "Speed: 10.4ms preprocess, 31.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 5 bottles, 1 cup, 2 chairs, 31.0ms\n",
            "Speed: 9.6ms preprocess, 31.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 5 bottles, 1 cup, 2 chairs, 31.8ms\n",
            "Speed: 6.9ms preprocess, 31.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 5 bottles, 1 cup, 2 chairs, 31.0ms\n",
            "Speed: 5.5ms preprocess, 31.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 5 bottles, 1 cup, 2 chairs, 31.0ms\n",
            "Speed: 5.3ms preprocess, 31.0ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 5 bottles, 1 cup, 2 chairs, 32.2ms\n",
            "Speed: 3.5ms preprocess, 32.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 5 bottles, 1 cup, 2 chairs, 34.7ms\n",
            "Speed: 6.6ms preprocess, 34.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 5 bottles, 1 cup, 2 chairs, 32.0ms\n",
            "Speed: 3.3ms preprocess, 32.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 5 bottles, 1 cup, 2 chairs, 31.0ms\n",
            "Speed: 4.6ms preprocess, 31.0ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 5 bottles, 1 cup, 2 chairs, 30.8ms\n",
            "Speed: 4.1ms preprocess, 30.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 5 bottles, 1 cup, 2 chairs, 31.5ms\n",
            "Speed: 6.3ms preprocess, 31.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 5 bottles, 1 cup, 2 chairs, 28.8ms\n",
            "Speed: 3.4ms preprocess, 28.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 5 bottles, 1 cup, 2 chairs, 28.8ms\n",
            "Speed: 3.3ms preprocess, 28.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 5 bottles, 1 cup, 2 chairs, 28.8ms\n",
            "Speed: 3.3ms preprocess, 28.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 5 bottles, 1 cup, 2 chairs, 28.8ms\n",
            "Speed: 3.2ms preprocess, 28.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 5 bottles, 1 cup, 2 chairs, 27.7ms\n",
            "Speed: 5.7ms preprocess, 27.7ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 6 bottles, 1 cup, 2 chairs, 26.9ms\n",
            "Speed: 3.5ms preprocess, 26.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 6 bottles, 1 cup, 2 chairs, 26.7ms\n",
            "Speed: 3.2ms preprocess, 26.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 6 bottles, 1 cup, 2 chairs, 26.6ms\n",
            "Speed: 3.2ms preprocess, 26.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 6 bottles, 1 cup, 2 chairs, 26.6ms\n",
            "Speed: 3.0ms preprocess, 26.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 6 bottles, 1 cup, 2 chairs, 26.6ms\n",
            "Speed: 3.0ms preprocess, 26.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 6 bottles, 1 cup, 2 chairs, 26.6ms\n",
            "Speed: 3.4ms preprocess, 26.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 6 bottles, 1 cup, 2 chairs, 26.6ms\n",
            "Speed: 3.4ms preprocess, 26.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 6 bottles, 1 cup, 2 chairs, 26.5ms\n",
            "Speed: 2.9ms preprocess, 26.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 6 bottles, 1 cup, 2 chairs, 26.6ms\n",
            "Speed: 3.2ms preprocess, 26.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 6 bottles, 1 cup, 2 chairs, 26.5ms\n",
            "Speed: 3.3ms preprocess, 26.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 6 bottles, 1 cup, 2 chairs, 26.6ms\n",
            "Speed: 3.2ms preprocess, 26.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 6 bottles, 1 cup, 2 chairs, 26.7ms\n",
            "Speed: 4.2ms preprocess, 26.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 6 bottles, 1 cup, 2 chairs, 26.6ms\n",
            "Speed: 3.2ms preprocess, 26.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 6 bottles, 1 cup, 2 chairs, 26.6ms\n",
            "Speed: 3.2ms preprocess, 26.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 6 bottles, 1 cup, 2 chairs, 26.6ms\n",
            "Speed: 3.3ms preprocess, 26.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 6 bottles, 1 cup, 2 chairs, 26.6ms\n",
            "Speed: 3.3ms preprocess, 26.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 6 bottles, 1 cup, 2 chairs, 26.6ms\n",
            "Speed: 3.3ms preprocess, 26.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 persons, 6 bottles, 1 cup, 2 chairs, 26.6ms\n",
            "Speed: 4.3ms preprocess, 26.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bowl, 31.4ms\n",
            "Speed: 3.1ms preprocess, 31.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 handbag, 1 cup, 2 bowls, 1 donut, 4 chairs, 1 couch, 1 dining table, 1 book, 26.6ms\n",
            "Speed: 3.4ms preprocess, 26.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 handbag, 1 cup, 2 bowls, 4 chairs, 1 couch, 1 dining table, 1 remote, 1 book, 26.6ms\n",
            "Speed: 3.6ms preprocess, 26.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 handbag, 1 cup, 2 bowls, 4 chairs, 1 couch, 1 dining table, 1 remote, 1 book, 26.6ms\n",
            "Speed: 3.4ms preprocess, 26.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 handbag, 1 cup, 2 bowls, 4 chairs, 1 couch, 1 dining table, 1 remote, 1 book, 26.7ms\n",
            "Speed: 3.1ms preprocess, 26.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 handbag, 1 cup, 2 bowls, 1 donut, 4 chairs, 1 couch, 1 dining table, 1 remote, 1 book, 27.8ms\n",
            "Speed: 3.0ms preprocess, 27.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 handbag, 1 cup, 2 bowls, 1 donut, 4 chairs, 1 couch, 1 dining table, 1 remote, 1 book, 27.2ms\n",
            "Speed: 3.2ms preprocess, 27.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 handbag, 1 cup, 2 bowls, 1 donut, 4 chairs, 1 couch, 1 dining table, 1 remote, 1 book, 28.2ms\n",
            "Speed: 3.2ms preprocess, 28.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 handbag, 1 cup, 2 bowls, 1 donut, 4 chairs, 1 couch, 1 dining table, 1 remote, 1 book, 31.2ms\n",
            "Speed: 3.3ms preprocess, 31.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 handbag, 1 cup, 2 bowls, 1 donut, 4 chairs, 1 couch, 1 dining table, 1 remote, 1 book, 28.3ms\n",
            "Speed: 3.2ms preprocess, 28.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 handbag, 1 cup, 2 bowls, 1 donut, 4 chairs, 1 couch, 1 dining table, 1 remote, 1 book, 28.4ms\n",
            "Speed: 7.7ms preprocess, 28.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 handbag, 1 cup, 2 bowls, 1 donut, 4 chairs, 1 couch, 1 dining table, 1 remote, 1 book, 28.4ms\n",
            "Speed: 3.2ms preprocess, 28.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 handbag, 1 cup, 2 bowls, 1 donut, 4 chairs, 1 couch, 1 dining table, 1 remote, 1 book, 30.2ms\n",
            "Speed: 3.4ms preprocess, 30.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 handbag, 1 cup, 2 bowls, 1 donut, 4 chairs, 1 couch, 1 dining table, 1 remote, 1 book, 27.9ms\n",
            "Speed: 3.3ms preprocess, 27.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 handbag, 1 cup, 2 bowls, 1 donut, 4 chairs, 1 couch, 1 dining table, 1 remote, 1 book, 27.9ms\n",
            "Speed: 3.2ms preprocess, 27.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 handbag, 1 cup, 2 bowls, 1 donut, 4 chairs, 1 couch, 1 dining table, 1 remote, 1 book, 27.7ms\n",
            "Speed: 3.2ms preprocess, 27.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 handbag, 1 cup, 2 bowls, 1 donut, 4 chairs, 1 couch, 1 dining table, 1 remote, 1 book, 27.6ms\n",
            "Speed: 5.4ms preprocess, 27.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 handbag, 1 cup, 2 bowls, 1 donut, 3 chairs, 2 couchs, 1 dining table, 1 remote, 1 book, 27.6ms\n",
            "Speed: 3.2ms preprocess, 27.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 handbag, 1 cup, 2 bowls, 1 donut, 4 chairs, 1 couch, 1 dining table, 1 laptop, 1 remote, 1 book, 27.4ms\n",
            "Speed: 3.2ms preprocess, 27.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 handbag, 2 cups, 2 bowls, 1 donut, 3 chairs, 2 couchs, 1 dining table, 1 laptop, 1 remote, 1 book, 27.4ms\n",
            "Speed: 3.4ms preprocess, 27.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 handbag, 2 cups, 2 bowls, 1 donut, 4 chairs, 1 couch, 1 dining table, 1 laptop, 1 remote, 1 book, 27.4ms\n",
            "Speed: 6.3ms preprocess, 27.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 handbag, 2 cups, 2 bowls, 1 donut, 3 chairs, 2 couchs, 1 dining table, 2 remotes, 1 book, 30.0ms\n",
            "Speed: 9.5ms preprocess, 30.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 handbag, 2 cups, 2 bowls, 1 donut, 4 chairs, 1 couch, 1 dining table, 1 laptop, 1 remote, 1 book, 27.4ms\n",
            "Speed: 3.3ms preprocess, 27.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 handbag, 2 cups, 2 bowls, 1 donut, 3 chairs, 2 couchs, 1 dining table, 1 laptop, 1 remote, 1 book, 27.4ms\n",
            "Speed: 3.4ms preprocess, 27.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 handbag, 2 cups, 2 bowls, 1 donut, 4 chairs, 1 couch, 1 dining table, 1 laptop, 1 remote, 1 book, 27.4ms\n",
            "Speed: 3.1ms preprocess, 27.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 handbag, 2 cups, 2 bowls, 1 donut, 4 chairs, 1 couch, 1 dining table, 1 laptop, 1 remote, 1 book, 27.4ms\n",
            "Speed: 3.2ms preprocess, 27.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 handbag, 2 cups, 2 bowls, 3 chairs, 2 couchs, 1 dining table, 1 laptop, 1 remote, 1 book, 27.4ms\n",
            "Speed: 3.2ms preprocess, 27.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 handbag, 2 cups, 2 bowls, 4 chairs, 1 couch, 1 dining table, 1 laptop, 1 remote, 1 book, 27.4ms\n",
            "Speed: 3.2ms preprocess, 27.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 handbag, 2 cups, 2 bowls, 4 chairs, 1 couch, 1 dining table, 1 laptop, 1 remote, 1 book, 27.4ms\n",
            "Speed: 3.0ms preprocess, 27.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 handbag, 2 cups, 2 bowls, 4 chairs, 1 couch, 1 dining table, 1 laptop, 1 remote, 1 book, 27.4ms\n",
            "Speed: 3.3ms preprocess, 27.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 handbag, 2 cups, 2 bowls, 4 chairs, 1 couch, 1 dining table, 1 laptop, 1 remote, 1 book, 27.4ms\n",
            "Speed: 3.2ms preprocess, 27.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 handbag, 2 cups, 2 bowls, 3 chairs, 2 couchs, 1 dining table, 1 laptop, 1 remote, 1 book, 27.4ms\n",
            "Speed: 3.4ms preprocess, 27.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 handbag, 2 cups, 2 bowls, 1 donut, 3 chairs, 2 couchs, 1 dining table, 1 laptop, 1 book, 27.4ms\n",
            "Speed: 3.1ms preprocess, 27.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 handbag, 2 cups, 2 bowls, 1 donut, 3 chairs, 2 couchs, 1 dining table, 1 laptop, 1 book, 27.8ms\n",
            "Speed: 3.2ms preprocess, 27.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 handbag, 2 cups, 2 bowls, 1 donut, 3 chairs, 2 couchs, 1 dining table, 1 laptop, 1 book, 28.1ms\n",
            "Speed: 3.2ms preprocess, 28.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 handbag, 2 cups, 2 bowls, 1 donut, 3 chairs, 2 couchs, 1 dining table, 1 laptop, 1 book, 28.1ms\n",
            "Speed: 3.3ms preprocess, 28.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 handbag, 2 cups, 2 bowls, 3 chairs, 2 couchs, 1 dining table, 1 laptop, 1 remote, 2 books, 28.4ms\n",
            "Speed: 3.3ms preprocess, 28.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 handbag, 2 cups, 2 bowls, 1 donut, 3 chairs, 2 couchs, 1 dining table, 1 laptop, 2 books, 28.4ms\n",
            "Speed: 3.3ms preprocess, 28.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 handbag, 2 cups, 2 bowls, 1 donut, 3 chairs, 2 couchs, 1 dining table, 1 laptop, 2 books, 28.8ms\n",
            "Speed: 3.4ms preprocess, 28.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 handbag, 2 cups, 2 bowls, 1 donut, 3 chairs, 2 couchs, 1 dining table, 1 laptop, 2 books, 28.8ms\n",
            "Speed: 3.2ms preprocess, 28.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 handbag, 2 cups, 2 bowls, 1 donut, 3 chairs, 2 couchs, 1 dining table, 1 laptop, 2 books, 29.0ms\n",
            "Speed: 3.6ms preprocess, 29.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 handbag, 2 cups, 2 bowls, 1 donut, 3 chairs, 2 couchs, 1 dining table, 1 laptop, 2 books, 27.6ms\n",
            "Speed: 3.2ms preprocess, 27.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 handbag, 2 cups, 2 bowls, 1 donut, 4 chairs, 1 couch, 1 dining table, 1 laptop, 2 books, 26.8ms\n",
            "Speed: 3.2ms preprocess, 26.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 handbag, 2 cups, 2 bowls, 1 donut, 3 chairs, 2 couchs, 1 dining table, 1 laptop, 2 books, 26.7ms\n",
            "Speed: 3.1ms preprocess, 26.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 handbag, 2 cups, 2 bowls, 1 donut, 3 chairs, 2 couchs, 1 dining table, 1 laptop, 2 books, 26.6ms\n",
            "Speed: 3.1ms preprocess, 26.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 handbag, 2 cups, 2 bowls, 1 donut, 3 chairs, 2 couchs, 1 dining table, 1 laptop, 2 books, 26.6ms\n",
            "Speed: 3.4ms preprocess, 26.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 handbag, 2 cups, 2 bowls, 1 donut, 3 chairs, 2 couchs, 1 dining table, 1 remote, 2 books, 26.6ms\n",
            "Speed: 3.9ms preprocess, 26.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 handbag, 2 cups, 2 bowls, 1 donut, 3 chairs, 2 couchs, 1 dining table, 1 remote, 2 books, 26.5ms\n",
            "Speed: 3.7ms preprocess, 26.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 handbag, 2 cups, 2 bowls, 1 donut, 3 chairs, 2 couchs, 1 dining table, 1 remote, 2 books, 26.5ms\n",
            "Speed: 3.2ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 handbag, 2 cups, 2 bowls, 3 chairs, 2 couchs, 1 dining table, 1 laptop, 1 remote, 2 books, 26.6ms\n",
            "Speed: 3.2ms preprocess, 26.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 handbag, 2 cups, 2 bowls, 3 chairs, 2 couchs, 1 dining table, 1 laptop, 1 remote, 2 books, 26.6ms\n",
            "Speed: 3.2ms preprocess, 26.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 handbag, 2 cups, 2 bowls, 1 donut, 3 chairs, 2 couchs, 1 dining table, 1 laptop, 2 books, 26.6ms\n",
            "Speed: 3.8ms preprocess, 26.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 handbag, 2 cups, 2 bowls, 1 donut, 3 chairs, 2 couchs, 1 dining table, 1 laptop, 2 books, 26.6ms\n",
            "Speed: 3.2ms preprocess, 26.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 handbag, 2 cups, 2 bowls, 3 chairs, 2 couchs, 1 dining table, 1 laptop, 2 remotes, 2 books, 26.6ms\n",
            "Speed: 3.2ms preprocess, 26.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 handbag, 2 cups, 2 bowls, 3 chairs, 2 couchs, 1 dining table, 3 remotes, 2 books, 26.6ms\n",
            "Speed: 3.3ms preprocess, 26.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 handbag, 2 cups, 2 bowls, 3 chairs, 2 couchs, 1 dining table, 1 laptop, 2 remotes, 2 books, 26.6ms\n",
            "Speed: 3.0ms preprocess, 26.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 handbag, 2 cups, 2 bowls, 3 chairs, 2 couchs, 1 dining table, 3 remotes, 2 books, 26.6ms\n",
            "Speed: 4.3ms preprocess, 26.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 handbag, 2 cups, 2 bowls, 3 chairs, 2 couchs, 1 dining table, 3 remotes, 2 books, 26.6ms\n",
            "Speed: 6.8ms preprocess, 26.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 handbag, 2 cups, 2 bowls, 1 donut, 3 chairs, 2 couchs, 1 dining table, 2 remotes, 1 book, 26.6ms\n",
            "Speed: 3.3ms preprocess, 26.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 handbag, 2 cups, 2 bowls, 1 donut, 3 chairs, 2 couchs, 1 dining table, 2 remotes, 1 book, 27.8ms\n",
            "Speed: 3.4ms preprocess, 27.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 chairs, 26.6ms\n",
            "Speed: 4.6ms preprocess, 26.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 5 bottles, 1 cup, 3 chairs, 26.6ms\n",
            "Speed: 5.6ms preprocess, 26.6ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6 bottles, 1 cup, 2 chairs, 1 dining table, 26.6ms\n",
            "Speed: 3.1ms preprocess, 26.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6 bottles, 1 cup, 2 chairs, 1 dining table, 28.2ms\n",
            "Speed: 3.7ms preprocess, 28.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6 bottles, 1 cup, 2 chairs, 1 dining table, 28.1ms\n",
            "Speed: 3.4ms preprocess, 28.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6 bottles, 1 cup, 2 chairs, 1 dining table, 28.1ms\n",
            "Speed: 3.1ms preprocess, 28.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6 bottles, 1 cup, 2 chairs, 1 dining table, 28.1ms\n",
            "Speed: 3.0ms preprocess, 28.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6 bottles, 1 cup, 2 chairs, 1 dining table, 28.1ms\n",
            "Speed: 3.3ms preprocess, 28.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6 bottles, 1 cup, 2 chairs, 1 dining table, 28.5ms\n",
            "Speed: 3.1ms preprocess, 28.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6 bottles, 1 cup, 2 chairs, 28.4ms\n",
            "Speed: 3.1ms preprocess, 28.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6 bottles, 1 cup, 2 chairs, 28.5ms\n",
            "Speed: 3.6ms preprocess, 28.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6 bottles, 1 cup, 2 chairs, 27.8ms\n",
            "Speed: 3.9ms preprocess, 27.8ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6 bottles, 1 cup, 2 chairs, 27.0ms\n",
            "Speed: 4.5ms preprocess, 27.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6 bottles, 1 cup, 2 chairs, 26.5ms\n",
            "Speed: 3.3ms preprocess, 26.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6 bottles, 1 cup, 2 chairs, 26.6ms\n",
            "Speed: 8.4ms preprocess, 26.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6 bottles, 1 cup, 2 chairs, 26.6ms\n",
            "Speed: 8.5ms preprocess, 26.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 7 bottles, 1 cup, 2 chairs, 26.7ms\n",
            "Speed: 3.3ms preprocess, 26.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 7 bottles, 1 cup, 2 chairs, 26.6ms\n",
            "Speed: 3.3ms preprocess, 26.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 7 bottles, 1 cup, 2 chairs, 26.6ms\n",
            "Speed: 3.2ms preprocess, 26.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 7 bottles, 1 cup, 2 chairs, 26.6ms\n",
            "Speed: 3.2ms preprocess, 26.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 7 bottles, 1 cup, 2 chairs, 26.6ms\n",
            "Speed: 3.2ms preprocess, 26.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 7 bottles, 1 cup, 2 chairs, 26.6ms\n",
            "Speed: 3.3ms preprocess, 26.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 8 bottles, 1 cup, 2 chairs, 26.6ms\n",
            "Speed: 3.4ms preprocess, 26.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 8 bottles, 1 cup, 2 chairs, 26.6ms\n",
            "Speed: 3.3ms preprocess, 26.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 8 bottles, 1 cup, 2 chairs, 26.6ms\n",
            "Speed: 3.3ms preprocess, 26.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 8 bottles, 1 cup, 2 chairs, 26.6ms\n",
            "Speed: 3.3ms preprocess, 26.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 8 bottles, 1 cup, 2 chairs, 26.6ms\n",
            "Speed: 3.2ms preprocess, 26.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 8 bottles, 1 cup, 2 chairs, 30.8ms\n",
            "Speed: 3.5ms preprocess, 30.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 8 bottles, 1 cup, 3 chairs, 26.6ms\n",
            "Speed: 3.2ms preprocess, 26.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 8 bottles, 1 cup, 3 chairs, 26.5ms\n",
            "Speed: 3.2ms preprocess, 26.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 8 bottles, 1 cup, 3 chairs, 26.6ms\n",
            "Speed: 3.4ms preprocess, 26.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 8 bottles, 1 cup, 3 chairs, 26.6ms\n",
            "Speed: 3.7ms preprocess, 26.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 8 bottles, 1 cup, 3 chairs, 26.6ms\n",
            "Speed: 3.2ms preprocess, 26.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 8 bottles, 1 cup, 3 chairs, 26.6ms\n",
            "Speed: 3.3ms preprocess, 26.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 8 bottles, 1 cup, 3 chairs, 26.6ms\n",
            "Speed: 5.8ms preprocess, 26.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 8 bottles, 1 cup, 3 chairs, 27.0ms\n",
            "Speed: 3.4ms preprocess, 27.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 8 bottles, 1 cup, 3 chairs, 26.3ms\n",
            "Speed: 3.7ms preprocess, 26.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 8 bottles, 1 cup, 3 chairs, 27.7ms\n",
            "Speed: 4.4ms preprocess, 27.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 8 bottles, 1 cup, 3 chairs, 27.7ms\n",
            "Speed: 4.3ms preprocess, 27.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 8 bottles, 1 cup, 3 chairs, 27.6ms\n",
            "Speed: 3.1ms preprocess, 27.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 8 bottles, 1 cup, 3 chairs, 27.1ms\n",
            "Speed: 3.7ms preprocess, 27.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 8 bottles, 1 cup, 3 chairs, 27.3ms\n",
            "Speed: 3.3ms preprocess, 27.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 26.3ms\n",
            "Speed: 2.8ms preprocess, 26.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 1 couch, 1 laptop, 3 books, 26.4ms\n",
            "Speed: 3.3ms preprocess, 26.4ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 1 couch, 1 laptop, 3 books, 26.4ms\n",
            "Speed: 3.3ms preprocess, 26.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 1 couch, 1 laptop, 3 books, 26.5ms\n",
            "Speed: 3.1ms preprocess, 26.5ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 1 couch, 1 laptop, 3 books, 26.3ms\n",
            "Speed: 3.3ms preprocess, 26.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 1 couch, 1 laptop, 3 books, 31.3ms\n",
            "Speed: 3.8ms preprocess, 31.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 1 couch, 1 laptop, 3 books, 26.3ms\n",
            "Speed: 3.1ms preprocess, 26.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 1 couch, 1 laptop, 3 books, 31.1ms\n",
            "Speed: 3.2ms preprocess, 31.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 2 couchs, 1 laptop, 3 books, 26.3ms\n",
            "Speed: 3.2ms preprocess, 26.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 2 couchs, 1 laptop, 3 books, 27.6ms\n",
            "Speed: 3.1ms preprocess, 27.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 2 couchs, 1 laptop, 3 books, 26.4ms\n",
            "Speed: 3.5ms preprocess, 26.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 2 couchs, 1 laptop, 3 books, 26.4ms\n",
            "Speed: 3.2ms preprocess, 26.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 2 couchs, 1 laptop, 3 books, 26.3ms\n",
            "Speed: 3.5ms preprocess, 26.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 2 couchs, 1 laptop, 3 books, 26.3ms\n",
            "Speed: 3.2ms preprocess, 26.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 2 couchs, 1 laptop, 3 books, 30.6ms\n",
            "Speed: 3.5ms preprocess, 30.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 2 couchs, 1 laptop, 3 books, 26.3ms\n",
            "Speed: 3.1ms preprocess, 26.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 2 couchs, 1 laptop, 3 books, 26.3ms\n",
            "Speed: 4.8ms preprocess, 26.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 2 couchs, 1 laptop, 3 books, 31.5ms\n",
            "Speed: 3.5ms preprocess, 31.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 2 couchs, 1 laptop, 3 books, 31.4ms\n",
            "Speed: 3.0ms preprocess, 31.4ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 2 couchs, 1 laptop, 3 books, 36.2ms\n",
            "Speed: 3.4ms preprocess, 36.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 2 couchs, 1 laptop, 3 books, 31.9ms\n",
            "Speed: 3.2ms preprocess, 31.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 2 couchs, 1 laptop, 3 books, 32.6ms\n",
            "Speed: 4.3ms preprocess, 32.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 2 couchs, 1 laptop, 3 books, 31.6ms\n",
            "Speed: 4.1ms preprocess, 31.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 2 couchs, 1 laptop, 3 books, 31.6ms\n",
            "Speed: 5.0ms preprocess, 31.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 2 couchs, 1 laptop, 3 books, 29.2ms\n",
            "Speed: 4.4ms preprocess, 29.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 2 couchs, 1 laptop, 3 books, 29.2ms\n",
            "Speed: 3.4ms preprocess, 29.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 1 couch, 1 laptop, 3 books, 29.6ms\n",
            "Speed: 7.2ms preprocess, 29.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 1 couch, 1 laptop, 3 books, 29.2ms\n",
            "Speed: 3.2ms preprocess, 29.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 1 couch, 1 laptop, 3 books, 29.3ms\n",
            "Speed: 4.0ms preprocess, 29.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 1 couch, 1 laptop, 3 books, 29.2ms\n",
            "Speed: 4.3ms preprocess, 29.2ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 1 couch, 1 laptop, 3 books, 29.2ms\n",
            "Speed: 5.7ms preprocess, 29.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 1 couch, 1 laptop, 3 books, 34.2ms\n",
            "Speed: 3.7ms preprocess, 34.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 1 couch, 1 laptop, 3 books, 29.2ms\n",
            "Speed: 4.0ms preprocess, 29.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 1 couch, 1 laptop, 3 books, 29.3ms\n",
            "Speed: 3.2ms preprocess, 29.3ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 1 couch, 1 laptop, 3 books, 29.2ms\n",
            "Speed: 6.2ms preprocess, 29.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 1 couch, 1 laptop, 3 books, 29.2ms\n",
            "Speed: 4.0ms preprocess, 29.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 1 couch, 1 laptop, 3 books, 32.7ms\n",
            "Speed: 5.3ms preprocess, 32.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 1 couch, 1 laptop, 3 books, 29.2ms\n",
            "Speed: 4.9ms preprocess, 29.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 1 couch, 1 laptop, 3 books, 29.2ms\n",
            "Speed: 3.2ms preprocess, 29.2ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 1 couch, 1 laptop, 3 books, 34.4ms\n",
            "Speed: 3.3ms preprocess, 34.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 1 couch, 1 laptop, 3 books, 29.7ms\n",
            "Speed: 5.4ms preprocess, 29.7ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 1 couch, 1 laptop, 3 books, 31.0ms\n",
            "Speed: 4.8ms preprocess, 31.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 1 couch, 1 laptop, 3 books, 31.4ms\n",
            "Speed: 3.1ms preprocess, 31.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 1 couch, 1 laptop, 3 books, 31.9ms\n",
            "Speed: 3.1ms preprocess, 31.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 1 couch, 1 laptop, 3 books, 31.1ms\n",
            "Speed: 3.7ms preprocess, 31.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 1 couch, 1 laptop, 3 books, 33.5ms\n",
            "Speed: 2.9ms preprocess, 33.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 1 couch, 1 laptop, 3 books, 31.5ms\n",
            "Speed: 3.4ms preprocess, 31.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 1 couch, 1 laptop, 3 books, 33.3ms\n",
            "Speed: 3.3ms preprocess, 33.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 1 couch, 1 laptop, 3 books, 32.5ms\n",
            "Speed: 4.2ms preprocess, 32.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 1 couch, 1 laptop, 3 books, 35.4ms\n",
            "Speed: 3.4ms preprocess, 35.4ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 1 couch, 1 laptop, 3 books, 32.5ms\n",
            "Speed: 3.3ms preprocess, 32.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 1 couch, 1 laptop, 3 books, 32.5ms\n",
            "Speed: 3.1ms preprocess, 32.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 1 couch, 1 laptop, 3 books, 32.5ms\n",
            "Speed: 3.4ms preprocess, 32.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 1 couch, 1 laptop, 3 books, 32.5ms\n",
            "Speed: 3.5ms preprocess, 32.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 1 couch, 1 laptop, 3 books, 31.4ms\n",
            "Speed: 3.2ms preprocess, 31.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 1 couch, 1 laptop, 3 books, 31.5ms\n",
            "Speed: 3.7ms preprocess, 31.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 1 couch, 1 laptop, 3 books, 31.4ms\n",
            "Speed: 3.3ms preprocess, 31.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 1 couch, 1 laptop, 3 books, 31.5ms\n",
            "Speed: 4.2ms preprocess, 31.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 1 couch, 1 laptop, 3 books, 31.4ms\n",
            "Speed: 3.1ms preprocess, 31.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 1 couch, 1 laptop, 3 books, 29.7ms\n",
            "Speed: 3.3ms preprocess, 29.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 1 couch, 1 laptop, 3 books, 29.6ms\n",
            "Speed: 3.2ms preprocess, 29.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 1 couch, 1 laptop, 3 books, 29.6ms\n",
            "Speed: 3.4ms preprocess, 29.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 1 couch, 1 laptop, 3 books, 29.6ms\n",
            "Speed: 3.1ms preprocess, 29.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 1 couch, 1 laptop, 3 books, 29.6ms\n",
            "Speed: 3.5ms preprocess, 29.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 1 couch, 1 laptop, 3 books, 29.7ms\n",
            "Speed: 6.6ms preprocess, 29.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 1 couch, 1 laptop, 3 books, 29.6ms\n",
            "Speed: 3.5ms preprocess, 29.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 1 couch, 1 laptop, 3 books, 29.6ms\n",
            "Speed: 3.2ms preprocess, 29.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 1 couch, 1 laptop, 3 books, 28.1ms\n",
            "Speed: 3.4ms preprocess, 28.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 1 couch, 1 laptop, 3 books, 28.1ms\n",
            "Speed: 3.1ms preprocess, 28.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 1 couch, 1 laptop, 3 books, 32.8ms\n",
            "Speed: 3.3ms preprocess, 32.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 1 couch, 1 laptop, 3 books, 28.1ms\n",
            "Speed: 3.1ms preprocess, 28.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 1 couch, 1 laptop, 3 books, 28.1ms\n",
            "Speed: 3.1ms preprocess, 28.1ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 1 couch, 1 laptop, 3 books, 27.9ms\n",
            "Speed: 6.8ms preprocess, 27.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 1 couch, 1 laptop, 3 books, 26.9ms\n",
            "Speed: 3.2ms preprocess, 26.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 1 couch, 1 laptop, 3 books, 26.7ms\n",
            "Speed: 3.3ms preprocess, 26.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 1 couch, 1 laptop, 3 books, 26.7ms\n",
            "Speed: 3.1ms preprocess, 26.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 1 couch, 1 laptop, 3 books, 26.7ms\n",
            "Speed: 3.2ms preprocess, 26.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 1 couch, 1 laptop, 3 books, 27.1ms\n",
            "Speed: 3.4ms preprocess, 27.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 1 couch, 1 laptop, 3 books, 26.4ms\n",
            "Speed: 3.7ms preprocess, 26.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 1 couch, 1 laptop, 3 books, 26.3ms\n",
            "Speed: 3.3ms preprocess, 26.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 1 couch, 1 laptop, 3 books, 26.3ms\n",
            "Speed: 3.1ms preprocess, 26.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 1 couch, 1 laptop, 3 books, 26.3ms\n",
            "Speed: 6.8ms preprocess, 26.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 1 couch, 1 laptop, 3 books, 26.9ms\n",
            "Speed: 3.4ms preprocess, 26.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 1 couch, 1 laptop, 3 books, 26.4ms\n",
            "Speed: 3.3ms preprocess, 26.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 1 couch, 1 laptop, 3 books, 26.3ms\n",
            "Speed: 3.2ms preprocess, 26.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 1 couch, 1 laptop, 3 books, 26.3ms\n",
            "Speed: 9.5ms preprocess, 26.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 1 couch, 1 laptop, 3 books, 26.3ms\n",
            "Speed: 3.3ms preprocess, 26.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 1 couch, 1 laptop, 3 books, 26.4ms\n",
            "Speed: 3.4ms preprocess, 26.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 1 couch, 1 laptop, 3 books, 26.3ms\n",
            "Speed: 3.1ms preprocess, 26.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 1 couch, 1 laptop, 3 books, 28.9ms\n",
            "Speed: 3.3ms preprocess, 28.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 1 couch, 1 laptop, 3 books, 26.5ms\n",
            "Speed: 3.2ms preprocess, 26.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 1 couch, 1 laptop, 3 books, 26.3ms\n",
            "Speed: 3.1ms preprocess, 26.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 1 couch, 1 laptop, 3 books, 26.4ms\n",
            "Speed: 3.2ms preprocess, 26.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 1 couch, 1 laptop, 3 books, 28.1ms\n",
            "Speed: 3.2ms preprocess, 28.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 1 couch, 1 laptop, 3 books, 26.3ms\n",
            "Speed: 3.3ms preprocess, 26.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 1 couch, 1 laptop, 3 books, 26.3ms\n",
            "Speed: 3.2ms preprocess, 26.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 1 couch, 1 laptop, 3 books, 26.3ms\n",
            "Speed: 3.2ms preprocess, 26.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 1 couch, 1 laptop, 3 books, 26.3ms\n",
            "Speed: 3.0ms preprocess, 26.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 1 couch, 1 laptop, 3 books, 26.3ms\n",
            "Speed: 3.2ms preprocess, 26.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 1 couch, 1 laptop, 3 books, 29.7ms\n",
            "Speed: 3.3ms preprocess, 29.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 1 couch, 1 laptop, 3 books, 26.9ms\n",
            "Speed: 3.2ms preprocess, 26.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 1 couch, 1 laptop, 3 books, 26.4ms\n",
            "Speed: 3.6ms preprocess, 26.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 1 couch, 1 laptop, 3 books, 26.3ms\n",
            "Speed: 3.1ms preprocess, 26.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 1 couch, 1 laptop, 3 books, 26.3ms\n",
            "Speed: 10.9ms preprocess, 26.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 1 couch, 1 laptop, 3 books, 27.3ms\n",
            "Speed: 3.6ms preprocess, 27.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 1 couch, 1 laptop, 3 books, 27.8ms\n",
            "Speed: 3.4ms preprocess, 27.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 1 couch, 1 laptop, 3 books, 26.9ms\n",
            "Speed: 3.2ms preprocess, 26.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 1 couch, 1 laptop, 3 books, 26.6ms\n",
            "Speed: 3.3ms preprocess, 26.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 1 couch, 1 laptop, 3 books, 26.6ms\n",
            "Speed: 3.2ms preprocess, 26.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 1 couch, 1 laptop, 3 books, 26.6ms\n",
            "Speed: 3.4ms preprocess, 26.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 1 couch, 1 laptop, 3 books, 27.1ms\n",
            "Speed: 3.0ms preprocess, 27.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 1 couch, 1 laptop, 3 books, 26.4ms\n",
            "Speed: 3.3ms preprocess, 26.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 1 couch, 1 laptop, 3 books, 26.4ms\n",
            "Speed: 3.5ms preprocess, 26.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 1 couch, 1 laptop, 3 books, 26.3ms\n",
            "Speed: 4.0ms preprocess, 26.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 1 couch, 1 laptop, 3 books, 26.3ms\n",
            "Speed: 3.1ms preprocess, 26.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 1 couch, 1 laptop, 3 books, 26.8ms\n",
            "Speed: 3.3ms preprocess, 26.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 1 couch, 1 laptop, 3 books, 27.7ms\n",
            "Speed: 8.5ms preprocess, 27.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 1 couch, 1 laptop, 3 books, 26.9ms\n",
            "Speed: 5.9ms preprocess, 26.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 1 couch, 1 laptop, 3 books, 27.8ms\n",
            "Speed: 3.3ms preprocess, 27.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 1 couch, 1 laptop, 3 books, 27.5ms\n",
            "Speed: 3.2ms preprocess, 27.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 1 couch, 1 laptop, 3 books, 27.2ms\n",
            "Speed: 4.0ms preprocess, 27.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 1 couch, 1 laptop, 3 books, 27.1ms\n",
            "Speed: 4.2ms preprocess, 27.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 1 couch, 1 laptop, 3 books, 26.3ms\n",
            "Speed: 3.7ms preprocess, 26.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 1 couch, 1 laptop, 3 books, 26.4ms\n",
            "Speed: 3.5ms preprocess, 26.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 1 couch, 1 laptop, 3 books, 26.3ms\n",
            "Speed: 3.1ms preprocess, 26.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 1 couch, 1 laptop, 3 books, 26.3ms\n",
            "Speed: 3.1ms preprocess, 26.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 1 couch, 1 laptop, 3 books, 26.3ms\n",
            "Speed: 3.3ms preprocess, 26.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 1 couch, 1 laptop, 3 books, 26.3ms\n",
            "Speed: 3.9ms preprocess, 26.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 1 couch, 1 laptop, 3 books, 26.6ms\n",
            "Speed: 3.3ms preprocess, 26.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 1 couch, 1 laptop, 3 books, 26.3ms\n",
            "Speed: 3.2ms preprocess, 26.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 1 couch, 1 laptop, 3 books, 26.4ms\n",
            "Speed: 3.2ms preprocess, 26.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 1 couch, 1 laptop, 3 books, 26.3ms\n",
            "Speed: 3.0ms preprocess, 26.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 1 couch, 1 laptop, 3 books, 26.4ms\n",
            "Speed: 3.1ms preprocess, 26.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 1 couch, 1 laptop, 3 books, 26.3ms\n",
            "Speed: 3.5ms preprocess, 26.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 1 couch, 1 laptop, 3 books, 26.3ms\n",
            "Speed: 3.1ms preprocess, 26.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 1 couch, 1 laptop, 3 books, 26.3ms\n",
            "Speed: 3.1ms preprocess, 26.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 1 couch, 1 laptop, 3 books, 26.4ms\n",
            "Speed: 5.7ms preprocess, 26.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 1 couch, 1 laptop, 3 books, 32.3ms\n",
            "Speed: 3.2ms preprocess, 32.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 1 couch, 1 laptop, 3 books, 26.5ms\n",
            "Speed: 3.3ms preprocess, 26.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 1 couch, 1 laptop, 3 books, 27.0ms\n",
            "Speed: 3.3ms preprocess, 27.0ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 1 couch, 1 laptop, 3 books, 26.4ms\n",
            "Speed: 4.0ms preprocess, 26.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 1 couch, 1 laptop, 3 books, 31.6ms\n",
            "Speed: 3.3ms preprocess, 31.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 1 couch, 1 laptop, 3 books, 28.5ms\n",
            "Speed: 3.2ms preprocess, 28.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 1 couch, 1 laptop, 3 books, 26.3ms\n",
            "Speed: 3.3ms preprocess, 26.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 1 couch, 1 laptop, 3 books, 26.3ms\n",
            "Speed: 3.3ms preprocess, 26.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 1 couch, 1 laptop, 3 books, 28.0ms\n",
            "Speed: 2.6ms preprocess, 28.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 1 couch, 1 laptop, 3 books, 27.7ms\n",
            "Speed: 3.3ms preprocess, 27.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 1 couch, 1 laptop, 3 books, 27.2ms\n",
            "Speed: 3.5ms preprocess, 27.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 2 chairs, 1 couch, 1 laptop, 3 books, 27.8ms\n",
            "Speed: 3.6ms preprocess, 27.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 27.0ms\n",
            "Speed: 3.3ms preprocess, 27.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 1 cup, 1 chair, 26.8ms\n",
            "Speed: 3.4ms preprocess, 26.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 1 cup, 1 chair, 26.6ms\n",
            "Speed: 3.3ms preprocess, 26.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 1 cup, 1 chair, 26.7ms\n",
            "Speed: 3.0ms preprocess, 26.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 1 cup, 1 chair, 26.6ms\n",
            "Speed: 3.8ms preprocess, 26.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 1 cup, 1 chair, 26.6ms\n",
            "Speed: 3.4ms preprocess, 26.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 1 cup, 1 chair, 25.9ms\n",
            "Speed: 3.4ms preprocess, 25.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 1 cup, 1 chair, 25.9ms\n",
            "Speed: 3.3ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 1 cup, 1 chair, 25.9ms\n",
            "Speed: 3.8ms preprocess, 25.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 1 cup, 1 chair, 25.9ms\n",
            "Speed: 4.2ms preprocess, 25.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 1 cup, 1 chair, 25.9ms\n",
            "Speed: 3.2ms preprocess, 25.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 1 cup, 1 chair, 25.9ms\n",
            "Speed: 3.6ms preprocess, 25.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 1 cup, 1 chair, 25.9ms\n",
            "Speed: 4.7ms preprocess, 25.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 1 cup, 1 chair, 25.9ms\n",
            "Speed: 3.3ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 1 cup, 1 chair, 25.9ms\n",
            "Speed: 3.4ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 1 cup, 1 chair, 25.9ms\n",
            "Speed: 6.0ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 1 cup, 1 chair, 26.0ms\n",
            "Speed: 3.4ms preprocess, 26.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 1 cup, 1 chair, 26.1ms\n",
            "Speed: 3.2ms preprocess, 26.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 1 cup, 1 chair, 26.2ms\n",
            "Speed: 3.4ms preprocess, 26.2ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 1 cup, 1 chair, 25.9ms\n",
            "Speed: 3.3ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 1 cup, 1 chair, 25.9ms\n",
            "Speed: 3.2ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 1 cup, 1 chair, 26.0ms\n",
            "Speed: 3.5ms preprocess, 26.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 1 cup, 1 chair, 25.9ms\n",
            "Speed: 3.3ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 1 cup, 1 chair, 26.0ms\n",
            "Speed: 2.8ms preprocess, 26.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 1 cup, 1 chair, 25.9ms\n",
            "Speed: 3.2ms preprocess, 25.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 1 cup, 1 chair, 25.9ms\n",
            "Speed: 3.7ms preprocess, 25.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 1 cup, 1 chair, 25.9ms\n",
            "Speed: 3.2ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 1 cup, 1 chair, 25.9ms\n",
            "Speed: 3.2ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 1 cup, 1 chair, 25.9ms\n",
            "Speed: 3.5ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 1 cup, 1 chair, 25.9ms\n",
            "Speed: 3.2ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 1 cup, 1 chair, 28.4ms\n",
            "Speed: 3.3ms preprocess, 28.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 1 cup, 1 chair, 25.9ms\n",
            "Speed: 3.1ms preprocess, 25.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 1 cup, 1 chair, 25.9ms\n",
            "Speed: 3.1ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 1 cup, 1 chair, 25.9ms\n",
            "Speed: 3.3ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 1 cup, 1 chair, 25.9ms\n",
            "Speed: 3.2ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 1 cup, 1 chair, 25.8ms\n",
            "Speed: 3.2ms preprocess, 25.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 1 cup, 1 chair, 25.9ms\n",
            "Speed: 3.3ms preprocess, 25.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 1 cup, 1 chair, 26.1ms\n",
            "Speed: 3.1ms preprocess, 26.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 1 cup, 1 chair, 25.9ms\n",
            "Speed: 3.3ms preprocess, 25.9ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 1 cup, 1 chair, 38.3ms\n",
            "Speed: 3.3ms preprocess, 38.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 1 cup, 1 chair, 27.7ms\n",
            "Speed: 5.3ms preprocess, 27.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 1 cup, 1 chair, 26.9ms\n",
            "Speed: 3.4ms preprocess, 26.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 1 cup, 1 chair, 26.6ms\n",
            "Speed: 3.3ms preprocess, 26.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 1 cup, 1 chair, 26.6ms\n",
            "Speed: 3.0ms preprocess, 26.6ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 1 cup, 1 chair, 28.5ms\n",
            "Speed: 4.4ms preprocess, 28.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 1 cup, 2 chairs, 27.8ms\n",
            "Speed: 3.2ms preprocess, 27.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 1 cup, 2 chairs, 32.6ms\n",
            "Speed: 3.2ms preprocess, 32.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 1 cup, 2 chairs, 27.4ms\n",
            "Speed: 3.3ms preprocess, 27.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 1 cup, 2 chairs, 28.4ms\n",
            "Speed: 3.2ms preprocess, 28.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 1 cup, 2 chairs, 27.4ms\n",
            "Speed: 3.2ms preprocess, 27.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 1 cup, 2 chairs, 28.3ms\n",
            "Speed: 3.1ms preprocess, 28.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 1 cup, 2 chairs, 26.3ms\n",
            "Speed: 2.6ms preprocess, 26.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 1 cup, 2 chairs, 26.3ms\n",
            "Speed: 3.0ms preprocess, 26.3ms inference, 9.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 1 cup, 2 chairs, 26.3ms\n",
            "Speed: 3.2ms preprocess, 26.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 1 cup, 2 chairs, 26.3ms\n",
            "Speed: 8.4ms preprocess, 26.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 1 cup, 2 chairs, 26.3ms\n",
            "Speed: 3.3ms preprocess, 26.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 1 cup, 2 chairs, 26.4ms\n",
            "Speed: 7.6ms preprocess, 26.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 1 cup, 2 chairs, 26.4ms\n",
            "Speed: 3.3ms preprocess, 26.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 bottles, 1 cup, 2 chairs, 27.3ms\n",
            "Speed: 3.2ms preprocess, 27.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 bottles, 1 cup, 2 chairs, 26.3ms\n",
            "Speed: 3.2ms preprocess, 26.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 bottles, 1 cup, 2 chairs, 26.3ms\n",
            "Speed: 3.2ms preprocess, 26.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 bottles, 1 cup, 2 chairs, 26.3ms\n",
            "Speed: 3.2ms preprocess, 26.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 4 bottles, 1 cup, 2 chairs, 26.3ms\n",
            "Speed: 3.3ms preprocess, 26.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 4 bottles, 1 cup, 2 chairs, 26.3ms\n",
            "Speed: 3.4ms preprocess, 26.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 4 bottles, 1 cup, 2 chairs, 26.3ms\n",
            "Speed: 4.6ms preprocess, 26.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 4 bottles, 1 cup, 2 chairs, 26.3ms\n",
            "Speed: 3.7ms preprocess, 26.3ms inference, 7.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 5 bottles, 1 cup, 2 chairs, 26.4ms\n",
            "Speed: 7.0ms preprocess, 26.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6 bottles, 1 cup, 2 chairs, 26.3ms\n",
            "Speed: 5.3ms preprocess, 26.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6 bottles, 1 cup, 2 chairs, 26.4ms\n",
            "Speed: 4.2ms preprocess, 26.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6 bottles, 1 cup, 2 chairs, 27.6ms\n",
            "Speed: 3.2ms preprocess, 27.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6 bottles, 1 cup, 1 chair, 26.3ms\n",
            "Speed: 9.5ms preprocess, 26.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6 bottles, 1 cup, 1 chair, 28.8ms\n",
            "Speed: 4.2ms preprocess, 28.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6 bottles, 1 cup, 1 chair, 28.8ms\n",
            "Speed: 5.8ms preprocess, 28.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 5 bottles, 1 cup, 1 chair, 29.6ms\n",
            "Speed: 3.5ms preprocess, 29.6ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6 bottles, 1 cup, 1 chair, 29.6ms\n",
            "Speed: 4.0ms preprocess, 29.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 6 bottles, 1 cup, 1 chair, 31.1ms\n",
            "Speed: 6.0ms preprocess, 31.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 5 bottles, 1 cup, 1 chair, 30.1ms\n",
            "Speed: 6.3ms preprocess, 30.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 1 chair, 33.4ms\n",
            "Speed: 3.2ms preprocess, 33.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 1 chair, 30.5ms\n",
            "Speed: 3.9ms preprocess, 30.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 chair, 31.7ms\n",
            "Speed: 3.1ms preprocess, 31.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 couch, 30.9ms\n",
            "Speed: 7.5ms preprocess, 30.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 couch, 33.6ms\n",
            "Speed: 3.8ms preprocess, 33.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 couch, 32.6ms\n",
            "Speed: 3.2ms preprocess, 32.6ms inference, 5.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 33.9ms\n",
            "Speed: 3.3ms preprocess, 33.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 31.0ms\n",
            "Speed: 12.5ms preprocess, 31.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 31.0ms\n",
            "Speed: 6.9ms preprocess, 31.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 34.3ms\n",
            "Speed: 3.4ms preprocess, 34.3ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 32.9ms\n",
            "Speed: 4.3ms preprocess, 32.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 32.7ms\n",
            "Speed: 3.4ms preprocess, 32.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 36.3ms\n",
            "Speed: 5.2ms preprocess, 36.3ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 35.6ms\n",
            "Speed: 3.2ms preprocess, 35.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 banana, 34.9ms\n",
            "Speed: 4.5ms preprocess, 34.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 banana, 32.9ms\n",
            "Speed: 8.6ms preprocess, 32.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 banana, 33.1ms\n",
            "Speed: 6.7ms preprocess, 33.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 32.9ms\n",
            "Speed: 3.2ms preprocess, 32.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 32.5ms\n",
            "Speed: 3.0ms preprocess, 32.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 32.5ms\n",
            "Speed: 3.2ms preprocess, 32.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 32.5ms\n",
            "Speed: 8.3ms preprocess, 32.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 32.5ms\n",
            "Speed: 3.2ms preprocess, 32.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 32.5ms\n",
            "Speed: 4.1ms preprocess, 32.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 27.9ms\n",
            "Speed: 3.3ms preprocess, 27.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 27.8ms\n",
            "Speed: 3.3ms preprocess, 27.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 27.6ms\n",
            "Speed: 3.8ms preprocess, 27.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 27.7ms\n",
            "Speed: 7.5ms preprocess, 27.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 27.0ms\n",
            "Speed: 3.3ms preprocess, 27.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 toaster, 27.0ms\n",
            "Speed: 5.3ms preprocess, 27.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 toaster, 26.6ms\n",
            "Speed: 3.2ms preprocess, 26.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 toaster, 26.6ms\n",
            "Speed: 3.2ms preprocess, 26.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 toaster, 26.6ms\n",
            "Speed: 3.8ms preprocess, 26.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 toaster, 26.6ms\n",
            "Speed: 3.4ms preprocess, 26.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 toaster, 26.5ms\n",
            "Speed: 4.1ms preprocess, 26.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 toaster, 26.5ms\n",
            "Speed: 3.3ms preprocess, 26.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 toaster, 26.5ms\n",
            "Speed: 4.0ms preprocess, 26.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 toaster, 30.5ms\n",
            "Speed: 4.2ms preprocess, 30.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 toaster, 26.9ms\n",
            "Speed: 3.2ms preprocess, 26.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 31.2ms\n",
            "Speed: 3.4ms preprocess, 31.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 26.6ms\n",
            "Speed: 3.3ms preprocess, 26.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 26.6ms\n",
            "Speed: 6.7ms preprocess, 26.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 26.6ms\n",
            "Speed: 3.2ms preprocess, 26.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 26.6ms\n",
            "Speed: 3.3ms preprocess, 26.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 26.6ms\n",
            "Speed: 4.6ms preprocess, 26.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 26.7ms\n",
            "Speed: 3.6ms preprocess, 26.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 26.6ms\n",
            "Speed: 7.2ms preprocess, 26.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 26.5ms\n",
            "Speed: 3.3ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 26.6ms\n",
            "Speed: 3.3ms preprocess, 26.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 25.9ms\n",
            "Speed: 3.4ms preprocess, 25.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 29.7ms\n",
            "Speed: 3.2ms preprocess, 29.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 25.6ms\n",
            "Speed: 3.1ms preprocess, 25.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 24.7ms\n",
            "Speed: 3.1ms preprocess, 24.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 24.6ms\n",
            "Speed: 4.0ms preprocess, 24.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 24.8ms\n",
            "Speed: 3.2ms preprocess, 24.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 24.2ms\n",
            "Speed: 3.2ms preprocess, 24.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 24.1ms\n",
            "Speed: 3.6ms preprocess, 24.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 24.3ms\n",
            "Speed: 3.1ms preprocess, 24.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 23.6ms\n",
            "Speed: 3.4ms preprocess, 23.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 23.5ms\n",
            "Speed: 3.2ms preprocess, 23.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 27.3ms\n",
            "Speed: 3.2ms preprocess, 27.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 23.6ms\n",
            "Speed: 3.3ms preprocess, 23.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 23.6ms\n",
            "Speed: 3.4ms preprocess, 23.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 23.6ms\n",
            "Speed: 3.0ms preprocess, 23.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 23.6ms\n",
            "Speed: 6.8ms preprocess, 23.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 23.8ms\n",
            "Speed: 3.5ms preprocess, 23.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 23.6ms\n",
            "Speed: 3.3ms preprocess, 23.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 23.6ms\n",
            "Speed: 3.8ms preprocess, 23.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 24.2ms\n",
            "Speed: 3.2ms preprocess, 24.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 23.6ms\n",
            "Speed: 3.5ms preprocess, 23.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 24.7ms\n",
            "Speed: 3.3ms preprocess, 24.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 23.6ms\n",
            "Speed: 3.2ms preprocess, 23.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 23.6ms\n",
            "Speed: 3.3ms preprocess, 23.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 23.6ms\n",
            "Speed: 3.3ms preprocess, 23.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 25.8ms\n",
            "Speed: 3.6ms preprocess, 25.8ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 23.7ms\n",
            "Speed: 3.4ms preprocess, 23.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 23.6ms\n",
            "Speed: 3.2ms preprocess, 23.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 23.7ms\n",
            "Speed: 3.3ms preprocess, 23.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 23.6ms\n",
            "Speed: 3.2ms preprocess, 23.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 22.9ms\n",
            "Speed: 3.3ms preprocess, 22.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 22.7ms\n",
            "Speed: 3.4ms preprocess, 22.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 22.3ms\n",
            "Speed: 3.1ms preprocess, 22.3ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 22.3ms\n",
            "Speed: 3.3ms preprocess, 22.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 22.3ms\n",
            "Speed: 3.5ms preprocess, 22.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 22.3ms\n",
            "Speed: 3.2ms preprocess, 22.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 22.3ms\n",
            "Speed: 3.3ms preprocess, 22.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 22.3ms\n",
            "Speed: 4.2ms preprocess, 22.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 22.9ms\n",
            "Speed: 5.3ms preprocess, 22.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 22.3ms\n",
            "Speed: 3.2ms preprocess, 22.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 22.3ms\n",
            "Speed: 3.2ms preprocess, 22.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 22.3ms\n",
            "Speed: 11.3ms preprocess, 22.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 24.3ms\n",
            "Speed: 3.4ms preprocess, 24.3ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 22.4ms\n",
            "Speed: 3.3ms preprocess, 22.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 23.9ms\n",
            "Speed: 3.1ms preprocess, 23.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 22.3ms\n",
            "Speed: 3.1ms preprocess, 22.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 25.0ms\n",
            "Speed: 3.4ms preprocess, 25.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 22.3ms\n",
            "Speed: 3.3ms preprocess, 22.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 22.3ms\n",
            "Speed: 3.7ms preprocess, 22.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 22.3ms\n",
            "Speed: 3.3ms preprocess, 22.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 22.3ms\n",
            "Speed: 4.2ms preprocess, 22.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 22.4ms\n",
            "Speed: 3.4ms preprocess, 22.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 22.3ms\n",
            "Speed: 3.7ms preprocess, 22.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 22.5ms\n",
            "Speed: 3.2ms preprocess, 22.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 22.0ms\n",
            "Speed: 3.5ms preprocess, 22.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 21.7ms\n",
            "Speed: 3.1ms preprocess, 21.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 21.9ms\n",
            "Speed: 4.1ms preprocess, 21.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 21.7ms\n",
            "Speed: 2.9ms preprocess, 21.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 21.7ms\n",
            "Speed: 3.1ms preprocess, 21.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 21.8ms\n",
            "Speed: 3.3ms preprocess, 21.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 23.4ms\n",
            "Speed: 3.3ms preprocess, 23.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 21.8ms\n",
            "Speed: 3.3ms preprocess, 21.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 21.7ms\n",
            "Speed: 3.3ms preprocess, 21.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 21.7ms\n",
            "Speed: 10.3ms preprocess, 21.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 21.8ms\n",
            "Speed: 3.3ms preprocess, 21.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 21.7ms\n",
            "Speed: 3.1ms preprocess, 21.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 21.7ms\n",
            "Speed: 3.3ms preprocess, 21.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 21.7ms\n",
            "Speed: 3.3ms preprocess, 21.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 21.8ms\n",
            "Speed: 3.5ms preprocess, 21.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 21.9ms\n",
            "Speed: 3.2ms preprocess, 21.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 21.8ms\n",
            "Speed: 3.7ms preprocess, 21.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 21.7ms\n",
            "Speed: 3.2ms preprocess, 21.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 21.7ms\n",
            "Speed: 3.1ms preprocess, 21.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 21.1ms\n",
            "Speed: 3.3ms preprocess, 21.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 21.2ms\n",
            "Speed: 3.8ms preprocess, 21.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 24.3ms\n",
            "Speed: 6.9ms preprocess, 24.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 22.3ms\n",
            "Speed: 3.2ms preprocess, 22.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 20.8ms\n",
            "Speed: 3.2ms preprocess, 20.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 21.0ms\n",
            "Speed: 3.2ms preprocess, 21.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 20.8ms\n",
            "Speed: 3.3ms preprocess, 20.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 20.8ms\n",
            "Speed: 3.3ms preprocess, 20.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 21.2ms\n",
            "Speed: 3.4ms preprocess, 21.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 cup, 1 bowl, 1 chair, 1 couch, 1 book, 21.2ms\n",
            "Speed: 3.2ms preprocess, 21.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 cup, 1 bowl, 1 chair, 1 couch, 1 book, 20.9ms\n",
            "Speed: 3.3ms preprocess, 20.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 cup, 1 bowl, 1 chair, 1 couch, 1 laptop, 1 book, 25.0ms\n",
            "Speed: 3.5ms preprocess, 25.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 cup, 1 bowl, 1 chair, 1 couch, 1 laptop, 1 book, 21.0ms\n",
            "Speed: 8.8ms preprocess, 21.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 cup, 1 bowl, 1 chair, 1 couch, 1 laptop, 2 books, 21.1ms\n",
            "Speed: 11.1ms preprocess, 21.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 cup, 1 bowl, 1 chair, 1 couch, 1 laptop, 2 books, 21.2ms\n",
            "Speed: 3.4ms preprocess, 21.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 cup, 1 bowl, 1 chair, 1 couch, 1 laptop, 2 books, 22.5ms\n",
            "Speed: 3.2ms preprocess, 22.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 cup, 1 bowl, 1 chair, 1 couch, 1 laptop, 2 books, 21.5ms\n",
            "Speed: 4.5ms preprocess, 21.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 cup, 1 bowl, 1 chair, 1 couch, 1 laptop, 2 books, 21.6ms\n",
            "Speed: 3.3ms preprocess, 21.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 bowl, 1 chair, 1 couch, 1 laptop, 2 books, 21.2ms\n",
            "Speed: 3.6ms preprocess, 21.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 bowl, 1 chair, 2 couchs, 1 laptop, 2 books, 26.2ms\n",
            "Speed: 4.9ms preprocess, 26.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 bowl, 1 chair, 2 couchs, 1 laptop, 1 book, 25.5ms\n",
            "Speed: 3.3ms preprocess, 25.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 bowl, 1 chair, 2 couchs, 1 laptop, 1 book, 21.1ms\n",
            "Speed: 3.3ms preprocess, 21.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 bowl, 1 chair, 3 couchs, 1 laptop, 1 book, 21.0ms\n",
            "Speed: 3.2ms preprocess, 21.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 bowl, 1 chair, 3 couchs, 1 laptop, 1 book, 21.2ms\n",
            "Speed: 3.2ms preprocess, 21.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 bowl, 1 chair, 3 couchs, 1 laptop, 1 book, 21.0ms\n",
            "Speed: 3.3ms preprocess, 21.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 bottle, 1 chair, 3 couchs, 1 laptop, 1 book, 24.2ms\n",
            "Speed: 3.3ms preprocess, 24.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 bottle, 1 chair, 3 couchs, 1 laptop, 1 book, 25.4ms\n",
            "Speed: 3.2ms preprocess, 25.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 bottle, 1 chair, 3 couchs, 1 laptop, 1 book, 24.7ms\n",
            "Speed: 3.1ms preprocess, 24.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 bottle, 1 chair, 3 couchs, 1 laptop, 24.6ms\n",
            "Speed: 3.1ms preprocess, 24.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 bottle, 1 chair, 2 couchs, 1 laptop, 24.7ms\n",
            "Speed: 3.2ms preprocess, 24.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 bottle, 1 chair, 3 couchs, 1 laptop, 24.7ms\n",
            "Speed: 3.5ms preprocess, 24.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 bottle, 1 chair, 3 couchs, 25.9ms\n",
            "Speed: 3.3ms preprocess, 25.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 bottle, 1 chair, 3 couchs, 25.0ms\n",
            "Speed: 3.1ms preprocess, 25.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 bottle, 1 chair, 3 couchs, 25.4ms\n",
            "Speed: 3.4ms preprocess, 25.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 bottle, 1 chair, 3 couchs, 1 book, 29.5ms\n",
            "Speed: 3.2ms preprocess, 29.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 chair, 3 couchs, 1 book, 25.3ms\n",
            "Speed: 3.2ms preprocess, 25.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 chairs, 2 couchs, 1 book, 26.5ms\n",
            "Speed: 3.3ms preprocess, 26.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 chair, 3 couchs, 1 book, 27.9ms\n",
            "Speed: 3.3ms preprocess, 27.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 chair, 3 couchs, 1 book, 25.6ms\n",
            "Speed: 8.6ms preprocess, 25.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 chair, 3 couchs, 1 book, 1 clock, 25.6ms\n",
            "Speed: 3.2ms preprocess, 25.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 chair, 3 couchs, 1 book, 1 clock, 25.6ms\n",
            "Speed: 3.4ms preprocess, 25.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 chair, 3 couchs, 1 book, 1 clock, 25.9ms\n",
            "Speed: 6.6ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 chair, 1 couch, 1 book, 1 clock, 26.6ms\n",
            "Speed: 3.1ms preprocess, 26.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 chair, 1 couch, 1 book, 1 clock, 25.9ms\n",
            "Speed: 3.3ms preprocess, 25.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 chair, 1 couch, 2 books, 27.0ms\n",
            "Speed: 3.5ms preprocess, 27.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 couchs, 2 books, 27.1ms\n",
            "Speed: 3.4ms preprocess, 27.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 chair, 1 couch, 2 books, 26.3ms\n",
            "Speed: 3.2ms preprocess, 26.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bowl, 1 chair, 2 couchs, 2 books, 26.3ms\n",
            "Speed: 3.2ms preprocess, 26.3ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bowl, 1 chair, 2 couchs, 4 books, 26.4ms\n",
            "Speed: 2.8ms preprocess, 26.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bowl, 1 chair, 1 couch, 4 books, 26.9ms\n",
            "Speed: 3.6ms preprocess, 26.9ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bowl, 1 chair, 1 couch, 3 books, 29.6ms\n",
            "Speed: 7.6ms preprocess, 29.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 couch, 2 books, 34.3ms\n",
            "Speed: 3.3ms preprocess, 34.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 couch, 1 book, 26.3ms\n",
            "Speed: 3.3ms preprocess, 26.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 couch, 1 remote, 2 books, 26.4ms\n",
            "Speed: 9.2ms preprocess, 26.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 couch, 1 remote, 2 books, 26.4ms\n",
            "Speed: 4.7ms preprocess, 26.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 couch, 1 book, 26.3ms\n",
            "Speed: 3.4ms preprocess, 26.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 couch, 26.3ms\n",
            "Speed: 3.2ms preprocess, 26.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 couch, 26.3ms\n",
            "Speed: 3.2ms preprocess, 26.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 couch, 26.3ms\n",
            "Speed: 4.3ms preprocess, 26.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 couch, 28.5ms\n",
            "Speed: 3.3ms preprocess, 28.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 tie, 1 couch, 26.3ms\n",
            "Speed: 4.3ms preprocess, 26.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 tie, 1 couch, 26.3ms\n",
            "Speed: 3.3ms preprocess, 26.3ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 tie, 26.3ms\n",
            "Speed: 3.3ms preprocess, 26.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 tie, 26.3ms\n",
            "Speed: 3.3ms preprocess, 26.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 tie, 26.7ms\n",
            "Speed: 7.2ms preprocess, 26.7ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 tie, 26.3ms\n",
            "Speed: 4.0ms preprocess, 26.3ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 tie, 1 bowl, 26.3ms\n",
            "Speed: 8.3ms preprocess, 26.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 tie, 1 bowl, 29.5ms\n",
            "Speed: 3.2ms preprocess, 29.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 tie, 1 bowl, 28.1ms\n",
            "Speed: 4.2ms preprocess, 28.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 tie, 30.1ms\n",
            "Speed: 4.0ms preprocess, 30.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 tie, 28.4ms\n",
            "Speed: 4.4ms preprocess, 28.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 tie, 1 bowl, 28.4ms\n",
            "Speed: 13.2ms preprocess, 28.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 1 bowl, 30.2ms\n",
            "Speed: 3.6ms preprocess, 30.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 bowl, 1 chair, 28.8ms\n",
            "Speed: 4.3ms preprocess, 28.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 bowl, 1 chair, 1 couch, 30.3ms\n",
            "Speed: 3.1ms preprocess, 30.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 tie, 1 bowl, 1 chair, 1 couch, 31.0ms\n",
            "Speed: 6.5ms preprocess, 31.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 tie, 2 bowls, 1 chair, 1 couch, 30.3ms\n",
            "Speed: 3.1ms preprocess, 30.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 bowl, 1 chair, 1 couch, 32.3ms\n",
            "Speed: 5.2ms preprocess, 32.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 tie, 1 bowl, 2 chairs, 1 couch, 34.5ms\n",
            "Speed: 3.5ms preprocess, 34.5ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 tie, 1 bowl, 3 chairs, 33.5ms\n",
            "Speed: 3.5ms preprocess, 33.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 tie, 1 bowl, 3 chairs, 1 couch, 32.3ms\n",
            "Speed: 5.2ms preprocess, 32.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 tie, 1 bowl, 3 chairs, 1 couch, 33.4ms\n",
            "Speed: 3.5ms preprocess, 33.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 tie, 1 bowl, 3 chairs, 1 couch, 31.5ms\n",
            "Speed: 5.0ms preprocess, 31.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 tie, 1 bowl, 3 chairs, 1 couch, 1 book, 31.5ms\n",
            "Speed: 9.3ms preprocess, 31.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 tie, 1 bowl, 3 chairs, 1 couch, 1 book, 32.1ms\n",
            "Speed: 3.9ms preprocess, 32.1ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 tie, 1 bowl, 3 chairs, 1 couch, 1 book, 32.0ms\n",
            "Speed: 10.5ms preprocess, 32.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 tie, 1 bowl, 3 chairs, 1 couch, 2 books, 32.5ms\n",
            "Speed: 6.8ms preprocess, 32.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 tie, 1 bowl, 2 chairs, 1 couch, 1 remote, 2 books, 32.5ms\n",
            "Speed: 3.3ms preprocess, 32.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 tie, 1 bowl, 2 chairs, 1 couch, 2 books, 33.1ms\n",
            "Speed: 3.3ms preprocess, 33.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 tie, 1 bowl, 2 chairs, 1 couch, 2 books, 40.1ms\n",
            "Speed: 3.2ms preprocess, 40.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 tie, 1 bowl, 2 chairs, 1 couch, 2 books, 38.2ms\n",
            "Speed: 4.3ms preprocess, 38.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 tie, 1 bowl, 2 chairs, 1 couch, 2 books, 33.1ms\n",
            "Speed: 8.5ms preprocess, 33.1ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 tie, 1 bowl, 2 chairs, 1 couch, 2 books, 33.6ms\n",
            "Speed: 3.4ms preprocess, 33.6ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n"
          ]
        }
      ]
    }
  ]
}